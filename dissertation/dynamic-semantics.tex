\chapter{Dynamic Semantics in \texorpdfstring{$\banana{\lambda}$}{Our Calculus}}
\label{chap:dynamic-semantics}

We will now examine dynamic semantics. We will consider two theories of
dynamics in natural language: Kamp's DRT~\cite{kamp1993discourse} and de
Groote's TTDL~\cite{de2006towards}. We will build a $\banana{\lambda}$
analysis of dynamics and link it to both theories, as a side effect showing
how DRT links to TTDL.\@ The analysis we will present can be motivated on
the grounds of either DRT or TTDL.\@ We can look at the monad at the core
of TTDL and devise operations that let us perform interesting things within
the monad (quantifying over the discourse and modifying the discourse
state). While this is the process that we have followed to discover this
analysis (presented in~\cite{marsik2014algebraic}), we will follow a novel
strategy in this exposition. We will start with DRT, more specifically its
presentation in Kamp and Reyle's canonical
textbook~\cite{kamp1993discourse} and show how to translate it into
$\banana{\lambda}$ computations. We will then interpret those computations
as TTDL dynamic propositions.

TODO: Speak about presuppositions.

\minitoc


\section{DRT as a Programming Language}
\label{sec:drt-as-pl}

We will argue that the construction rules for DRSes as presented
in~\cite{kamp1993discourse} can be seen as an operational semantics for a
programming language. Once we will have established that DRT is a
programming language, we will use techniques similar to those in
Chapter~\ref{chap:continuations} to embed this language in
$\banana{\lambda}$.

\vspace{6mm}

\doublebox{
\parbox{0.64\textwidth}{
  \underline{\textbf{DRS-Construction Algorithm}}

  \textbf{Input:}
  \begin{tabular}{l}
    discourse $D = S_1, \ldots, S_i, S_{i+1}, \ldots, S_n$ \\
    the empty DRS $K_0$
  \end{tabular}
  
  \vspace{2mm}
  \textbf{Keep repeating for $i = 1, \ldots, n$:}

  \begin{enumerate}[(i)]
  \item\label{item:drs-alg-step1} add the syntactic analysis $[S_i]$ of
    (the next) sentence $S_i$ to the conditions of $K_{i-1}$; call this DRS
    $K_i^*$. Go to~(\ref{item:drs-alg-step2}).

  \item\label{item:drs-alg-step2} Input: a set of reducible conditions of $K_i^*$

    Keep on applying construction principles to each reducible condition of
    $K_i^*$ until a DRS $K_i$ is obtained that only contains irreducible
    conditions. Go to~(\ref{item:drs-alg-step1}).
  \end{enumerate}
}
}

\vspace{6mm}

In~\ref{ssec:drs}, we have said that the conditions of a DRS are atomic
formulas of predicate logic: predicates applied to variables or
constants. However, during DRS construction, this notion is expanded. The
atomic predicates described above are called \emph{irreducible
  conditions}. Along with them, we will also have syntactic trees as
conditions. Furthermore, these syntactic trees might contain discourse
referents.

We will look at DRS construction for an example
from~\cite{kamp1993discourse} (Example~(1.28), Section~1.1.3):

\begin{exe}
  \ex \label{ex:jones-porsche} Jones owns a Porsche. It fascinates him.
\end{exe}

\begin{center}
\begin{tabular}{rcccl}
\drs{\hspace{1cm}}
{
\begin{tikzpicture}
  \Tree [.S [.NP [.PN Jones ] ]
            [.VP$'$ [.VP [.V owns ]
                         [.NP [.DET a ]
                              [.N Porsche ] ] ] ] ]
\end{tikzpicture}
}
& $\to_\crpn$
& \drs{$\drx$}
{
$\obj{Jones}(\drx)$ \\
\begin{tikzpicture}
  \Tree [.S $\drx$
            [.VP$'$ [.VP [.V owns ]
                         [.NP [.DET a ]
                              [.N Porsche ] ] ] ] ]
\end{tikzpicture}
}
& $\to_\crid$
& \drs{$\drx$ $\dry$}
{
$\obj{Jones}(\drx)$ \\
\begin{tikzpicture}
  \Tree [.N($\drx$) Porsche ]
\end{tikzpicture} \\
\begin{tikzpicture}
  \Tree [.S $\drx$
            [.VP$'$ [.VP [.V owns ]
                         $\dry$ ] ] ]
\end{tikzpicture}
}
\end{tabular}
\end{center}

We insert the syntactic analysis of the first sentence into the empty
DRS.\@ Then there is a reduction rule which replaces the NP \emph{Jones}
with a discourse referent $\drx$ while at the same time introducing the
discourse referent $\drx$ and the condition $\obj{Jones}(\drx)$ into the DRS.\@
In the next DRS, we evaluate the object by replacing it with $\dry$ and adding
the discourse referent $\dry$ and a condition in which (the meaning of) the
noun \emph{Porsche} is applied to $\dry$.

\begin{center}
\begin{tabular}{rcccccl}
\drs{$\drx$ $\dry$}
{
$\obj{Jones}(\drx)$ \\
\begin{tikzpicture}
  \Tree [.N($\dry$) Porsche ]
\end{tikzpicture} \\
\begin{tikzpicture}
  \Tree [.S $\drx$
            [.VP$'$ [.VP [.V owns ]
                         $\dry$ ] ] ]
\end{tikzpicture}
}
& $\to_\crlin$
& \drs{$\drx$ $\dry$}
{
$\obj{Jones}(\drx)$ \\
$\obj{Porsche}(\dry)$ \\
\begin{tikzpicture}
  \Tree [.S $\drx$
            [.VP$'$ [.VP [.V owns ]
                         $\dry$ ] ] ]
\end{tikzpicture}
}
& $=$
& \drs{$\drx$ $\dry$}
{
$\obj{Jones}(\drx)$ \\
$\obj{Porsche}(\dry)$ \\
$[\drx$ owns $\dry]$
}
& $\to_\crlitv$
& \drs{$\drx$ $\dry$}
{
$\obj{Jones}(\drx)$ \\
$\obj{Porsche}(\dry)$ \\
$\obj{own}(\drx, \dry)$
}
\end{tabular}
\end{center}

Having reduced the noun phrase \emph{a Porsche}, we are now led to evaluate
the noun \emph{Porsche} itself. It yields the predicate $\obj{Porsche}$. At
this point, the algorithm presented in~\cite{kamp1993discourse}
stops. However, in order to be a little bit more uniform, we will evaluate
reduce the piece of syntax $[\drx$ owns $\dry]$ and replace it with an
atomic formula $\obj{own}(\drx, \dry)$. We can now add the syntactic
analysis of the second sentence and proceed with computation.


\begin{center}
\begin{tabular}{rcl}
\drs{$\drx$ $\dry$}
{
$\obj{Jones}(\drx)$ \\
$\obj{Porsche}(\dry)$ \\
$\obj{own}(\drx, \dry)$ \\
\begin{tikzpicture}
  \Tree [.S [.NP [.PRO It ] ]
            [.VP$'$ [.VP [.V fascinates ]
                         [.NP [.PRO him ] ] ] ] ]
\end{tikzpicture}
}
& $\to_\crpro$
& \drs{$\drx$ $\dry$ $\dru$}
{
$\obj{Jones}(\drx)$ \\
$\obj{Porsche}(\dry)$ \\
$\obj{own}(\drx, \dry)$ \\
$\dru = \dry$ \\
\begin{tikzpicture}
  \Tree [.S $\dru$
            [.VP$'$ [.VP [.V fascinates ]
                         [.NP [.PRO him ] ] ] ] ]
\end{tikzpicture}
}
\end{tabular}
\end{center}

Again, we start by evaluating the subject. This time, it is a pronoun, but
the process remains largely the same. We replace the pronoun with a new
discourse referent $\dru$ which we introduce into the DRS along with the
condition $\dru = \dry$.

\begin{center}
\begin{tabular}{rcccl}
\drs{$\drx$ $\dry$ $\dru$}
{
$\obj{Jones}(\drx)$ \\
$\obj{Porsche}(\dry)$ \\
$\obj{own}(\drx, \dry)$ \\
$\dru = \dry$ \\
\begin{tikzpicture}
  \Tree [.S $\dru$
            [.VP$'$ [.VP [.V fascinates ]
                         [.NP [.PRO him ] ] ] ] ]
\end{tikzpicture}
}
& $\to_\crpro$
& \drs{$\drx$ $\dry$ $\dru$ $\drv$}
{
$\obj{Jones}(\drx)$ \\
$\obj{Porsche}(\dry)$ \\
$\obj{own}(\drx, \dry)$ \\
$\dru = \dry$ \\
$\drv = \drx$ \\
\begin{tikzpicture}
  \Tree [.S $\dru$
            [.VP$'$ [.VP [.V fascinates ]
                         $\drv$ ] ] ]
\end{tikzpicture}
}
& $\to_\crlitv$
& \drs{$\drx$ $\dry$ $\dru$ $\drv$}
{
$\obj{Jones}(\drx)$ \\
$\obj{Porsche}(\dry)$ \\
$\obj{own}(\drx, \dry)$ \\
$\dru = \dry$ \\
$\drv = \drx$ \\
$\obj{fascinate}(\dru, \drv)$
}
\end{tabular}
\end{center}

For the object noun we do the same, introducing the discourse referent
$\drv$ and the condition $\drv = \drx$. Finally, all that is left to
translate the transitive verb into a binary relation and we get the final
DRS representation.

Let us now look at the formulation of the construction rules\footnote{We
  will omit gender features from the rules as we will not be studying
  anaphora resolution in this work.}, starting with $\crid$ in
Figure~\ref{fig:crid}.

\begin{figure}
\centering
\cridbox
\caption{\label{fig:crid} $\crid$: The construction rule for indefinite
  descriptions.}
\end{figure}

The \emph{triggering configuration} describes the rule's redex (and part of
its context). In the case of $\crid$, the rule for indefinite descriptions,
the redex is a noun phrase of the form \emph{a(n) $N$}. The actual
triggering configuration also includes the node dominating the NP as
well. This is for reasons of evaluation order:

\begin{quote}
``A reducible condition $\gamma$ must be reduced by applying the appropriate
rule to its \emph{highest} triggering configuration, i.e.\ that triggering
configuration $\tau$ such that the highest node of $\tau$ dominates the
highest node of any other triggering configuration that $\gamma$ contains.''
\begin{flushright}
  From Discourse to Logic~\cite{kamp1993discourse} (Section 1.1.4, page 87
  in the Student Edition)
\end{flushright}
\end{quote}

In this rule, it serves to make the application of the rule to a subject
dominant to the application of the same rule (or any other rule evaluating,
for that purpose) to an object and therefore fixes evaluation order: first
subject, then object.

The rule then has its contractum, which is given on the last line
(\textbf{Substitute in $\overline{\gamma}$}). In this case, the contractum
is the discourse referent $u$. The rule also has two important side
effects. First, the discourse referent $u$ is introduced into the DRS that
contains this condition. Second, the condition $[N](u)$ is added to the
conditions of that same DRS.\@ The notation $[N](u)$ means that we copy the
whole syntactic structure of $N$ (i.e.\ the whole program for computing the
meaning of the noun) and once its meaning (a predicate) is computed, we
apply it to the discourse referent $u$.

\begin{figure}
\centering
\crprobox
\caption{\label{fig:crpro} $\crpro$: The construction rule for (anaphoric
  third-person singular) pronouns.}
\end{figure}

The rule for pronouns, $\crpro$ in Figure~\ref{fig:crpro}, is very
similar. In introduces a new kind of operation, in which the NP being
evaluated is asking its context for a suitable anaphoric referent.

We will leave the rule for proper nouns until~\ref{sec:presuppositions} and
give the two lexical insertion rules for nouns and transitive verbs
\footnote{the latter is not present in~\cite{kamp1993discourse}. Instead,
  the authors declare [$x$ loves $y$] to be an irreducible condition.}.

\begin{figure}
\begin{subfigure}[b]{0.4\textwidth}
\crlinbox
\caption{\label{fig:crlin} $\crlin$: The lexical insertion rule for
  (common) nouns.}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.4\textwidth}
\crlitvbox
\caption{\label{fig:crlitv} $\crlitv$: The lexical insertion rule for
  (transitive) verbs.}
\end{subfigure}
\caption{\label{fig:li} The lexical insertion construction rules.}
\end{figure}

The system from~\cite{kamp1993discourse} described above can be presented
in a manner reminiscent of operational semantics for programming languages.

The terms of this language are syntactic trees containing discourse
referents and wrapped inside DRSs. The values are just discourse referents
and DRSs\footnote{Containing only predicates as conditions.}. We will
define evaluation contexts $C$. These should reflect the fact the
construction algorithm of DRT permits reduction in any of the conditions
within a DRS.

$$
  C ::= [] \ | \ \drs{ $\drx_1$ \ldots\ $\drx_n$ }
                { $\gamma_1$ \\ \ldots \\ $\lnot C$ \\ \ldots \\ $\gamma_m$}
           \ | \ \drs{ $\drx_1$ \ldots\ $\drx_n$ }
                { $\gamma_1$ \\ \ldots \\ $C \Rightarrow K$ \\ \ldots \\ $\gamma_m$}
           \ | \ \drs{ $\drx_1$ \ldots\ $\drx_n$ }
                { $\gamma_1$ \\ \ldots \\ $K \Rightarrow C$ \\ \ldots \\ $\gamma_m$}
           \ | \ \drs{ $\drx_1$ \ldots\ $\drx_n$ }
                { $\gamma_1$ \\ \ldots \\ $C \lor K$ \\ \ldots \\ $\gamma_m$}
           \ | \ \drs{ $\drx_1$ \ldots\ $\drx_n$ }
                { $\gamma_1$ \\ \ldots \\ $K \lor C$ \\ \ldots \\ $\gamma_m$}
$$

The reducible conditions are syntactic trees. The triggering configuration
can be found in any part of a syntactic tree and so we define $C_\gamma$ to
be a context that places $[]$ inside a syntactic tree. For every rule
$A \to B_1 \ldots B_n$, there will be a production rule for the context
$C_\gamma ::= A (B_1, \ldots, B_{i-1}, C_\gamma, B_{i+1}, \ldots, B_n)$.

$$
  C_\gamma ::= []\ |\ \leaf{$C_\gamma$} \leaf{VP} \branch{2}{S} \tree
                 \ |\ \leaf{NP} \leaf{$C_\gamma$} \branch{2}{S} \tree
                 \ |\ \leaf{$C_\gamma$} \leaf{NP} \branch{2}{VP} \tree
                 \ |\ \leaf{V} \leaf{$C_\gamma$} \branch{2}{VP} \tree \ |\ \ldots
$$

The construction rule $\crid$ is then a reduction rule on these forms:

$$
  C\left[\ 
    \drs{$\drx_1$ \ldots\ $\drx_n$}
        {$\gamma_1$ \\
         \ldots \\
         $C_\gamma \left[ \leaf{a(n)} \branch{1}{DET} \leaf{N}
           \branch{2}{NP} \leaf{VP$'$} \branch{2}{S} \tree \right]$ \\
         \ldots \\
         $\gamma_m$}\ \right]
  \to_\crid
  C\left[\ 
    \drs{$\drx_1$ \ldots\ $\drx_n$ $\dru$}
        {$\gamma_1$ \\
         \ldots \\
         $[$N$](\dru)$ \\
         $C_\gamma \left[ \leaf{$\dru$} \leaf{VP$'$} \branch{2}{S} \tree \right]$ \\
         \ldots \\
         $\gamma_m$}\ \right]
$$

Likewise, there is an analogue for evaluating indefinite descriptions in
object positions which differs only in the triggerring configuration. The
reduction rules for $\crpro$, $\crlin$ and $\crlitv$ can be derived in the
same way. Then, the DRS that corresponds to a sentence can be seen as a
normal form of in this reduction system\footnote{The system permits
  reductions in different conditions at the same time and is therefore not
  confluent. Hence the indefinite article in ``\emph{a normal form}''.}.

If we look at the rule that we can see a remarkable similarity to the likes
of those seen in Chapter~\ref{chap:continuations} for $\lambda_\shift$ and
$\lambda_\shifto$. Inside the context $C$, we have some kind of delimiting
construction, a DRS in one case and a $\reset$ in the other. As one of the
arguments of this construction, we have an expression buried inside a more
limited context: $C_\gamma$, which cannot contain any more nested DRSs, and
$F$, which cannot contain any more $\reset$s. In the case of DRT, this
buried expression is an indefinite or a pronoun which wants to access the
context's DRS to add (and possibly look for) discourse referents and
conditions. In the case of $\lambda_\shift$, the buried expression is a
$\shift$ that wants complete control over the context inside the
$\reset$. In our analysis of $\lambda_\shift$, $\reset$ corresponded
directly to a handler. Therefore, we will be treating DRSs as handlers in
the coming $\banana{\lambda}$ analysis. The denotations of indefinites and
pronouns will use operations to introduce new discourse referents and
conditions and to query the state of discourse to resolve anaphora.


\section{\texorpdfstring{$\banana{\lambda}$ Analysis}{Analysis in Our Calculus}}
\label{sec:banana-drt}

The first step in building a $\banana{\lambda}$ analysis of dynamics is to
design the effect signature: how many operations we will need, what their
types should be and what they should do. However, our task is largely
facilitated by the fact that in their exposition of
DRT~\cite{kamp1993discourse}, Kamp and Reyle have structured the
construction rules by using a limited set of operations to manipulate the
DRSs. It is these operations that we will include in our effect
signature. Consider the construction rule of pronouns and the corresponding
representation as a $\banana{\lambda}$ computation.

\vspace{6mm}

\hspace{-5mm}
\begin{minipage}{0.63\textwidth}
\crprobox
\end{minipage}
\begin{minipage}{0.36\textwidth}
\vspace{0.4cm}
\begin{align*}
\alpha &: NP \\ \\
\sem{NP} &= \FF_E(\iota)
\end{align*}
\vspace{0.1cm}
\begin{align*}
\sem{\alpha} =\ & \app{\op{choose}}{&&\star}{ &(\lam{v}{ \\
                & \app{\op{introduce}}{&&\star}{ &(\lam{u}{ \\
                & \app{\op{assert}}{&&(u = v)}{ &(\lam{\_}{ \\
                \\ \\
                & \ap{\eta}{u}})}})}})}
\end{align*}
\end{minipage}

\vspace{6mm}

Let $\alpha$ be a third-person singular pronoun\footnote{Since we ignore
  gender, we can think of $\alpha$ as \emph{the} third-person singular
  pronoun}. The construction rule reduces the NP node formed by $\alpha$
into a discourse referent. In the corresponding analysis in our formalism
(ACG + $\banana{\lambda}$), we have $\alpha$ as an abstract constant of
type $NP$ whose semantic interpretation is a computation of type
$\FF_E(\iota)$. The pronoun asks the context for a suitable antecedent,
which is then referred to as $v$. We mimic the verb \textbf{choose} with an
operation $\op{choose}$. It does not take as any inputs, as no inputs are
provided in the construction to the rule\footnote{If we were to care about
  gender markers, the input of this operation would be the gender
  marker/predicate, much like in the example of the $\op{select}$ operator
  proposed in~\ref{ssec:choosing-effect-signature}.}, and expects a
discourse referent in return. Since we will be using the type $\iota$ for
terms that designate individuals, we will identify the type of discourse
referents with $\iota$.

$$
\typedop{choose}{1}{\iota}
$$

Next up, the construction rule demands the introduction of a new discourse
referent into the DRS $\KK$ that contains the condition being
evaluated. This instruction and its use of the verb \textbf{introduce}
gives rise to the $\op{introduce}$ operation. $\op{introduce}$ asks for a
fresh discourse referent and so its type ends being the same as the one for
$\op{choose}$, only the semantics differ\footnote{}:

$$
\typedop{introduce}{1}{\iota}
$$

The next step in the construction rule asks the DRS $\KK$ to introduce a
new condition. For this kind of interaction, \textbf{introducing} a
condition, we will use a new operation, $\op{assert}$. The NP indicates
that the condition it wants to add to the DRS, the truth-condition that it
wants to assert. Conditions are atomic formulas of predicate logic and so
we will use $o$, the type of propositions, to represent them. The output
will be of the trivial type $1$ and we will therefore use the variable name
$\_$, as conventional in functional programming.

$$
\typedop{assert}{o}{1}
$$

Finally, the construction rule tells us to replace the NP node with the
discourse referent $u$. This way, when this NP occurs as an argument to a
predicate, the predicate should be applied to the discourse referent
$u$. In $\banana{\lambda}$, this role is played by the return values of
computations (see equation below). Therefore, we return $u$ with the
computation $\etaE{u}$.

$$
\obj{predicate} \apr (\app{\op{op}}{M_\petitp}{(\lam{x}{ \ldots\
    \etaE{u}})}) = \app{\op{op}}{M_\petitp}{(\lam{x}{ \ldots\
    \etaE{(\obj{predicate}(u))}})}
$$

We can do the same kind of analysis/translation for the $\crid$ rule for
indefinite descriptions.

\vspace{6mm}

\hspace{-10mm}
\begin{minipage}{0.72\textwidth}
\cridbox
\end{minipage}
\begin{minipage}{0.27\textwidth}
\vspace{0.3cm}
\begin{align*}
\abs{a} &: N \limp NP \\
\sem{N} &= \FF_E(\iota \to o) \\
\sem{NP} &= \FF_E(\iota)
\end{align*}
\begin{align*}
\sem{\abs{a}} =\ \lam{N}{& \app{\op{introduce}}{&&\star}{ &(\lam{u}{ \\
                         & N &&\hsbind &(\lam {n}{ \\
                         & \app{\op{assert}}{&&(n(u))}{ &(\lam{\_}{ \\
                         \\
                         & \ap{\eta}{u}})}})})}}
\end{align*}
\end{minipage}

\vspace{6mm}

The $\crid$ rule evaluates a noun phrase which is composed of the
indefinite article followed by some noun $N$. This construction is
represented in our ACG as an abstract constant $\abs{a} : N \limp NP$. Its
denotation will be a function from $\sem{N}$ to $\sem{NP}$. As in the rest
of the analyses seen in this chapter, we will take
$\sem{N} = \FF_E(\iota \to o)$, which meshes with the fact that DRT expects
nouns to reduce to predicates.

The evaluation of the noun phrase ``\emph{a $N$}'' starts by introducing a
fresh discourse referent $u$ and so we use the same operation as in
$\crpro$. Then we will proceed by adding the condition $[N](u)$. Note that
in the DRT rule, we are dealing with a reducible condition ($[N]$ is the
syntax of $N$). In adding this reducible condition, DRT essentially
schedules the evaluation of the syntactic expression $[N]$ via some other
construction rule ($\crlin$ if $N$ is only a common noun, other rules if it
is, e.g., restricted by a relative clause or an adjective). In
$\banana{\lambda}$, we achieve a similar effect by asking for the
evaluation of $N$ using the $\hsbind$ operator. We then state that once the
noun has been evaluated down to a predicate, we want this predicate,
applied to the referent $u$, to be a condition inside the DRS.\@ Finally,
as in $\crpro$, we present the discourse referent $u$ as the referent of
the noun phrase.

For completeness, we will also give translations for the $\crlin$ and
$\crlitv$ rules, even though they do not have any dynamic effects of their
own.

\vspace{6mm}

\begin{minipage}{0.5\textwidth}
\crlinbox
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{align*}
\abs{common} &: CN \limp N \\
\sem{CN} &= \iota \to o \\
\sem{N} &= \FF_E(\iota \to o)
\end{align*}
\begin{align*}
\sem{\abs{common}} &= \lam{\alpha}{\etaE{(\lam{v}{\alpha(v)})}} \\
                   &= \lam{\alpha}{\etaE{\alpha}} \\
                   &= \eta
\end{align*}
\end{minipage}

\vspace{6mm}

We, as well as Kamp and Reyle, assume that behind every common noun
$\alpha$ lies a set of individuals, a predicate $\alpha$. The lexical
insertion rule for nouns replaces the noun by that predicate. We can
capture the same line of reasoning in ACGs. We contrast the category $CN$
of common nouns (such as \emph{snowman}, \emph{snake}, \emph{ladder}) to
the larger category $N$ of nouns (\emph{animal in your garden}, \emph{man
  who owns a donkey}). The common nouns will correspond to plain sets of
individuals, $\sem{CN} = \iota \to o$. However, more complex nouns might
also have effects (in the case of dynamics, anaphora, more generally,
deixis, quantification, conventional implicature\ldots) and so we have
$\sem{N} = \FF_E(\iota \to o)$. In ACGs, to say that every common noun $CN$
is a noun $N$ is to provide an injection of type $N \limp
CN$. Homomorphically, its denotation will be an injection from
$\iota \to o$ to $\FF_E(\iota \to o)$, the constructor $\eta$.

\vspace{6mm}

\begin{minipage}{0.5\textwidth}
\crlitvbox
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{align*}
\abs{trans} &: V \limp NP \limp NP \limp S \\
\sem{V} &= \iota \to \iota \to o \\
\sem{NP} &= \FF_E(\iota) \\
\sem{S} &= \FF_E(o)
\end{align*}
\begin{align*}
\sem{\abs{trans}} = \lam{\alpha Y X}{&X \hsbind (\lam{x}{ \\
                                     &Y \hsbind (\lam{y}{ \\
                                     &\etaE{(\alpha(x, y))}})})} \\
                  = \lam{\alpha Y X}{&\alpha \apr X \aplr Y}
\end{align*}
\end{minipage}

\vspace{6mm}

With $\crlitv$, the idea behind the DRT/$\banana{\lambda}$ analogy is the
same as with $\crlin$. Behind every (extensional transitive) verb $\alpha$
lies a binary relation, also called $\alpha$. When combined with a subject
and an object, verbs form sentences. This is embodied by the ACG abstract
constant $\abs{trans}$ which maps verbs from $V$ into functions in
$NP \limp NP \limp S$. From the triggerring configuration of the rule
$\crlitv$, we see that (the parent of) the subject dominates (the parent
of) the object. This leads DRT to always evaluate the dynamic effects of
the subject before the object. In $\banana{\lambda}$, this feature is
expressed in the lexical entry for the construction that combines the
subject, verb and object into a sentence, $\abs{trans}$.


\subsection{Example}
\label{ssec:dynamic-example}

We have seen how to map the syntax-semantics construction rules of DRT into
the ACG formalism and how the extra steps performed when reducing
indefinites or pronouns in DRT correspond naturally to operations, with
which we have extended ACG's lambda calculus in $\banana{\lambda}$. We can
now look at an example in action.

\begin{exe}
  \ex \label{ex:man-porsche} A man owns a Porsche. It fascinates him.
\end{exe}

This is a small variation of Example~\ref{ex:jones-porsche} in which
\emph{Jones} was replaced by \emph{a man}\footnote{We relegate the
  discussion of proper nouns to~\ref{sec:presuppositions}.}.

\begin{align*}
  \sem{\appp{\abs{trans}}{&\abs{owns}}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{Porsche}})})}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{man}})})}} \\
  \tto &\ \app{\op{introduce}}{\star}{(\lam{x}{ \\
       &\ \app{\op{assert}}{(\obj{man}(x))}{(\lam{\_}{ \\
       &\ \app{\op{introduce}}{\star}{(\lam{y}{ \\
       &\ \app{\op{assert}}{(\obj{Porsche}(y))}{(\lam{\_}{ \\
       &\ \etaE{(\obj{own}(x, y))}})}})}})}})}
\end{align*}

The only effects are due to the indefinites that introduce new discourse
referents and assert truth conditions. The operations are ordered
subject-first, object-last and the computation returns the predicate that
is the application of the verb's predicate to the referents of the subject
and the object. The same goes for the second sentence in
Example~\ref{ex:man-porsche}:

\begin{align*}
  \sem{\appp{\abs{trans}}{&\abs{fascinates}}{\abs{him}}{\abs{it}}} \\
  \tto &\ \app{\op{choose}}{\star}{(\lam{y'}{ \\
       &\ \app{\op{introduce}}{\star}{(\lam{u}{ \\
       &\ \app{\op{assert}}{(u = y')}{(\lam{\_}{ \\
       &\ \app{\op{choose}}{\star}{(\lam{x'}{ \\
       &\ \app{\op{introduce}}{\star}{(\lam{v}{ \\
       &\ \app{\op{assert}}{(v = x')}{(\lam{\_}{ \\
       &\ \etaE{(\obj{fascinate}(u, v))}})}})}})}})}})}})}
\end{align*}

We can compose the two using $\andlr$, the conjunction of propositions
raised to computations.

\begin{align*}
  \sem{\appp{\abs{trans}}{&\abs{owns}}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{Porsche}})})}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{man}})})}} \andlr \sem{\appp{\abs{trans}}{\abs{fascinates}}{\abs{him}}{\abs{it}}} \\
  \tto &\ \app{\op{introduce}}{\star}{(\lam{x}{ \\
       &\ \app{\op{assert}}{(\obj{man}(x))}{(\lam{\_}{ \\
       &\ \app{\op{introduce}}{\star}{(\lam{y}{ \\
       &\ \app{\op{assert}}{(\obj{Porsche}(y))}{(\lam{\_}{ \\
       &\ \app{\op{choose}}{\star}{(\lam{y'}{ \\
       &\ \app{\op{introduce}}{\star}{(\lam{u}{ \\
       &\ \app{\op{assert}}{(u = y')}{(\lam{\_}{ \\
       &\ \app{\op{choose}}{\star}{(\lam{x'}{ \\
       &\ \app{\op{introduce}}{\star}{(\lam{v}{ \\
       &\ \app{\op{assert}}{(v = x')}{(\lam{\_}{ \\
       &\ \etaE{(\obj{own}(x, y) \land \obj{fascinate}(u, v))}})}})}})}})}})}})}})}})}})}})}
\end{align*}

The resulting computation introduces 4 discourse referents: $x$, $y$, $u$
and $v$. Assuming that $\op{choose}$ will give us $x$ for $x'$ and $y$ for
$y'$, then we end up introducing and returning the conditions
$\obj{man}(x)$, $\obj{Porsche}(y)$, $u = x$, $v = y$, $\obj{own}(x, y)$ and
$\obj{fascinate}(u, v)$, i.e.\ the same conditions as in the DRS for
Example~\ref{ex:jones-porsche} (replacing $\obj{Jones}(x)$ with
$\obj{man}(x)$). However, while that might be our desired interpretation of
this computation, for now, it is just a string of symbols.


\subsection{Handler for Dynamics}
\label{ssec:handler-for-dynamics}

In order to give a formal semantics to the operations that we have
introduced for DRT, we will write a handler. The type of dynamic
propositions, $\gamma \to (\gamma \to o) \to o$, of de Groote's TTDL will
serve as a suitable interpretation domain. On top of that, apart from
implementing a semantics for our operations, we will have demonstrated the
link between DRT and TTDL.\@ The type of the handler's input will be
$\FF_E(o)$, where $E$ is the effect signature containing only
$\op{choose}$, $\op{introduce}$ and $\op{assert}$.

\begin{align*}
  \TTDL :\ &\FF_E(o) \to \gamma \to (\gamma \to o) \to o \\
  \TTDL = \bbanana{\ 
  &\onto{\op{choose}}{(\lam{\_ k e \phi}{\appp{k}{(\sel(e))}{e}{\phi}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k e \phi}{\exists x.\ \appp{k}{x}{(x \cons e)}{\phi}})}, \\
  &\onto{\op{assert}}{(\lam{p k e \phi}{p \land \appp{k}{\star}{(p \cons e)}{\phi}})}, \\
  &\onto{\eta}{(\lam{p e \phi}{p \land \ap{\phi}{e}})}\ }
\end{align*}

We write the handler by following the types, keeping in mind the intended
semantics. There is a remarkable similarity between the clauses of our
handler and the operators and semantic entries used in TTDL.\@ The $\eta$
clause is the operation that lifts plain propositions into dynamic
propositions~\cite{lebedeva2012expression}. The clause for $\op{choose}$ is
(ignoring the first dummy argument) exactly the denotation assigned to
pronouns in TTDL~\cite{de2006towards}. The clause for $\op{introduce}$ is
the denotation of the indefinite \emph{someone}, also known as the dynamic
existential quantifier in~\cite{lebedeva2012expression}. This is not a
coincidence. The clauses for $\op{choose}$ and $\op{introduce}$ are both
values of type $\iota$ written in continuation-passing style with
observation type $\Omega = \gamma \to (\gamma \to o) \to o$, i.e.\ values
of type $(\iota \to \Omega) \to \Omega$. TTDL uses continuation-passing
style in the denotation of its noun phrases to account for quantification
and so their denotations end up having the very same type. The two noun
phrases, the pronoun and the indefinite, stand for the two major ways that
dynamic noun phrases interact with their contexts, retrieving their
referents from context or introducing new ones into the context. Together
with $\op{assert}$, which lets us conjoin another proposition to the
observed proposition, these form the three operations with which we
characterize DRT dynamics. Our original discovery of these three operations
with which we can characterize dynamic effects came from the realization
that we can express all the denotations in TTDL with: reading from the
context ($\op{choose}$, or later $\op{get}$), wrapping an existential
quantifier over the continuation while adding the bound variable into the
context ($\op{introduce}$) and conjoining a proposition to the continuation
($\op{assert}$).

Once we have applied the $\TTDL$ handler to a computation of type
$\FF_E(o)$, we can extract the corresponding (simple) proposition by
applying the result to some left context and the trivial right context
($\lam{e}{\top}$). Since this what we will be doing most of the time, we
can simplify the $\TTDL$ handler by assuming that $\phi$ is always equal to
$\lam{e}{\top}$.

\begin{align*}
  \BOX :\ &\FF_E(o) \to \gamma \to o \\
  \BOX = \bbanana{\ 
  &\onto{\op{choose}}{(\lam{\_ k e}{\app{k}{(\sel(e))}{e}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k e}{\exists x.\ \app{k}{x}{(x \cons e)}})}, \\
  &\onto{\op{assert}}{(\lam{p k e}{p \land \app{k}{\star}{(p \cons e)}})}, \\
  &\onto{\eta}{(\lam{p e}{p})}\ }
\end{align*}

Getting back to Example~\ref{ex:man-porsche}, we can now apply one of these
two handlers to get the dynamic proposition.

\begin{align*}
&\ap{\TTDL}{(\sem{\appp{\abs{trans}}{\abs{owns}}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{Porsche}})})}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{man}})})}} \andlr \sem{\appp{\abs{trans}}{\abs{fascinates}}{\abs{him}}{\abs{it}}})} \\
&\tto \lam{e \phi}{\exists x.\ \obj{man}(x) \land (\exists y.\ \obj{Porsche}(y) \land (\exists u.\ u = \sel(e_1) \land (\exists v.\ v = \sel(e_2) \land \obj{own}(x, y) \land \obj{fascinate}(u, v) \land \ap{\phi}{e_3})))} \\
&= \lam{e \phi}{\exists x y u v.\ \obj{man}(x) \land \obj{Porsche}(y) \land u = \sel(e_1) \land v = \sel(e_2) \land \obj{own}(x, y) \land \obj{fascinate}(u, v) \land \ap{\phi}{e_3}} \\
&= \lam{e \phi}{\exists x y u v.\ \obj{man}(x) \land \obj{Porsche}(y) \land u = y \land v = x \land \obj{own}(x, y) \land \obj{fascinate}(u, v) \land \ap{\phi}{e_3}} \\
&= \lam{e \phi}{\exists x y.\ \obj{man}(x) \land \obj{Porsche}(y) \land \obj{own}(x, y) \land \obj{fascinate}(y, x) \land \ap{\phi}{e_3}}
\end{align*}

where:
\vspace{-1mm}
\begin{align*}
  e_1 &= \obj{Porsche}(y) \cons y \cons \obj{man}(x) \cons x \cons e \\
  e_2 &= (u = \sel(e_1)) \cons u \cons e_1 \\
  e_3 &= (v = \sel(e_2)) \cons v \cons e_2
\end{align*}

We have used Kamp's construction rules to compute a dynamic proposition in
de Groote's TTDL.\@ The first line shows the result as we get it from the
handler. On the second line, we pull out all of the existential quantifiers
(prenex form). On the third line, we resolve the anaphora and we get a
dynamic proposition which corresponds referent by referent, condition by
condition to the DRS derived by Kamp and Reyle. The last line removes
spurious variables and equalities.


\subsection{Negation}
\label{ssec:dynamic-negation}

In order to match the empirical coverage of the original TTDL
from~\cite{de2006towards}, we have two more features to cover: negation and
(universal) quantification. We will cover negation here. Quantification
reuses the idea from negation and the $\op{scope}$ operation of
quantification: we will see how the two connect in
Chapter~\ref{chap:composing-effects}.

\begin{figure}
  \centering
  \crnegbox
  \caption{\label{fig:crneg} $\crneg$: The construction rule for negation.}
\end{figure}

The construction rule for negation, $\crneg$, is displayed in
Figure~\ref{fig:crneg}. We are reducing a condition which is in the form of
a negated sentence. The DRT mechanism will place the sentence in its own
DRS, whose negation will then become the new condition that replaces the
sentence. The dynamic effects that we have seen so far reach only into the
nearest enclosing DRS.\@ This means that wrapping something inside a new
DRS is significant: the reach of any dynamic effects within will be limited
to that DRS.\@ We have also seen that this is akin to the way effects like
$\shift$ are delimited/handled by the nearest $\reset$. It will come as no
surprise then that our implementation of negation will use a handler for
dynamic effects.

The definition of dynamic negation in TTDL
from~\cite{lebedeva2012expression} will be a great guide in how to proceed:

\begin{align*}
\dnot_{\TTDL} \_ &: \Omega \to \Omega \\
\dnot_{\TTDL} A &= \lam{e \phi}{\lnot (\app{A}{e}{(\lam{e}{\top})}) \land \ap{\phi}{e}}
\end{align*}

We know that $\lam{e \phi}{M \land \ap{\phi}{e}}$ corresponds to $\etaE{M}$
and that $\app{A}{e}{(\lam{e}{\top})}$ is $\app{\BOX}{A}{e}$. Therefore, we
can define our dynamic negation by:

\begin{align*}
\dnot \_ &: \FF_E(o) \to \FF_E(o) \\
\dnot A &= \etaE{(\lnot (\app{\BOX}{A}{e}))}
\end{align*}

However, there is a small catch. We have a free variable $e$ of type
$\gamma$. This is supposed to be the context in which the new negated
condition is to appear. This is necessary so that the anaphoric elements
within the negated condition can refer to not only referents proper to the
negated DRS, but also those originating in superordinate DRSs. We can
introduce a new operation for accessing the context.

$$
\typedop{get}{1}{\gamma}
$$

Now, we can have dynamic negation as:

$$
\dnot A = \app{\op{get}}{\star}{(\lam{e}{\etaE{(\lnot (\app{\BOX}{A}{e}))}})}
$$

We can see the analogy with $\crneg$: the negation of $A$ puts $A$ inside a
box, the box is then negated and returned as the new condition. The name
$\BOX$ for this kind of handler was motivated exactly by this kind of
analogy, wherein a handler is used to contain dynamic effects inside some
scope.

We have introduced a new operation into our dynamic effect signature. This
means that we will have to extend our handlers to cover the new
operation. However, before we do so, we note that $\op{choose}$ can be
expressed in terms of $\op{get}$ and $\sel$:

$$
\op{choose} = \lam{\_ k}{\app{\op{get}}{\star}{(\lam{e}{\ap{k}{(\sel(e))}})}}
$$

Therefore, we will drop $\op{choose}$ and keep only $\op{get}$. We have now
arrived at our final effect signature for DRT dynamics. This signature
allows us to treat dynamic effects the same way as the other effects that
we have analyzed in this chapter.

\begin{align*}
  E_\DRT = \{\ &\typedop{get}{1}{\gamma}, \\
              &\typedop{introduce}{1}{\iota}, \\
              &\typedop{assert}{o}{1}\ \}
\end{align*}

The closed handlers $\TTDL$ and $\BOX$ are updated to use $\op{get}$
instead of $\op{choose}$:

\begin{align*}
  \TTDL :\ &\FF_{E_\DRT}(o) \to \gamma \to (\gamma \to o) \to o \\
  \TTDL = \bbanana{\ 
  &\onto{\op{get}}{(\lam{\_ k e \phi}{\appp{k}{e}{e}{\phi}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k e \phi}{\exists x.\ \appp{k}{x}{(x \cons e)}{\phi}})}, \\
  &\onto{\op{assert}}{(\lam{p k e \phi}{p \land \appp{k}{\star}{(p \cons e)}{\phi}})}, \\
  &\onto{\eta}{(\lam{p e \phi}{p \land \ap{\phi}{e}})}\ } \\ \\
  \BOX :\ &\FF_{E_\DRT}(o) \to \gamma \to o \\
  \BOX = \bbanana{\ 
  &\onto{\op{get}}{(\lam{\_ k e}{\app{k}{e}{e}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k e}{\exists x.\ \app{k}{x}{(x \cons e)}})}, \\
  &\onto{\op{assert}}{(\lam{p k e}{p \land \app{k}{\star}{(p \cons e)}})}, \\
  &\onto{\eta}{(\lam{p e}{p})}\ }
\end{align*}


\subsection{Truth Conditions as Side Effects}
\label{ssec:truth-conditions-side-effects}

Let us look back the computation that we assigned to the first sentence in
Example~\ref{ex:man-porsche}: \emph{a man owns a Porsche}.

\begin{align*}
&\app{\op{introduce}}{\star}{(\lam{x}{ \\
&\app{\op{assert}}{(\obj{man}(x))}{(\lam{\_}{ \\
&\app{\op{introduce}}{\star}{(\lam{y}{ \\
&\app{\op{assert}}{(\obj{Porsche}(y))}{(\lam{\_}{ \\
&\etaE{(\obj{own}(x, y))}})}})}})}})}
\end{align*}

The truth condition that corresponds to the verb is being returned by the
computation, whereas the truth conditions that arise from the nouns are
expressed using $\op{assert}$. The at-issue content of this sentence
consists of all of these conditions and therefore there is no reason to
separate out the verb's predicate. We could thus write this instead:

\begin{align*}
&\app{\op{introduce}}{\star}{(\lam{x}{ \\
&\app{\op{assert}}{(\obj{man}(x))}{(\lam{\_}{ \\
&\app{\op{introduce}}{\star}{(\lam{y}{ \\
&\app{\op{assert}}{(\obj{Porsche}(y))}{(\lam{\_}{ \\
&\app{\op{assert}}{(\obj{own}(x, y))}{(\lam{\_}{ \\
&\etaE{\star}})}})}})}})}})}
\end{align*}

This is a computation of type $\FF_{E_\DRT}(1)$. As before, we use a
handler to extract the proposition that is represented by this computation.

\begin{align*}
  \TTDL :\ &\FF_{E_\DRT}(1) \to \gamma \to (\gamma \to o) \to o \\
  \TTDL = \bbanana{\ 
  &\onto{\op{choose}}{(\lam{\_ k e \phi}{\appp{k}{(\ap{\sel}{e})}{e}{\phi}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k e \phi}{\exists x.\ \appp{k}{x}{(x \cons e)}{\phi}})}, \\
  &\onto{\op{assert}}{(\lam{p k e \phi}{p \land \appp{k}{\star}{(p \cons e)}{\phi}})}, \\
  &\onto{\eta}{(\lam{\_ e \phi}{\ap{\phi}{e}})}\ }
\end{align*}

The handler differs from the original $\TTDL$ only in the $\eta$ clause,
which substitutes $\top$ for the returned proposition $p$ in
$\lam{e \phi}{p \land \ap{\phi}{e}}$.

We can use computations of type $\FF_{E_\DRT}(1)$ as our type of dynamic
(i.e.\ effectful) propositions. We can embed simple propositions using
$\op{assert}!$, which has type $o \to \FF_{E_\DRT}(1)$. We can perform
conjunction by chaining two computations,
$M \hsbind (\lam{\_}{N}) : \FF_{E_\DRT}(1)$ for $M, N :
\FF_{E_\DRT}(1)$. We can modify $\BOX$ the same way we modified
$\TTDL$. Negation will be the same as before, with $\eta$ being replaced
with $\op{assert}!$.

\begin{align*}
  \BOX :\ &\FF_{E_\DRT}(1) \to \gamma \to o \\
  \BOX = \bbanana{\ 
  &\onto{\op{get}}{(\lam{\_ k e}{\app{k}{e}{e}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k e}{\exists x.\ \app{k}{x}{(x \cons e)}})}, \\
  &\onto{\op{assert}}{(\lam{p k e}{p \land \app{k}{\star}{(p \cons e)}})}, \\
  &\onto{\eta}{(\lam{\_ e}{\top})}\ }
\end{align*}

$$
\dnot A = \app{\op{get}}{\star}{(\lam{e}{\ap{\op{assert}!}{(\lnot (\app{\BOX}{A}{e}))}})}
$$

In the lexical entries derived from the construction rules, not much will
have to change. We will only see a difference in the lexical entry
$\abs{trans}$ that we have introduced for the $\crlitv$ rule for transitive
verbs (which was extrapolated from the DRT treatment
in~\cite{kamp1993discourse}). Instead of returning the proposition as the
result of evaluating the sentence, we add it as a condition using
$\op{assert}!$, which is actually what the DRS construction algorithm ends
up doing.

\begin{align*}
\abs{trans} &: V \limp NP \limp NP \limp S \\
\sem{\abs{trans}} &= \lam{\alpha Y X}{(\alpha \apr X \aplr Y) \hsbind \op{assert}!}
\end{align*}

This means that we can build up our dynamic semantics using computations
that do not return anything, only modify the context using side
effects. This is very much in the spirit of dynamic semantics: meaning is
context change potential.

If we look closer at TTDL, we can see that the same strategy is applied
there. Let $S$ be the state monad which maps the type $\alpha$ to the type
$\gamma \to (\alpha \times \gamma)$. This is the monad that underlies
state, such as the storing and retrieving of discourse referents. Its
corresponding monad transformer $S(F)$ maps the type $\alpha$ to the type
$\gamma \to F(\alpha \times \gamma)$. Let $C$ be the continuation monad
which maps the type $\alpha$ to the type $(\alpha \to o) \to o$. By
applying the $S$ monad transformer to the $C$ monad, we get a monad $S(C)$
that maps the type $\alpha$ to the type
$\gamma \to (\alpha \times \gamma \to o) \to o$. This monad characterizes
computations that have read/write access to some state of type $\gamma$ and
can manipulate their continuation of type $o$. If we look at such
computations of return type $1$, we get a computation type
$\gamma \to (1 \times \gamma \to o) \to o$. By the isomorphism between
$1 \times \gamma$ and $\gamma$, this is the same as
$\gamma \to (\gamma \to o) \to o$, which is the type $\Omega$ of dynamic
propositions in TTDL.\@ The correspondence is not a shallow coincidence of
types, but many of the terms of TTDL can be generated using the $\eta$ and
$\hsbind$ of this monad.

The switch from $\FF_E(o)$ to $\FF_{E \uplus DRT}(1)$ is very much like the
one from $\FF_E((\iota \to o) \to o)$ to
$\FF_{E \uplus \op{scope}}(\iota)$: we found a way to encode
quantifiers/truth conditions as side effects and so we move the extra
structure from the return type to the effect signature. The choice between
the two is rather arbitrary. Keeping $o$ as the return type for
computations that interpret sentences is more consistent with what we have
been doing in Chapter~\ref{chap:introducing-effects}. On the other hand,
using $1$ as the return type:

\begin{itemize}
\item is more uniform by not admitting both $\etaE{A}$ and
  $\ap{\op{assert}!}{A}$
\item which leads to nicer canonical representations and equational theory
  in~\ref{ssec:algebraic-drt}
\item in order to correctly treat the cancellation of presuppositions
  in~\ref{sec:presuppositions}, we will need to add the truth-conditions
  generated by verbs into the context using something like $\op{assert}$
  anyway
\end{itemize}

For the remainder of this chapter, we will use the encoding that models
sentences as computations of return type $1$.


\subsection{Algebraic Considerations}
\label{ssec:algebraic-drt}

Now that we have handlers for our computations, we can study which
computations share the same interpretations and try to derive some
equational theory over them.

We will first start by looking at how $\op{get}$ behaves w.r.t.\ itself and
the other operations.

\begin{align*}
   \app{\op{get}}{\star}{(\lam{e}{\app{\op{get}}{\star}{(\lam{e'}{M(e, e')})}})}
&= \app{\op{get}}{\star}{(\lam{e}{M(e, e)})} \\
   M
&= \app{\op{get}}{\star}{(\lam{e}{M})}
\end{align*}

As with the $\op{speaker}$ getter from~\ref{sec:deixis}, we get two laws
telling us that asking for the context is idempotent (first equation) and
that it has no other bearing on the result of the computation (second
equation).

Since we know how $\op{assert}$ and $\op{introduce}$ modify the context, we
can reorder $\op{get}$ w.r.t.\ these two operations:

\begin{align*}
   \app{\op{assert}}{A}{(\lam{u}{\app{\op{get}}{\star}{(\lam{e}{M(u, e)})}})}
&= \app{\op{get}}{\star}{(\lam{e}{\app{\op{assert}}{A}{(\lam{u}{M(u, A \cons e)})}})} \\
   \app{\op{introduce}}{\star}{(\lam{x}{\app{\op{get}}{\star}{(\lam{e}{M(x, e)})}})}
&= \app{\op{get}}{\star}{(\lam{e}{\app{\op{introduce}}{\star}{(\lam{x}{M(x, x \cons e)})}})} \\
\end{align*}

This means we can assume that every computation of type $\FF_{E_\DRT}(1)$
uses $\op{get}$ exactly once and does so at the very beginning, i.e.\ it is
of the form $\app{\op{get}}{\star}{(\lam{e}{M(e)})}$ where
$M(e) : \FF_{\{\op{implicate}, \op{assert}\}}(1)$\footnote{When writing
  effect signatures in subscripts, we will often omit the types of
  operations, which are presumed to be constant.}.

If we assume that relative order of discourse referents and conditions is
not important (i.e.\ they are both separate parts, as in a DRS),
$x \cons p \cons e = p \cons x \cons e$ for $x : \iota$, $p : o$ and
$e : \gamma$, then we get the following equation:

$$
  \app{\op{assert}}{A}{(\lam{u}{\app{\op{introduce}}{\star}{(\lam{x}{M(u, x)})}})} 
= \app{\op{introduce}}{\star}{(\lam{x}{\app{\op{assert}}{A}{(\lam{u}{M(u, x)})}})}
$$

This will allows us to move $\op{introduce}$ operations above $\op{assert}$
operations so that we can have the following canonical representation for
computations of type $\FF_{E_\DRT}(1)$:

\begin{align*}
  &\app{\op{get}}{\star}{(\lam{e}{ \\
  &\app{\op{introduce}}{\star}{(\lam{x_1}{ \\
  &\qquad \cdots \\
  &\app{\op{introduce}}{\star}{(\lam{x_n}{ \\
  &\app{\op{assert}}{c_1}{(\lam{\_}{ \\
  &\qquad \cdots \\
  &\app{\op{assert}}{c_m}{(\lam{\_}{ \\
  &\etaE{\star}})}})}})}})}})}
\end{align*}

In other words, the computation examines its context $e$ and then produces
the DRS:

\vspace{2mm}

\drs{$x_1$\ \ldots\ $x_n$}{$c_1$ \\ $\cdots$ \\ $c_m$}

\vspace{2mm}

Note that as in TTDL, discourse referents correspond to $\lambda$-binders
in $\banana{\lambda}$ and their standard notion of $\alpha$-equivalence
gives rise to $\alpha$-equivalence for our representations.

If we were to further assume that the order in contexts does not matter at
all (i.e.\ the discourse referents and conditions form sets, as in a DRS),
$x \cons y \cons e = y \cons x \cons e$ and
$p \cons q \cons e = q \cons p \cons e$ for $x, y : \iota$, $p, q : o$ and
$e : \gamma$, then we get the following:

\begin{align*}
   \app{\op{assert}}{A}{(\lam{u_1}{\app{\op{assert}}{B}{(\lam{u_2}{M(u_1, u_2)})}})} 
&= \app{\op{assert}}{B}{(\lam{u_2}{\app{\op{assert}}{A}{(\lam{u_1}{M(u_1, u_2)})}})} \\
   \app{\op{introduce}}{\star}{(\lam{x}{\app{\op{introduce}}{\star}{(\lam{y}{M(x, y)})}})} 
&= \app{\op{introduce}}{\star}{(\lam{y}{\app{\op{introduce}}{\star}{(\lam{x}{M(x, y)})}})}
\end{align*}

Since the discourse referents and conditions are (unordered) sets in the
presentation in~\cite{kamp1993discourse}, this would make our
representation closer to DRSs.

Finally, if we assume that the conditions in a context can be seen as a big
conjunction, $p \cons q \cons e = (p \land q) \cons e$ for $p, q : o$ and
$e : \gamma$, then we admit the following equations:

$$
  \app{\op{assert}}{A}{(\lam{u}{\app{\op{assert}}{B}{(\lam{u'}{M(u, u')})}})} 
= \app{\op{assert}}{(A \land B)}{(\lam{u}{M(u, u)})}
$$

which gives us a simpler canonical representation:

\begin{align*}
  &\app{\op{get}}{\star}{(\lam{e}{ \\
  &\app{\op{introduce}}{\star}{(\lam{x_1}{ \\
  &\qquad \cdots \\
  &\app{\op{introduce}}{\star}{(\lam{x_n}{ \\
  &\app{\op{assert}}{p}{(\lam{\_}{ \\
  &\etaE{\star}})}})}})}})}
\end{align*}

This boils down a computation of type $\FF_{E_\DRT}(1)$ into a proposition
$p$ that depends on some context $e$ and introduces the new discourse
referents $x_1$, \ldots, $x_n$.


\section{Presuppositions}
\label{sec:presuppositions}

In our $\banana{\lambda}$ analysis of anaphora, we have completely omitted
proper nouns, even though they are treated by DRT
in~\cite{kamp1993discourse} and feature in
Example~\ref{ex:jones-porsche}. This is due to the fact that proper nouns
trigger presuppositions: \emph{Jones sleeps} presupposes that there is some
(contextually salient) entity named Jones. These presuppositions project
outside of entailment-cancelling operators such as negation, outside of the
DRSs in which they are contained.

\begin{exe}
  \ex \label{ex:jones-mercedes} It is not the case that Jones owns a
  Porsche. He owns a Mercedes.
\end{exe}

In Example~\ref{ex:jones-mercedes}, the proper noun \emph{Jones}
contributes a discourse referent which is then picked up in the second
sentence. This would be impossible to achieve using $\op{introduce}$, since
that would contribute the referent only to the DRS ($\BOX$) that is being
negated and the discourse referent would not reach the second sentence.

\begin{figure}
\centering
\crpnbox
\caption{\label{fig:crpn} $\crpn$: The construction rule for proper nouns.}
\end{figure}

If we look at the construction rule for proper nouns in DRT, $\crpn$,
displayed on Figure~\ref{fig:crpn}, we will see that the discourse referent
and the condition describing it are being inserted into the main DRS and
not into the DRS $K$, in which the condition being reduced appears.

In TTDL, this issue was resolved by adding exceptions into the lambda
calculus used for the semantic terms~\cite{lebedeva2012expression}. The
lexical entry for a presuppositional trigger such as a proper noun or a
definite description throws an exception,
$(\texttt{AbsentIndividualExc}\ P)$. This exception carries the predicate
$P$ that describes the entity that is presupposed to exist. At the top
level, a handler catches these exceptions and accommodates these
presuppositions. We have seen that in $\banana{\lambda}$, dynamic
propositions are modelled as computations and these computations already
have a notion of throwing exceptions (effects) and handling them
(handlers). We will introduce an operation named $\op{presuppose}$. Its
input type will be $\iota \to o$, a predicate that describes the entity
whose existence is presupposed. The output type will be $\iota$, the
presupposed entity satisfying the predicate.

$$
\typedop{presuppose}{(\iota \to o)}{\iota}
$$

The type of this operation is not exactly equivalent to the exception
$\texttt{AbsentIndividualExc}$ from~\cite{lebedeva2012expression}. As we
have seen in Chapter~\ref{ssec:expressions-as-computations}, exceptions are
effects that have the impossible output type $0$, which means that no
handler will be able to resume the computation by using the
continuation. In Lebedeva's approach, when the toplevel handler intercepts
the exception, it accommodates the presupposition, rewinds the dynamic
state and evaluates the sentence again, this time with a context which now
contains the presupposed entity. This is not suitable to our approach
because of two reasons:

\begin{itemize}
\item We will deal with many other effects besides dynamic state and
  rewinding all of their effects in order to evaluate the sentence again in
  a new context would be needlessly complex.
\item This approach over-generates by licencing the reading ``He$_1$ loves
  John's$_1$ car''. When evaluating \emph{John}, the existence of John is
  presupposed and the sentence is evaluated again, in a context in which
  John is accessible. However, this will allow the pronoun in subject
  position to resolve to John and end up being bound by the object.
\end{itemize}

The effects in $\banana{\lambda}$ differ from traditional exceptions in
that they are resumable. Besides having the input type (which is the
message type of a traditional exception), they also have an output
type. Handlers can then resume computation at the point of the effect by
calling the continuation with a value of the output type. We make full use
of this in our treatment of presuppositions by using $\iota$ as the output
type of $\op{presuppose}$. This way, we do not have to abort the evaluation
of the sentence, rewind all of the effects and evaluate it again; we return
the presupposed entity immediately and the evaluation of the sentence
continues. This strategy also avoid the over-generation mentioned above, in
which a presupposition trigger binds a pronoun preceding it.

We have shown have the $\op{presuppose}$ operation can be motivated on the
grounds of the analysis done by Lebedeva
in~\cite{lebedeva2012expression}. We can also look at how it ties to the
DRT construction rule for presupposition triggers such as $\crpn$. When
translating construction rules into computations, we have implemented the
\textbf{Introduce in $\universe_K$} command as the $\op{introduce}$
operation and the \textbf{Introduce in $\conditions_K$} as the
$\op{assert}$ operation. We might therefore proceed the same way and
translate the \textbf{Introduce into the universe of the main DRS} command
as some operation $\typedop{introduce\_main}{\star}{\iota}$ and
\textbf{Introduce into the condition set of the main DRS} command as
$\typedop{assert\_main}{o}{1}$. However, by looking at the construction
rules of presupposition triggers, we see that they tend to use the two
operations in tandem: first introduce a new discourse referent and then
some condition(s) describing it. Therefore, we can fuse the two into a
single operation $\typedop{presuppose}{(\iota \to o)}{\iota}$, which
introduces and outputs a new discourse referent $x$ while at the same it
introduces the condition $P(x)$, where $P$ is its argument.

Besides lowering the number of basic operations that we have to introduce,
this also has an advantage when we start to consider ambiguous ways of
accommodating presuppositions
(\ref{ssec:presupposition-ambiguities}). Suppose we have two operations,
$\op{introduce\_somewhere}$ and $\op{assert\_somewhere}$, that let us
introduce discourse referents and conditions into arbitrary DRSs on the
projection line\footnote{A \emph{projection line} is a path in the
  accessibility tree from a sub-DRS to the root of the
  tree~\cite{van1992presupposition}.}. We might then end up accommodating
the discourse referent and the condition in different DRS, yielding an
undesired meaning. If we package the two operations into a single
$\op{presuppose\_somewhere}$, then we do not have this problem.


\subsection{Revising the Dynamic Handler}
\label{ssec:revising-dynamic-handler}

We will want to introduce the $\op{presuppose}$ operation into our dynamic
semantics in such a way that $\op{presuppose}$ projects outside of boxes
(DRSs, applications of the $\BOX$ handler). This means that applying the
$\BOX$ handler to a computation should yield a computation free of
$\op{get}$, $\op{introduce}$ and $\op{assert}$ but still possibly using
$\op{presuppose}$: $\BOX$ will be an open handler for $\op{get}$,
$\op{introduce}$ and $\op{assert}$. The open handler will be more complex,
since where before we had continuations which returned simple propositions,
or rather functions from contexts to propositions, we will now have
continuations which return computations.

\begin{align*}
  \BOX :\ &\FF_{E_\DRT}(1) \to \gamma \to o \\
  \BOX = \bbanana{\ 
  &\onto{\op{get}}{(\lam{\_ k e}{\app{k}{e}{e}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k e}{\exists x.\ \app{k}{x}{(x \cons e)}})}, \\
  &\onto{\op{assert}}{(\lam{p k e}{p \land \app{k}{\star}{(p \cons e)}})}, \\
  &\onto{\eta}{(\lam{\_ e}{\top})}\ } \\
  \\
  \BOX :\ &\FF_{E \uplus E_\DRT}(1) \to \gamma \to \FF_E(o) \\
  \BOX = \lam{A e}{(\ap{\banana{\ 
  &\onto{\op{get}}{(\lam{\_ k}{\etaE{(\lam{e}{\ap{k}{e} \apll e})}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k}{\etaE{(\lam{e}{\exists \apr (\ap{\CC}{(\lam{x}{\ap{k}{x} \apll (x \cons e)})})})}})}, \\
  &\onto{\op{assert}}{(\lam{p k}{\etaE{(\lam{e}{p \andr (\ap{k}{\star} \apll (p \cons e))})}})}, \\
  &\onto{\eta}{(\lam{\_}{\etaE{(\lam{e}{\top})}})}\ }}{A}) \apll e} \\
  \\
  \_ \apll \_ &: \FF_E(\alpha \to \FF_E(\beta)) \to \alpha \to \FF_E(\beta) \\
  F \apll x &= F \hsbind (\lam{f}{\ap{f}{x}})
\end{align*}

We include the closed $\BOX$ handler for comparison. At the heart of the
open $\BOX$ handler, we have a $\banana{}$ of type $\FF_{E \uplus
  E_\DRT}(1) \to \FF_E(\gamma \to \FF_E(o))$. This $\banana{}$ differs from
the closed $\bbanana{}$ in the following ways:

\begin{itemize}
\item Since the interpretations are no longer functions (type
  $\gamma \to o$), but computations that produce functions (type
  $\FF_E(\gamma \to \FF_E(o))$), we start all the clauses with
  $\etaE{(\lam{e}{\ldots})}$ instead of $\lam{e}{\ldots}$
\item When we apply the continuation $k$ to the output (the context $e$ in
  $\op{get}$, the referent $x$ in $\op{introduce}$ and the trivial $\star$
  in $\op{assert}$), we now get a computation (type
  $\FF_E(\gamma \to \FF_E(o))$) instead of a function (type
  $\gamma \to o$). We need to first evaluate the computation to get a
  function and then apply that function to the new context. For that
  purpose, we define the $\apll$ combinator below.
\item The proposition that is the result of applying the continuation to
  the output and to the new context is now a computation (type $\FF_E(o)$)
  instead of a simple proposition (type $o$). In the $\op{assert}$ clause,
  if we want to conjoin a proposition $p$ to this proposition, we need to
  use the $\andr$ operator, which takes a computation as its right
  argument. In the $\op{introduce}$ clause, we have an impure predicate
  $\lam{x}{\ap{k}{x} \apll (x \cons e)}$ of type $\iota \to \FF_E(o)$. We
  use $\CC$ to push the effects out and get a computation that returns a
  pure predicate, type $\FF_E(\iota \to o)$. We can then apply the
  existential quantifier under the $\FF_E$ type wrapper using $\apr$.
\end{itemize}

After having interpreted the $A : \FF_{E \uplus E_\DRT}(1)$ using the
$\banana{}$, we get a computation of type $\FF_E(\gamma \to \FF_E(o))$. In
order to apply it to an $e : \gamma$, we use the $\apll$ combinator one
last time.

The handler above is much more complicated than any we have seen so far in
this manuscript. However, note that:

\begin{itemize}
\item The translation from the closed $\BOX$ handler was mechanical. The
  open $\BOX$ handler does not include any ad hoc features built in to make
  it compatible with presuppositions.
\item The cost of replacing the simpler closed handler with the open
  handler is a price we would have to pay anyway if we wanted to use this
  handler in a setting that involved other effects (such as quantification,
  deixis, conventional implicature); it is not limited to adding support
  for presuppositions. E.g., in Chapter~\ref{chap:composing-effects}, we
  will deal almost exclusively with open handlers.
\item The $\BOX$ handlers are by far the largest handlers in our
  analyses. Furthermore, open handlers that thread some mutable state
  throughout the computation are slightly awkward to write (as testified by
  all the uses of $\apll$) in pure languages without using some syntactic
  sugar, such as parameterized handlers that can automatically thread some
  parameter from operation to operation as
  in~\cite{kammar2013handlers,kiselyov2015freer}.
\end{itemize}

The open $\BOX$ handler outputs computations of propositions instead of
simple propositions, which is something we have to take into account when
using it in, e.g., negation:

$$
\dnot A = \app{\op{get}}{\star}{(\lam{e}{\app{\BOX}{A}{e} \hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}})})}
$$

Now that we have an open version of the $\BOX$ handler, there is one change
that we will make in how it actually functions. We will motivate it by the
following example.

\begin{exe}
  \ex \label{ex:not-john-car} It is not the case that John$_1$ likes his$_1$ car.
\end{exe}

The negation will use $\op{get}$ to retrieve the current context $e$ and
then proceed by evaluating the expression
$(\app{\BOX}{\sem{\text{John likes his car}}}{e})$. The proper noun
\emph{John} will then use $\op{presuppose}$, which will project out of the
$\BOX$ and introduce John into some superordinate context. But now we have
to evaluate the pronoun \emph{his} in the context $e$ which was untouched
by \emph{John} and we will thus fail to retrieve John and get the expected
reading. The problem is in our definition of $\dnot A$. We want anaphoric
expressions within $A$ to have access to referents introduced outside of
$A$. We do this by using $\op{get}$ to recover the context $e$ in which we
are about to evaluate $\dnot A$ and then use that context as the initial
context when interpreting anaphora in $A$ with $\app{\BOX}{A}{e}$. While
this works well for TTDL, in which dynamic propositions have no way to
modify contexts other contexts than the local one, it breaks when we allow
$\op{presuppose}$ to modify the top context.

The solution is to dismiss the assumption that surrounding contexts are
immune to change. Whenever we handle a $\op{get}$, we use another
$\op{get}$ to gather the current state of the surrounding context and then
combine that with the local context. This solution will actually simplify
the definition of $\dnot$ and the type of $\BOX$, since $\BOX$ does not
need to be seeded with its surrounding context but retrieves it itself when
necessary. Furthermore, note that this solution was not available to us
before we made the handler open, since it interprets computations in
$\FF_{E_\DRT}(1)$ into computations in $\FF_{\{\op{get}\}}(o)$.

\begin{align*}
  \BOX :\ &\FF_{E \uplus E_\DRT}(1) \to \FF_{E \uplus \{\op{get}\}}(o) \\
  \BOX = \lam{A}{(\ap{\banana{\ 
  &\onto{\op{get}}{(\lam{\_ k}{\etaE{(\lam{e}{\app{\op{get}}{\star}{(\lam{e'}{\ap{k}{(e \cat e')} \apll e})}})}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k}{\etaE{(\lam{e}{\exists \apr (\ap{\CC}{(\lam{x}{\ap{k}{x} \apll (x \cons e)})})})}})}, \\
  &\onto{\op{assert}}{(\lam{p k}{\etaE{(\lam{e}{p \andr (\ap{k}{\star} \apll (p \cons e))})}})}, \\
  &\onto{\eta}{(\lam{\_}{\etaE{(\lam{e}{\top})}})}\ }}{A}) \apll \nil}
\end{align*}

The $\op{get}$ now uses another $\op{get}$ to retrieve the current
surrounding $e'$ which is then combined with the local context $e$ as the
answer to the original $\op{get}$. In order to combine the two contexts, we
assume that there is some operation
$(\cat) : \gamma \to \gamma \to \gamma$. If contexts are (pairs of) lists,
then this operation would be (pointwise) list concatenation. Since we
always ask again for the surrounding context, we do not need the
surrounding context as an argument to $\BOX$. Instead, we pass in $\nil$ as
the initial local context, where $\nil : \gamma$ is a constant representing
the empty context, e.g.\ an empty list.

As we no longer need to supply the initial surrounding context, dynamic
negation becomes simpler:

$$
\dnot A = \ap{\BOX}{A} \hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}})
$$


\subsection{Presupposition in Action}
\label{ssec:presupposition-in-action}

With $\op{presuppose}$ in place, we can now translate the DRT construction
rule for proper nouns, $\crpn$, into $\banana{\lambda}$:

\vspace{6mm}

\hspace{-1cm}
\begin{minipage}{0.69\textwidth}
\crpnbox
\end{minipage}
\begin{minipage}{0.31\textwidth}
\vspace{-4mm}
\begin{align*}
\abs{proper} &: PN \limp NP \\
\sem{PN} &= \iota \to o \\
\sem{NP} &= \FF_E(\iota)
\end{align*}
\vspace{2mm}
\begin{align*}
  \sem{\abs{proper}} =
  \lam{\alpha}{&\app{\op{presuppose}}{&(\lam{u}{ \\
               \\
               &\alpha(u)})}{&(\lam{u}{ \\
               \\ \\
               & \ap{\eta}{u}})}}
\end{align*}
\end{minipage}

\vspace{6mm}

We map the introduction of a discourse referent and a condition into the
main DRS into the $\op{presuppose}$ operation. As with the lexical
insertion rules for common nouns and transitive verbs, this rule is
parameterized by a lexical item, this time a proper noun. In DRT, proper
nouns are described using predicates and so we introduce an abstract atomic
type $PN$ for proper nouns whose interpretation $\sem{PN}$ is the type of
predicates. The definition of $\abs{proper}$ above is expanded in order to
parallel the construction. We can actually make it a lot shorter:

\begin{align*}
  \sem{\abs{proper}}
  &= \lam{\alpha}{\app{\op{presuppose}}{(\lam{u}{\alpha(u)})}{(\lam{u}{\ap{\eta}{u}})}} \\
  &= \lam{\alpha}{\app{\op{presuppose}}{\alpha}{(\lam{u}{\ap{\eta}{u}})}} \\
  &= \lam{\alpha}{\ap{\op{presuppose}!}{\alpha}} \\
  &= \op{presuppose}!
\end{align*}

We will also need a handler to give a meaning to the $\op{presuppose}$
operation. The meaning behind is $\op{presuppose}$ is clear: it will
introduce a discourse referent and a condition.

\begin{align*}
  \accommodate &: \FF_{E \uplus \{\op{presuppose}\}}(\alpha) \to \FF_E(\alpha) \\
  \accommodate &= \banana{\onto{\op{presuppose}}{(\lam{P k}{\app{\op{introduce}}{\star}{(\lam{x}{\app{\op{assert}}{(\ap{P}{x})}{(\lam{\_}{\ap{k}{x}})}})}})}}
\end{align*}

The accommodate handler turns presupposed content into asserted
content. The place we want to do that is usually on the level of the
topmost DRS.\@ We can define a combinator which corresponds to the idea of
a top DRS.

\begin{align*}
  \TOP &: \FF_{E \uplus E_\DRT \uplus \{\op{presuppose}\}}(1) \to \FF_{E \uplus \{\op{get}\}}(o) \\
  \TOP &= \BOX \circ \accommodate
\end{align*}

We can now deal with Example~\ref{ex:jones-mercedes}. We start by computing
the denotation of the first sentence.

\begin{align*}
  \sem{S_1} =
     &\ \sem{\appp{\abs{trans}}{\abs{owns}}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{Porsche}})})}{(\ap{\abs{proper}}{\abs{Jones}})}} \\
\tto &\ \app{\op{presuppose}}{\obj{Jones}}{(\lam{x}{ \\
     &\ \app{\op{introduce}}{\star}{(\lam{y}{ \\
     &\ \app{\op{assert}}{(\obj{Porsche}(y))}{(\lam{\_}{ \\
     &\ \app{\op{assert}}{(\obj{own}(x, y))}{(\lam{\_}{ \\
     &\ \etaE{\star}})}})}})}})}
\end{align*}

Wrapping a dynamic negation over this will resolve all the $\op{introduce}$
and $\op{assert}$ operations but the $\op{presuppose}$ will prevail.

\begin{align*}
&\dnot\ \sem{S_1} \\
\tto &\ \ap{\BOX}{\sem{S_1}} \hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}})\\
\tto &\ \app{\op{presuppose}}{\obj{Jones}}{(\lam{x}{ \\
     &\ \etaE{(\exists y.\ \obj{Porsche}(y) \land \obj{own}(x, y))}})} \hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}}) \\
\tto &\ \app{\op{presuppose}}{\obj{Jones}}{(\lam{x}{ \\
     &\ \app{\op{assert}}{(\lnot (\exists y.\ \obj{Porsche}(y) \land \obj{own}(x, y)))}{(\lam{\_}{ \\
     &\ \etaE{\star}})}})}
\end{align*}

We now turn to the second sentence in Example~\ref{ex:jones-mercedes},
whose meaning is derived below.

\begin{align*}
  \sem{S_2} =
     &\ \sem{\appp{\abs{trans}}{\abs{owns}}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{Mercedes}})})}{\abs{he}}} \\
\tto &\ \app{\op{get}}{}{(\lam{e}{ \\
     &\ \app{\op{introduce}}{\star}{(\lam{y}{ \\
     &\ \app{\op{assert}}{(\obj{Mercedes}(y))}{(\lam{\_}{ \\
     &\ \app{\op{assert}}{(\obj{own}(\sel(e), y))}{(\lam{\_}{ \\
     &\ \etaE{\star}})}})}})}})}
\end{align*}

Dynamic propositions of type $\FF_{E_\DRT}(1)$ are conjoined by chaining
their computations. By chaining the two computations, we get a meaning for
the whole discourse in Example~\ref{ex:jones-mercedes}.

\begin{align*}
  \sem{\text{not $S_1$. $S_2$}} = &\ (\dnot\ \sem{S_1}) \hsbind (\lam{\_}{\sem{S_2}}) \\
\tto &\ \app{\op{presuppose}}{\obj{Jones}}{(\lam{x}{ \\
     &\ \app{\op{assert}}{(\lnot (\exists y.\ \obj{Porsche}(y) \land \obj{own}(x, y)))}{(\lam{\_}{ \\
     &\ \app{\op{get}}{}{(\lam{e}{ \\
     &\ \app{\op{introduce}}{\star}{(\lam{y}{ \\
     &\ \app{\op{assert}}{(\obj{Mercedes}(y))}{(\lam{\_}{ \\
     &\ \app{\op{assert}}{(\obj{own}(\sel(e), y))}{(\lam{\_}{ \\
     &\ \etaE{\star}})}})}})}})}})}})}
\end{align*}

We can now embed this in the top-level box.

\begin{align*}
  \ap{\TOP}{\sem{\text{not $S_1$. $S_2$}}} = &\ \ap{\BOX}{(\ap{\accommodate}{\sem{\text{not $S_1$. $S_2$}}})} \\
\tto \ap{\BOX}{(
     &\ \app{\op{introduce}}{\star}{(\lam{x}{ \\
     &\ \app{\op{assert}}{(\obj{Jones}(x))}{(\lam{\_}{ \\
     &\ \app{\op{assert}}{(\lnot (\exists y.\ \obj{Porsche}(y) \land \obj{own}(x, y)))}{(\lam{\_}{ \\
     &\ \app{\op{get}}{}{(\lam{e}{ \\
     &\ \app{\op{introduce}}{\star}{(\lam{y}{ \\
     &\ \app{\op{assert}}{(\obj{Mercedes}(y))}{(\lam{\_}{ \\
     &\ \app{\op{assert}}{(\obj{own}(\sel(e), y))}{(\lam{\_}{ \\
     &\ \etaE{\star}})}})}})}})}})}})}})}\ )} \\
\tto &\ \app{\op{get}}{\star}{(\lam{e}{ \\
     &\ \etaE{(\exists x.\
          \obj{Jones}(x) \land
          \lnot (\exists y.\ \obj{Porsche}(y) \land \obj{own}(x, y)) \land
          (\exists y.\ \obj{Mercedes}(y) \land \obj{own}(\sel(e'), y)))}})}
\end{align*}

where

$$
e' = \lnot (\exists y.\ \obj{Porsche}(y) \land \obj{own}(x, y)) \cons
     \obj{Jones}(x) \cons x \cons e
$$

By assuming that $x$ is \emph{the} salient antecedent for the pronoun or by
evaluating in the empty context $\nil$, we get the intended reading.

\begin{align*}
  &\ap{\banana{\onto{\op{get}}{(\lam{\_ k}{\ap{k}{\nil}})}}}{(\ap{\TOP}{\sem{\text{not $S_1$. $S_2$}}})} \\
  &\tto \etaE{(\exists x.\
          \obj{Jones}(x) \land
          \lnot (\exists y.\ \obj{Porsche}(y) \land \obj{own}(x, y)) \land
          (\exists y.\ \obj{Mercedes}(y) \land \obj{own}(x, y)))}
\end{align*}


\subsection{Cancelling Presuppositions}
\label{ssec:cancelling-presuppositions}

It has been observed that not every presupposition projects.


\subsection{Presupposition Ambiguities}
\label{ssec:presupposition-ambiguities}




\section{Double Negation}
\label{sec:double-negation}

