\chapter{Dynamic Semantics in \texorpdfstring{$\banana{\lambda}$}{Our Calculus}}
\label{chap:dynamic-semantics}

We will now examine dynamic semantics. We will consider two theories of
dynamics in natural language: Kamp's DRT~\cite{kamp1993discourse} and de
Groote's TTDL~\cite{de2006towards,lebedeva2012expression}. We will build a
$\banana{\lambda}$ analysis of dynamics and link it to both theories, as a
side effect showing how DRT links to TTDL.\@ The analysis we will present
can be motivated on the grounds of either DRT or TTDL.\@ We can look at the
monad at the core of TTDL and devise operations that let us perform
interesting things within the monad (quantifying over the discourse and
modifying the discourse state). While this is the process that we have
followed to discover this analysis (presented
in~\cite{marsik2014algebraic}), we will follow a novel strategy in this
exposition. We will start with DRT, more specifically its presentation in
Kamp and Reyle's canonical textbook~\cite{kamp1993discourse}, and show how
to translate it into $\banana{\lambda}$ computations
(Section~\ref{sec:banana-drt}). We will then interpret those computations
as TTDL dynamic propositions.

Afterwards, we will have our first taste of combining different effects. We
will enhance our theory of dynamics with a treatment of presuppositions
covering projection, cancellation and accommodation. Our analysis will be
based on Lebedeva's extension of TTDL~\cite{lebedeva2012expression}, which
uses exceptions and exception handlers to handle presupposition projection
and accommodation. We will see a variation of this approach in terms of
effects and handlers (Section~\ref{sec:presuppositions}).

Finally, we consider one more extension of TTDL, Qian's double-negation
TTDL. This will be an example of a negative result. We will see why and how
Qian's DN-TTDL evades an analysis in $\calc$
(Section~\ref{sec:double-negation}).

\minitoc


\section{DRT as a Programming Language}
\label{sec:drt-as-pl}

We will argue that the construction rules for DRSs as presented
in~\cite{kamp1993discourse} can be seen as an operational semantics for a
programming language. Once we will have established that DRT is a
programming language, we will use techniques similar to those in
Chapter~\ref{chap:continuations} to embed this language in
$\banana{\lambda}$.

\vspace{6mm}

\doublebox{
\parbox{0.64\textwidth}{
  \underline{\textbf{DRS-Construction Algorithm}}

  \textbf{Input:}
  \begin{tabular}{l}
    discourse $D = S_1, \ldots, S_i, S_{i+1}, \ldots, S_n$ \\
    the empty DRS $K_0$
  \end{tabular}
  
  \vspace{2mm}
  \textbf{Keep repeating for $i = 1, \ldots, n$:}

  \begin{enumerate}[(i)]
  \item\label{item:drs-alg-step1} add the syntactic analysis $[S_i]$ of
    (the next) sentence $S_i$ to the conditions of $K_{i-1}$; call this DRS
    $K_i^*$. Go to~(\ref{item:drs-alg-step2}).

  \item\label{item:drs-alg-step2} Input: a set of reducible conditions of $K_i^*$

    Keep on applying construction principles to each reducible condition of
    $K_i^*$ until a DRS $K_i$ is obtained that only contains irreducible
    conditions. Go to~(\ref{item:drs-alg-step1}).
  \end{enumerate}
}
}

\vspace{6mm}

In~\ref{ssec:drt-drss}, we have said that the conditions of a DRS are
atomic formulas of predicate logic: predicates applied to variables or
constants. However, during DRS construction, this notion is expanded. The
atomic predicates described above are called \emph{irreducible
  conditions}. Along with them, we will also have syntactic trees as
conditions. Furthermore, these syntactic trees might contain discourse
referents.

We will look at DRS construction for an example
from~\cite{kamp1993discourse} (Example~(1.28), Section~1.1.3):

\begin{exe}
  \exr{ex:jones-porsche} Jones owns a Porsche. It fascinates him.
\end{exe}

\begin{center}
\begin{tabular}{rcccl}
\drs{\hspace{1cm}}
{
\begin{tikzpicture}
  \Tree [.S [.NP [.PN Jones ] ]
            [.VP$'$ [.VP [.V owns ]
                         [.NP [.DET a ]
                              [.N Porsche ] ] ] ] ]
\end{tikzpicture}
}
& $\to_\crpn$
& \drs{$\drx$}
{
$\ap{\obj{Jones}}{\drx}$ \\
\begin{tikzpicture}
  \Tree [.S $\drx$
            [.VP$'$ [.VP [.V owns ]
                         [.NP [.DET a ]
                              [.N Porsche ] ] ] ] ]
\end{tikzpicture}
}
& $\to_\crid$
& \drs{$\drx$ $\dry$}
{
$\ap{\obj{Jones}}{\drx}$ \\
\begin{tikzpicture}
  \Tree [.N($\dry$) Porsche ]
\end{tikzpicture} \\
\begin{tikzpicture}
  \Tree [.S $\drx$
            [.VP$'$ [.VP [.V owns ]
                         $\dry$ ] ] ]
\end{tikzpicture}
}
\end{tabular}
\end{center}

We insert the syntactic analysis of the first sentence into the empty
DRS.\@ Then there is a reduction rule which replaces the NP \emph{Jones}
with a discourse referent $\drx$ while at the same time introducing the
discourse referent $\drx$ and the condition $\ap{\obj{Jones}}{\drx}$ into
the DRS.\@ In the next DRS, we evaluate the object by replacing it with
$\dry$ and adding the discourse referent $\dry$ and a condition in which
(the meaning of) the noun \emph{Porsche} is applied to $\dry$.

\begin{center}
\begin{tabular}{rcccccl}
\drs{$\drx$ $\dry$}
{
$\ap{\obj{Jones}}{\drx}$ \\
\begin{tikzpicture}
  \Tree [.N($\dry$) Porsche ]
\end{tikzpicture} \\
\begin{tikzpicture}
  \Tree [.S $\drx$
            [.VP$'$ [.VP [.V owns ]
                         $\dry$ ] ] ]
\end{tikzpicture}
}
& $\to_\crlin$
& \drs{$\drx$ $\dry$}
{
$\ap{\obj{Jones}}{\drx}$ \\
$\ap{\obj{Porsche}}{\dry}$ \\
\begin{tikzpicture}
  \Tree [.S $\drx$
            [.VP$'$ [.VP [.V owns ]
                         $\dry$ ] ] ]
\end{tikzpicture}
}
& $=$
& \drs{$\drx$ $\dry$}
{
$\ap{\obj{Jones}}{\drx}$ \\
$\ap{\obj{Porsche}}{\dry}$ \\
$[\drx$ owns $\dry]$
}
& $\to_\crlitv$
& \drs{$\drx$ $\dry$}
{
$\ap{\obj{Jones}}{\drx}$ \\
$\ap{\obj{Porsche}}{\dry}$ \\
$\app{\obj{own}}{\drx}{\dry}$
}
\end{tabular}
\end{center}

Having reduced the noun phrase \emph{a Porsche}, we are now led to evaluate
the noun \emph{Porsche} itself. It yields the predicate $\obj{Porsche}$. At
this point, the algorithm presented in~\cite{kamp1993discourse}
stops. However, in order to be a little bit more uniform, we will reduce
the piece of syntax $[\drx$ owns $\dry]$ and replace it with an atomic
formula $\app{\obj{own}}{\drx}{\dry}$. We can now add the syntactic
analysis of the second sentence and proceed with computation.


\begin{center}
\begin{tabular}{rcl}
\drs{$\drx$ $\dry$}
{
$\ap{\obj{Jones}}{\drx}$ \\
$\ap{\obj{Porsche}}{\dry}$ \\
$\app{\obj{own}}{\drx}{\dry}$ \\
\begin{tikzpicture}
  \Tree [.S [.NP [.PRO It ] ]
            [.VP$'$ [.VP [.V fascinates ]
                         [.NP [.PRO him ] ] ] ] ]
\end{tikzpicture}
}
& $\to_\crpro$
& \drs{$\drx$ $\dry$ $\dru$}
{
$\ap{\obj{Jones}}{\drx}$ \\
$\ap{\obj{Porsche}}{\dry}$ \\
$\app{\obj{own}}{\drx}{\dry}$ \\
$\dru = \dry$ \\
\begin{tikzpicture}
  \Tree [.S $\dru$
            [.VP$'$ [.VP [.V fascinates ]
                         [.NP [.PRO him ] ] ] ] ]
\end{tikzpicture}
}
\end{tabular}
\end{center}

Again, we start by evaluating the subject. This time, it is a pronoun, but
the process remains largely the same. We replace the pronoun with a new
discourse referent $\dru$, which we introduce into the DRS along with the
condition $\dru = \dry$.

\begin{center}
\begin{tabular}{rcccl}
\drs{$\drx$ $\dry$ $\dru$}
{
$\ap{\obj{Jones}}{\drx}$ \\
$\ap{\obj{Porsche}}{\dry}$ \\
$\app{\obj{own}}{\drx}{\dry}$ \\
$\dru = \dry$ \\
\begin{tikzpicture}
  \Tree [.S $\dru$
            [.VP$'$ [.VP [.V fascinates ]
                         [.NP [.PRO him ] ] ] ] ]
\end{tikzpicture}
}
& $\to_\crpro$
& \drs{$\drx$ $\dry$ $\dru$ $\drv$}
{
$\ap{\obj{Jones}}{\drx}$ \\
$\ap{\obj{Porsche}}{\dry}$ \\
$\app{\obj{own}}{\drx}{\dry}$ \\
$\dru = \dry$ \\
$\drv = \drx$ \\
\begin{tikzpicture}
  \Tree [.S $\dru$
            [.VP$'$ [.VP [.V fascinates ]
                         $\drv$ ] ] ]
\end{tikzpicture}
}
& $\to_\crlitv$
& \drs{$\drx$ $\dry$ $\dru$ $\drv$}
{
$\ap{\obj{Jones}}{\drx}$ \\
$\ap{\obj{Porsche}}{\dry}$ \\
$\app{\obj{own}}{\drx}{\dry}$ \\
$\dru = \dry$ \\
$\drv = \drx$ \\
$\app{\obj{fascinate}}{\dru}{\drv}$
}
\end{tabular}
\end{center}

For the object noun we do the same, introducing the discourse referent
$\drv$ and the condition $\drv = \drx$. Finally, all that is left is to
translate the transitive verb into a binary relation and we get the final
DRS representation.

Let us now look at the formulation of the construction rules, starting with
$\crid$ in Figure~\ref{fig:crid}.\footnote{The construction rules presented
  in~\cite{kamp1993discourse} also include gender features, which are
  necessary for correct anaphora resolution. We will omit them from the
  rules as we will not be studying anaphora resolution in this work.}

\begin{figure}
\centering
\cridbox
\caption{\label{fig:crid} $\crid$: The construction rule for indefinite
  descriptions.}
\end{figure}

The \emph{triggering configuration} describes the rule's redex (and part of
its context). In the case of $\crid$, the rule for indefinite descriptions,
the redex is a noun phrase of the form \emph{a(n) $N$}. The actual
triggering configuration also includes the node dominating the NP as
well. This is for reasons of evaluation order:

\begin{quote}
``A reducible condition $\gamma$ must be reduced by applying the appropriate
rule to its \emph{highest} triggering configuration, i.e.\ that triggering
configuration $\tau$ such that the highest node of $\tau$ dominates the
highest node of any other triggering configuration that $\gamma$ contains.''
\begin{flushright}
  From Discourse to Logic~\cite{kamp1993discourse} (Section 1.1.4, page 87
  in the Student Edition)
\end{flushright}
\end{quote}

In this rule, the extra piece of context in the triggering configuration
make it so that the application of the rule to the subject dominates the
application of the same rule to the object and therefore fixes evaluation
order: first subject, then object.

The rule then has its contractum, which is given on the last line
(\textbf{Substitute in $\overline{\gamma}$}). In this case, the contractum
is the discourse referent $u$. The rule also has two important side
effects. First, the discourse referent $u$ is introduced into the DRS that
contains this condition. Second, the condition $[N](u)$ is added to the
conditions of that same DRS.\@ The notation $[N](u)$ means that we copy the
whole syntactic structure of $N$ (i.e.\ the whole program for computing the
meaning of the noun) and once its meaning (a predicate) is computed, we
apply it to the discourse referent $u$.

\begin{figure}
\centering
\crprobox
\caption{\label{fig:crpro} $\crpro$: The construction rule for (anaphoric
  third-person singular) pronouns.}
\end{figure}

The rule for pronouns, $\crpro$ in Figure~\ref{fig:crpro}, is very
similar. In introduces a new kind of operation, in which the NP being
evaluated is asking its context for a suitable anaphoric referent.

We will leave the rule for proper nouns until
Section~\ref{sec:presuppositions} and give the two lexical insertion rules
for nouns and transitive verbs \footnote{The latter is not present
  in~\cite{kamp1993discourse}. Instead, [$x$ loves $y$] is treated as an
  irreducible condition.} --- Figures~\ref{fig:crlin} and~\ref{fig:crlitv},
respectively.

\begin{figure}
\begin{subfigure}[b]{0.4\textwidth}
\crlinbox
\caption{\label{fig:crlin} $\crlin$: The lexical insertion rule for
  (common) nouns.}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.4\textwidth}
\crlitvbox
\caption{\label{fig:crlitv} $\crlitv$: The lexical insertion rule for
  (transitive) verbs.}
\end{subfigure}
\caption{\label{fig:li} The lexical insertion construction rules.}
\end{figure}

The system from~\cite{kamp1993discourse} described above can be presented
in a manner reminiscent of operational semantics for programming languages.

The terms of this language are DRSs which contain as conditions syntactic
trees with discourse referents. The values in this language are discourse
referents and plain DRSs (DRSs whose conditions are formulas). We will
define evaluation contexts $C$. These should reflect the fact the
construction algorithm of DRT permits reduction in any of the conditions
within a DRS.

$$
  C ::= [] \ | \ \drs{ $\drx_1$ \ldots\ $\drx_n$ }
                { $\gamma_1$ \\ \ldots \\ $\lnot C$ \\ \ldots \\ $\gamma_m$}
           \ | \ \drs{ $\drx_1$ \ldots\ $\drx_n$ }
                { $\gamma_1$ \\ \ldots \\ $C \Rightarrow K$ \\ \ldots \\ $\gamma_m$}
           \ | \ \drs{ $\drx_1$ \ldots\ $\drx_n$ }
                { $\gamma_1$ \\ \ldots \\ $K \Rightarrow C$ \\ \ldots \\ $\gamma_m$}
           \ | \ \drs{ $\drx_1$ \ldots\ $\drx_n$ }
                { $\gamma_1$ \\ \ldots \\ $C \lor K$ \\ \ldots \\ $\gamma_m$}
           \ | \ \drs{ $\drx_1$ \ldots\ $\drx_n$ }
                { $\gamma_1$ \\ \ldots \\ $K \lor C$ \\ \ldots \\ $\gamma_m$}
$$

The reducible conditions are syntactic trees. The triggering configuration
can be found in any part of a syntactic tree and so we define $C_\gamma$ to
be a context that places $[]$ inside a syntactic tree. For every rule
$A \to B_1 \ldots B_n$, there will be a production rule for the context
$C_\gamma ::= A (B_1, \ldots, B_{i-1}, C_\gamma, B_{i+1}, \ldots, B_n)$.

$$
  C_\gamma ::= []\ |\ \leaf{$C_\gamma$} \leaf{VP} \branch{2}{S} \tree
                 \ |\ \leaf{NP} \leaf{$C_\gamma$} \branch{2}{S} \tree
                 \ |\ \leaf{$C_\gamma$} \leaf{NP} \branch{2}{VP} \tree
                 \ |\ \leaf{V} \leaf{$C_\gamma$} \branch{2}{VP} \tree \ |\ \ldots
$$

The construction rule $\crid$ is then a reduction rule on these forms:

$$
  C\left[\ 
    \drs{$\drx_1$ \ldots\ $\drx_n$}
        {$\gamma_1$ \\
         \ldots \\
         $C_\gamma \left[ \leaf{a(n)} \branch{1}{DET} \leaf{N}
           \branch{2}{NP} \leaf{VP$'$} \branch{2}{S} \tree \right]$ \\
         \ldots \\
         $\gamma_m$}\ \right]
  \to_\crid
  C\left[\ 
    \drs{$\drx_1$ \ldots\ $\drx_n$ $\dru$}
        {$\gamma_1$ \\
         \ldots \\
         $[$N$](\dru)$ \\
         $C_\gamma \left[ \leaf{$\dru$} \leaf{VP$'$} \branch{2}{S} \tree \right]$ \\
         \ldots \\
         $\gamma_m$}\ \right]
$$

Likewise, there is an analogue for evaluating indefinite descriptions in
object positions which differs only in the triggerring configuration. The
reduction rules for $\crpro$, $\crlin$ and $\crlitv$ can be derived in the
same way. Then, the DRS that corresponds to a sentence can be seen as a
normal form\footnote{The system permits reductions in different conditions
  at the same time and is therefore not confluent. Hence the indefinite
  article in ``\emph{a normal form}''.} in this reduction system.

If we look at the rule, then we can see a remarkable similarity to the
rules seen in Chapter~\ref{chap:continuations} for $\lambda_\shift$ and
$\lambda_\shifto$. Inside the context $C$, we have some kind of delimiting
construction, a DRS in one case and a $\reset$ in the other. As one of the
arguments of this construction, we have an expression buried inside a more
limited context: $C_\gamma$, which cannot contain any more nested DRSs, and
$F$, which cannot contain any more $\reset$s. In the case of DRT, this
buried expression is an indefinite or a pronoun which wants to access the
context's DRS to add (and possibly look for) discourse referents and
conditions. In the case of $\lambda_\shift$, the buried expression is a
$\shift$ that wants complete control over the context inside the
$\reset$. In our analysis of $\lambda_\shift$, $\reset$ corresponded
directly to a handler. Therefore, we will be treating DRSs as handlers in
the coming $\banana{\lambda}$ analysis. The denotations of indefinites and
pronouns will use operations to introduce new discourse referents and
conditions and to query the state of discourse to resolve anaphora.


\section{\texorpdfstring{$\banana{\lambda}$ Analysis}{Analysis in Our Calculus}}
\label{sec:banana-drt}

The first step in building a $\banana{\lambda}$ analysis of dynamics is to
design the effect signature: how many operations we will need, what their
types should be and what they should do. However, our task is largely
facilitated by the fact that in their exposition of
DRT~\cite{kamp1993discourse}, Kamp and Reyle have structured the
construction rules by using a limited set of operations to manipulate the
DRSs. It is these operations that we will include in our effect
signature. Consider the construction rule for pronouns and the
corresponding representation as a $\banana{\lambda}$ computation.

\vspace{6mm}

\hspace{-5mm}
\begin{minipage}{0.63\textwidth}
\crprobox
\end{minipage}
\begin{minipage}{0.36\textwidth}
\vspace{0.4cm}
\begin{align*}
\alpha &: NP \\ \\
\sem{NP} &= \FF_E(\iota)
\end{align*}
\vspace{0.1cm}
\begin{align*}
\sem{\alpha} =\ & \app{\op{choose}}{&&\star}{ &(\lam{v}{ \\
                & \app{\op{introduce}}{&&\star}{ &(\lam{u}{ \\
                & \app{\op{assert}}{&&(u = v)}{ &(\lam{\_}{ \\
                \\ \\
                & \ap{\eta}{u}})}})}})}
\end{align*}
\end{minipage}

\vspace{6mm}

Let $\alpha$ be a third-person singular pronoun.\footnote{Since we ignore
  gender, we can think of $\alpha$ as \emph{the} third-person singular
  pronoun.} The construction rule reduces the NP node formed by $\alpha$
into a discourse referent. In the corresponding analysis in our formalism
(ACG + $\banana{\lambda}$), we have $\alpha$ as an abstract constant of
type $NP$ whose semantic interpretation is a computation of type
$\FF_E(\iota)$. The pronoun asks the context for a suitable antecedent,
which is then referred to as $v$. We mimic the verb \textbf{choose} with an
operation $\op{choose}$. It does not take any input, as no input is given
to \textbf{choose} in the construction rule,\footnote{If we were to care about
  gender markers, the input of this operation would be the gender
  marker/predicate, much like in the example of the $\op{select}$ operator
  proposed in~\ref{ssec:choosing-effect-signature}.} and expects a
discourse referent as output. Since we will be using the type $\iota$ for
terms that designate individuals, we will identify the type of discourse
referents with $\iota$.

$$
\typedop{choose}{1}{\iota}
$$

Next up, the construction rule demands the introduction of a new discourse
referent into the DRS $\KK$ that contains the condition being
evaluated. This instruction and its use of the verb \textbf{introduce}
gives rise to the $\op{introduce}$ operation. $\op{introduce}$ asks for a
fresh discourse referent and so its type ends being the same as the one for
$\op{choose}$, only the semantics differ.

$$
\typedop{introduce}{1}{\iota}
$$

The next step in the construction rule asks the DRS $\KK$ to introduce a
new condition. For this kind of interaction, \textbf{introducing} a
condition, we will use a new operation, $\op{assert}$. The NP indicates the
condition it wants to add to the DRS, the truth condition that it wants to
assert. Conditions are atomic formulas of predicate logic and so we will
use $o$, the type of propositions, to represent them. The output will be of
the trivial type $1$.

$$
\typedop{assert}{o}{1}
$$

Finally, the construction rule tells us to replace the NP node with the
discourse referent $u$. This means that when this NP occurs as an argument
to a predicate, the predicate should be applied to the discourse referent
$u$. In $\banana{\lambda}$, this role is played by the return values of
computations (see equation below). Therefore, we return $u$ with the
computation $\etaE{u}$.

$$
\obj{predicate} \apr (\app{\op{op}}{M_\petitp}{(\lam{x}{ \ldots\
    \etaE{u}})}) = \app{\op{op}}{M_\petitp}{(\lam{x}{ \ldots\
    \etaE{(\ap{\obj{predicate}}{u})}})}
$$

We can do the same kind of analysis/translation for the $\crid$ rule for
indefinite descriptions.

\vspace{6mm}

\hspace{-10mm}
\begin{minipage}{0.72\textwidth}
\cridbox
\end{minipage}
\begin{minipage}{0.27\textwidth}
\vspace{0.3cm}
\begin{align*}
\abs{a} &: N \limp NP \\
\sem{N} &= \FF_E(\iota \to o) \\
\sem{NP} &= \FF_E(\iota)
\end{align*}
\begin{align*}
\sem{\abs{a}} =\ \lam{N}{& \app{\op{introduce}}{&&\star}{ &(\lam{u}{ \\
                         & N &&\hsbind &(\lam {n}{ \\
                         & \app{\op{assert}}{&&(\ap{n}{u})}{ &(\lam{\_}{ \\
                         \\
                         & \ap{\eta}{u}})}})})}}
\end{align*}
\end{minipage}

\vspace{6mm}

The $\crid$ rule evaluates a noun phrase which is composed of the
indefinite article followed by some noun $N$. This construction is
represented in our ACG as an abstract constant $\abs{a} : N \limp NP$. Its
denotation will be a function from $\sem{N}$ to $\sem{NP}$. As in the rest
of the analyses seen in this chapter, we will take
$\sem{N} = \FF_E(\iota \to o)$, which meshes with the fact that DRT expects
nouns to reduce to predicates.

The evaluation of the noun phrase ``\emph{a $N$}'' starts by introducing a
fresh discourse referent $u$ and so we use the same operation as in
$\crpro$. Then we will proceed by adding the condition $[N](u)$. Note that
in the DRT rule, we are dealing with a reducible condition ($[N]$ is the
syntax of $N$). In adding this reducible condition, DRT essentially
schedules the evaluation of the syntactic expression $[N]$ via some other
construction rule ($\crlin$ if $N$ is only a common noun, other rules if it
is, e.g., restricted by a relative clause or an adjective). In
$\banana{\lambda}$, we achieve a similar effect by asking for the
evaluation of $N$ using the $\hsbind$ operator. We then state that once the
noun has been evaluated down to a predicate, we want this predicate,
applied to the referent $u$, to be a condition inside the DRS.\@ Finally,
as in $\crpro$, we present the discourse referent $u$ as the referent of
the noun phrase.

For completeness, we will also give translations for the $\crlin$ and
$\crlitv$ rules, even though they do not have any dynamic effects of their
own.

\vspace{6mm}

\begin{minipage}{0.5\textwidth}
\crlinbox
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{align*}
\abs{common} &: CN \limp N \\
\sem{CN} &= \iota \to o \\
\sem{N} &= \FF_E(\iota \to o)
\end{align*}
\begin{align*}
\sem{\abs{common}} &= \lam{\alpha}{\etaE{(\lam{v}{\ap{\alpha}{v}})}} \\
                   &= \lam{\alpha}{\etaE{\alpha}} \\
                   &= \eta
\end{align*}
\end{minipage}

\vspace{6mm}

We, as well as Kamp and Reyle, assume that behind every common noun
$\alpha$ lies a set of individuals, a predicate $\alpha$. The lexical
insertion rule for nouns replaces the noun by that predicate. We can
capture the same line of reasoning in ACGs. We contrast the category $CN$
of common nouns (such as \emph{snowman}, \emph{snake}, \emph{ladder}) to
the larger category $N$ of nouns (\emph{animal in your garden}, \emph{man
  who owns a donkey}). The common nouns will correspond to plain sets of
individuals, $\sem{CN} = \iota \to o$. However, more complex nouns might
also have effects\footnote{In the case of dynamics, it might be just
  anaphora, but more generally it might also be indexicality,
  quantification, conventional implicature\ldots}  and so we have
$\sem{N} = \FF_E(\iota \to o)$. In ACGs, to say that every common noun $CN$
is a noun $N$ is to provide an injection of type $CN \limp
N$. Homomorphically, its denotation will be an injection from $\iota \to o$
to $\FF_E(\iota \to o)$, the constructor $\eta$.

\vspace{6mm}

\begin{minipage}{0.5\textwidth}
\crlitvbox
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{align*}
\abs{trans} &: V \limp NP \limp NP \limp S \\
\sem{V} &= \iota \to \iota \to o \\
\sem{NP} &= \FF_E(\iota) \\
\sem{S} &= \FF_E(o)
\end{align*}
\begin{align*}
\sem{\abs{trans}} = \lam{\alpha Y X}{&X \hsbind (\lam{x}{ \\
                                     &Y \hsbind (\lam{y}{ \\
                                     &\etaE{(\app{\alpha}{x}{y})}})})} \\
                  = \lam{\alpha Y X}{&\alpha \apr X \aplr Y}
\end{align*}
\end{minipage}

\vspace{6mm}

With $\crlitv$, the idea behind the DRT/$\banana{\lambda}$ analogy is the
same as with $\crlin$. Behind every (extensional transitive) verb $\alpha$
lies a binary relation, also called $\alpha$. When combined with a subject
and an object, verbs form sentences. This is embodied by the ACG abstract
constant $\abs{trans}$ which maps verbs from $V$ into functions in
$NP \limp NP \limp S$. From the triggerring configuration of the rule
$\crlitv$, we see that (the parent of) the subject dominates (the parent
of) the object. This leads DRT to always evaluate the dynamic effects of
the subject before the object. In $\banana{\lambda}$, this feature is
expressed in the lexical entry for the construction that combines the
subject, verb and object into a sentence, $\abs{trans}$, where $X$ is
evaluated before $Y$ using $\hsbind$.


\subsection{Example}
\label{ssec:dynamic-example}

We have seen how to map the syntax-semantics construction rules of DRT into
the ACG formalism and how the extra steps performed when reducing
indefinites or pronouns in DRT correspond to operations, with which we have
extended ACG's lambda calculus in $\banana{\lambda}$. We can now look at an
example in action.

\begin{exe}
  \ex \label{ex:man-porsche} A man owns a Porsche. It fascinates him.
\end{exe}

This is a small variation of Example~\ref{ex:jones-porsche} in which
\emph{Jones} was replaced by \emph{a man}.\footnote{We relegate the
  discussion of proper nouns to Section~\ref{sec:presuppositions}.}

\begin{align*}
  \sem{\appp{\abs{trans}}{&\abs{owns}}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{Porsche}})})}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{man}})})}} \\
  \tto &\ \app{\op{introduce}}{\star}{(\lam{x}{ \\
       &\ \app{\op{assert}}{(\ap{\obj{man}}{x})}{(\lam{\_}{ \\
       &\ \app{\op{introduce}}{\star}{(\lam{y}{ \\
       &\ \app{\op{assert}}{(\ap{\obj{Porsche}}{y})}{(\lam{\_}{ \\
       &\ \etaE{(\app{\obj{own}}{x}{y})}})}})}})}})}
\end{align*}

The only effects are due to the indefinites that introduce new discourse
referents and assert truth conditions. The operations are ordered
subject-first, object-last and the computation returns the predicate that
is the application of the verb's predicate to the referents of the subject
and the object. The same goes for the second sentence in
Example~\ref{ex:man-porsche}:

\begin{align*}
  \sem{\appp{\abs{trans}}{&\abs{fascinates}}{\abs{him}}{\abs{it}}} \\
  \tto &\ \app{\op{choose}}{\star}{(\lam{y'}{ \\
       &\ \app{\op{introduce}}{\star}{(\lam{u}{ \\
       &\ \app{\op{assert}}{(u = y')}{(\lam{\_}{ \\
       &\ \app{\op{choose}}{\star}{(\lam{x'}{ \\
       &\ \app{\op{introduce}}{\star}{(\lam{v}{ \\
       &\ \app{\op{assert}}{(v = x')}{(\lam{\_}{ \\
       &\ \etaE{(\app{\obj{fascinate}}{u}{v})}})}})}})}})}})}})}
\end{align*}

We can compose the two using $\andlr$, the conjunction of propositions
raised to computations.

\begin{align*}
  \sem{\appp{\abs{trans}}{&\abs{owns}}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{Porsche}})})}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{man}})})}} \andlr \sem{\appp{\abs{trans}}{\abs{fascinates}}{\abs{him}}{\abs{it}}} \\
  \tto &\ \app{\op{introduce}}{\star}{(\lam{x}{ \\
       &\ \app{\op{assert}}{(\ap{\obj{man}}{x})}{(\lam{\_}{ \\
       &\ \app{\op{introduce}}{\star}{(\lam{y}{ \\
       &\ \app{\op{assert}}{(\ap{\obj{Porsche}}{y})}{(\lam{\_}{ \\
       &\ \app{\op{choose}}{\star}{(\lam{y'}{ \\
       &\ \app{\op{introduce}}{\star}{(\lam{u}{ \\
       &\ \app{\op{assert}}{(u = y')}{(\lam{\_}{ \\
       &\ \app{\op{choose}}{\star}{(\lam{x'}{ \\
       &\ \app{\op{introduce}}{\star}{(\lam{v}{ \\
       &\ \app{\op{assert}}{(v = x')}{(\lam{\_}{ \\
       &\ \etaE{(\app{\obj{own}}{x}{y} \land \app{\obj{fascinate}}{u}{v})}})}})}})}})}})}})}})}})}})}})}
\end{align*}

The resulting computation introduces 4 discourse referents: $x$, $y$, $u$
and $v$. Assuming that $\op{choose}$ will give us $x$ for $x'$ and $y$ for
$y'$, then we end up introducing and returning the conditions
$\ap{\obj{man}}{x}$, $\ap{\obj{Porsche}}{y}$, $u = x$, $v = y$,
$\app{\obj{own}}{x}{y}$ and $\app{\obj{fascinate}}{u}{v}$, i.e.\ the same
conditions as in the DRS for Example~\ref{ex:jones-porsche} (replacing
$\ap{\obj{Jones}}{x}$ with $\ap{\obj{man}}{x}$). However, while that might
be our desired interpretation of this computation, for now it is just a
string of (operation) symbols, to which we will now need to give some
meaning.


\subsection{Handler for Dynamics}
\label{ssec:handler-for-dynamics}

In order to give a formal semantics to the operations that we have
introduced for DRT, we will write a handler. The type of dynamic
propositions of de Groote's Type-Theoretic Dynamic Logic (TTDL),
$\gamma \to (\gamma \to o) \to o$, will serve as a suitable interpretation
domain. On top of that, apart from implementing a semantics for our
operations, we will have demonstrated the link between DRT and TTDL.\@ The
type of the handler's input will be $\FF_E(o)$, where $E$ is the effect
signature containing only $\op{choose}$, $\op{introduce}$ and
$\op{assert}$.

\begin{align*}
  \TTDL :\ &\FF_E(o) \to \gamma \to (\gamma \to o) \to o \\
  \TTDL = \bbanana{\ 
  &\onto{\op{choose}}{(\lam{\_ k e \phi}{\appp{k}{(\ap{\sel}{e})}{e}{\phi}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k e \phi}{\exists x.\, \appp{k}{x}{(x \cons e)}{\phi}})}, \\
  &\onto{\op{assert}}{(\lam{p k e \phi}{p \land \appp{k}{\star}{(p \cons e)\footnotemark}{\phi}})}, \\
  &\onto{\eta}{(\lam{p e \phi}{p \land \ap{\phi}{e}})}\ }
\end{align*}

\footnotetext{Unlike the TTDL we presented in Section~\ref{sec:ttdl}, the
  contexts will be composed not only of accessible discourse referents
  (which are added to the context in the $\op{introduce}$ clause) but also
  of propositions added to the common ground (which are added by
  $\op{assert}$). As in~\cite{lebedeva2012expression}, this information
  will be necessary to correctly handle presuppositions.}

We write the handler by following the types, keeping in mind the intended
semantics. There is a notable similarity between the clauses of our handler
and the operators and semantic entries used in TTDL.\@ The $\eta$ clause is
the operation that lifts plain propositions into dynamic
propositions~\cite{lebedeva2012expression}. The clause for $\op{choose}$ is
(ignoring the first dummy argument) exactly the denotation assigned to
pronouns in
TTDL~\cite{de2006towards}~(Subsection~\ref{ssec:ttdl-lexicon}). The clause
for $\op{introduce}$ is the denotation of the indefinite \emph{someone},
also known as the dynamic existential quantifier
in~\cite{lebedeva2012expression}. This is not a coincidence. The clauses
for $\op{choose}$ and $\op{introduce}$ are both values of type $\iota$
written in continuation-passing style with observation type
$\Omega = \gamma \to (\gamma \to o) \to o$, i.e.\ values of type
$(\iota \to \Omega) \to \Omega$. TTDL uses continuation-passing style
(generalized quantifiers) in the denotation of its noun phrases and so
their denotations end up having the same type. The two noun phrases, the
pronoun and the indefinite, stand for the two major ways that dynamic noun
phrases interact with their contexts, retrieving their referents from
context or introducing new ones into the context. Together with
$\op{assert}$, which lets us conjoin another proposition to the observed
proposition, these form the three operations with which we characterize
DRT-style dynamics. Our original discovery of these three operations with
which we can characterize dynamic effects came from the realization that we
can express all the denotations in TTDL with: reading from the context
($\op{choose}$, or later $\op{get}$), wrapping an existential quantifier
over the continuation while adding the bound variable into the context
($\op{introduce}$) and conjoining a proposition to the continuation
($\op{assert}$).

Once we have applied the $\TTDL$ handler to a computation of type
$\FF_E(o)$, we can extract the corresponding (static) proposition by
applying the result to some left context and the trivial right context
($\lam{e}{\top}$). Since this what we will be doing most of the time, we
can simplify the $\TTDL$ handler by assuming that $\phi$ is always equal to
$\lam{e}{\top}$.

\begin{align*}
  \BOX :\ &\FF_E(o) \to \gamma \to o \\
  \BOX = \bbanana{\ 
  &\onto{\op{choose}}{(\lam{\_ k e}{\app{k}{(\ap{\sel}{e})}{e}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k e}{\exists x.\, \app{k}{x}{(x \cons e)}})}, \\
  &\onto{\op{assert}}{(\lam{p k e}{p \land \app{k}{\star}{(p \cons e)}})}, \\
  &\onto{\eta}{(\lam{p e}{p})}\ }
\end{align*}

The handler is called $\BOX$ to stress the analogy to DRSs, which are
customarily drawn as boxes. The crucial common point is that putting
something in a box means that any truth conditions or discourse referents
that it introduces are contained within the box. Throughout this chapter,
we will refer to applications of this handler as boxes, DRSs or
contexts.\footnote{Since the handler acts as something that provides and
  regulates access to a (left) TTDL context.}

Getting back to Example~\ref{ex:man-porsche}, we can now apply one of these
two handlers to get the dynamic proposition.

\begin{align*}
&\ap{\TTDL}{(\sem{\appp{\abs{trans}}{\abs{owns}}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{Porsche}})})}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{man}})})}} \andlr \sem{\appp{\abs{trans}}{\abs{fascinates}}{\abs{him}}{\abs{it}}})} \\
&\tto \lam{e \phi}{\exists x.\ \ap{\obj{man}}{x} \land (\exists y.\, \ap{\obj{Porsche}}{y} \land (\exists u.\ u = \ap{\sel}{e_1} \land (\exists v.\ v = \ap{\sel}{e_2} \land \app{\obj{own}}{x}{y} \land \app{\obj{fascinate}}{u}{v} \land \ap{\phi}{e_3})))} \\
&= \lam{e \phi}{\exists x y u v.\ \ap{\obj{man}}{x} \land \ap{\obj{Porsche}}{y} \land u = \ap{\sel}{e_1} \land v = \ap{\sel}{e_2} \land \app{\obj{own}}{x}{y} \land \app{\obj{fascinate}}{u}{v} \land \ap{\phi}{e_3}} \\
&= \lam{e \phi}{\exists x y u v.\ \ap{\obj{man}}{x} \land \ap{\obj{Porsche}}{y} \land u = y \land v = x \land \app{\obj{own}}{x}{y} \land \app{\obj{fascinate}}{u}{v} \land \ap{\phi}{e_3}} \\
&= \lam{e \phi}{\exists x y.\ \ap{\obj{man}}{x} \land \ap{\obj{Porsche}}{y} \land \app{\obj{own}}{x}{y} \land \app{\obj{fascinate}}{y}{x} \land \ap{\phi}{e_1}}
\end{align*}

where:
\vspace{-1mm}
\begin{align*}
  e_1 &= \ap{\obj{Porsche}}{y} \cons y \cons \ap{\obj{man}}{x} \cons x \cons e \\
  e_2 &= (u = \ap{\sel}{e_1}) \cons u \cons e_1 \\
  e_3 &= (v = \ap{\sel}{e_2}) \cons v \cons e_2
\end{align*}

We have used Kamp and Reyle's construction rules to compute a dynamic
proposition in de Groote's TTDL.\@ The first line shows the result as we
get it from the handler. On the second line, we pull out all of the
existential quantifiers (prenex form). On the third line, we resolve the
anaphora and we get a dynamic proposition which corresponds, referent by
referent, condition by condition, to the DRS derived by Kamp and Reyle. The
last line removes spurious variables and equalities.


\subsection{Negation}
\label{ssec:dynamic-negation}

In order to match the empirical coverage of the original TTDL
from~\cite{de2006towards}, we have two more features to cover: negation and
(universal) quantification. We will cover negation here. Quantification
reuses the idea from negation and the $\op{scope}$ operation of
quantification: we will see how the two connect in
Chapter~\ref{chap:composing-effects}.

\begin{figure}
  \centering
  \crnegbox
  \caption{\label{fig:crneg} $\crneg$: The construction rule for negation.}
\end{figure}

The construction rule for negation, $\crneg$, is displayed in
Figure~\ref{fig:crneg}. We are reducing a condition which is in the form of
a negated sentence. The DRT mechanism will place the sentence in its own
DRS, whose negation will then become the new condition that replaces the
sentence. The dynamic effects that we have seen so far reach only into the
nearest enclosing DRS.\@ This means that wrapping something inside a new
DRS is significant: the reach of any dynamic effects within will be limited
to that DRS.\@ We have also seen that this is akin to the way effects like
$\shift$ are delimited/handled by the nearest $\reset$. It will come as no
surprise then that our implementation of negation will use a handler for
dynamic effects.

The definition of dynamic negation in TTDL
from~\cite{lebedeva2012expression} will be a great guide in how to proceed:

\begin{align*}
\dnot_{\TTDL} \_ &: \Omega \to \Omega \\
\dnot_{\TTDL} A &= \lam{e \phi}{\lnot (\app{A}{e}{(\lam{e}{\top})}) \land \ap{\phi}{e}}
\end{align*}

We know that $\lam{e \phi}{M \land \ap{\phi}{e}}$ corresponds to $\etaE{M}$
and that $\app{A}{e}{(\lam{e}{\top})}$ is $\app{\BOX}{A}{e}$. Therefore, we
can define our dynamic negation by:

\begin{align*}
\dnot \_ &: \FF_E(o) \to \FF_E(o) \\
\dnot A &= \etaE{(\lnot (\app{\BOX}{A}{e}))}
\end{align*}

However, there is a small catch. We have a free variable $e$ of type
$\gamma$. This is supposed to be the context in which the new negated
condition is to appear. This is necessary so that the anaphoric elements
within the negated condition can refer to not only the referents proper to
the negated DRS, but also to those originating in superordinate DRSs. We
can introduce a new operation for accessing the context.

$$
\typedop{get}{1}{\gamma}
$$

Now, we can have dynamic negation as:

$$
\dnot A = \app{\op{get}}{\star}{(\lam{e}{\etaE{(\lnot (\app{\BOX}{A}{e}))}})}
$$

We can see the analogy with $\crneg$: the negation of $A$ puts $A$ inside a
box, the box is then negated and returned as the new condition. The name
$\BOX$ for this kind of handler was motivated exactly by this kind of
analogy, wherein a handler is used to contain dynamic effects inside some
scope.

We have introduced a new operation into our dynamic effect signature. This
means that we will have to extend our handlers to cover the new
operation. However, before we do so, we note that $\op{choose}$ can be
expressed in terms of $\op{get}$ and $\sel$:

$$
\op{choose} = \lam{\_ k}{\app{\op{get}}{\star}{(\lam{e}{\ap{k}{(\ap{\sel}{e})}})}}
$$

Therefore, we will drop $\op{choose}$ and keep only $\op{get}$. We have now
arrived at our final effect signature for DRT dynamics. This signature
allows us to treat dynamic effects the same way as the other effects that
we have analyzed in Chapter~\ref{chap:introducing-effects}.

\begin{align*}
  E_\DRT = \{\ &\typedop{get}{1}{\gamma}, \\
              &\typedop{introduce}{1}{\iota}, \\
              &\typedop{assert}{o}{1}\ \}
\end{align*}

The closed handlers $\TTDL$ and $\BOX$ are updated to use $\op{get}$
instead of $\op{choose}$:

\begin{align*}
  \TTDL :\ &\FF_{E_\DRT}(o) \to \gamma \to (\gamma \to o) \to o \\
  \TTDL = \bbanana{\ 
  &\onto{\op{get}}{(\lam{\_ k e \phi}{\appp{k}{e}{e}{\phi}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k e \phi}{\exists x.\ \appp{k}{x}{(x \cons e)}{\phi}})}, \\
  &\onto{\op{assert}}{(\lam{p k e \phi}{p \land \appp{k}{\star}{(p \cons e)}{\phi}})}, \\
  &\onto{\eta}{(\lam{p e \phi}{p \land \ap{\phi}{e}})}\ } \\ \\
  \BOX :\ &\FF_{E_\DRT}(o) \to \gamma \to o \\
  \BOX = \bbanana{\ 
  &\onto{\op{get}}{(\lam{\_ k e}{\app{k}{e}{e}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k e}{\exists x.\ \app{k}{x}{(x \cons e)}})}, \\
  &\onto{\op{assert}}{(\lam{p k e}{p \land \app{k}{\star}{(p \cons e)}})}, \\
  &\onto{\eta}{(\lam{p e}{p})}\ }
\end{align*}


\subsection{Truth Conditions as Side Effects}
\label{ssec:truth-conditions-side-effects}

Let us look back the computation that we assigned to the first sentence in
Example~\ref{ex:man-porsche}: \emph{a man owns a Porsche}.

\begin{align*}
&\app{\op{introduce}}{\star}{(\lam{x}{ \\
&\app{\op{assert}}{(\ap{\obj{man}}{x})}{(\lam{\_}{ \\
&\app{\op{introduce}}{\star}{(\lam{y}{ \\
&\app{\op{assert}}{(\ap{\obj{Porsche}}{y})}{(\lam{\_}{ \\
&\etaE{(\app{\obj{own}}{x}{y})}})}})}})}})}
\end{align*}

The truth condition that corresponds to the verb is being returned by the
computation, whereas the truth conditions that arise from the nouns are
expressed using $\op{assert}$. The at-issue content of this sentence
consists of all of these conditions and therefore there is no reason to
separate out the verb's predicate. We could write this instead:

\begin{align*}
&\app{\op{introduce}}{\star}{(\lam{x}{ \\
&\app{\op{assert}}{(\ap{\obj{man}}{x})}{(\lam{\_}{ \\
&\app{\op{introduce}}{\star}{(\lam{y}{ \\
&\app{\op{assert}}{(\ap{\obj{Porsche}}{y})}{(\lam{\_}{ \\
&\app{\op{assert}}{(\app{\obj{own}}{x}{y})}{(\lam{\_}{ \\
&\etaE{\star}})}})}})}})}})}
\end{align*}

This is a computation of type $\FF_{E_\DRT}(1)$. As before, we use a
handler to extract the proposition that is represented by this computation.

\begin{align*}
  \TTDL :\ &\FF_{E_\DRT}(1) \to \gamma \to (\gamma \to o) \to o \\
  \TTDL = \bbanana{\ 
  &\onto{\op{choose}}{(\lam{\_ k e \phi}{\appp{k}{(\ap{\sel}{e})}{e}{\phi}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k e \phi}{\exists x.\ \appp{k}{x}{(x \cons e)}{\phi}})}, \\
  &\onto{\op{assert}}{(\lam{p k e \phi}{p \land \appp{k}{\star}{(p \cons e)}{\phi}})}, \\
  &\onto{\eta}{(\lam{\_ e \phi}{\ap{\phi}{e}})}\ }
\end{align*}

The handler differs from the original $\TTDL$ only in the $\eta$ clause,
which substitutes $\top$ for the returned proposition $p$ in
$\lam{e \phi}{p \land \ap{\phi}{e}}$.

We can use computations of type $\FF_{E_\DRT}(1)$ as our type of dynamic
(i.e.\ effectful) propositions. We can embed simple propositions using
$\op{assert}!$, which has type $o \to \FF_{E_\DRT}(1)$. We can perform
dynamic conjunction $M \dand N$ by chaining two computations,
$M \hsbind (\lam{\_}{N}) : \FF_{E_\DRT}(1)$ for $M, N :
\FF_{E_\DRT}(1)$. We can modify $\BOX$ the same way we modified
$\TTDL$. Dynamic negation will be the same as before, with $\eta$ being
replaced with $\op{assert}!$.

\begin{align*}
  \BOX :\ &\FF_{E_\DRT}(1) \to \gamma \to o \\
  \BOX = \bbanana{\ 
  &\onto{\op{get}}{(\lam{\_ k e}{\app{k}{e}{e}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k e}{\exists x.\ \app{k}{x}{(x \cons e)}})}, \\
  &\onto{\op{assert}}{(\lam{p k e}{p \land \app{k}{\star}{(p \cons e)}})}, \\
  &\onto{\eta}{(\lam{\_ e}{\top})}\ }
\end{align*}

$$
\dnot A = \app{\op{get}}{\star}{(\lam{e}{\ap{\op{assert}!}{(\lnot (\app{\BOX}{A}{e}))}})}
$$

In the lexical entries derived from the construction rules, not much will
have to change. We will only see a difference in the lexical entry
$\abs{trans}$ that we have introduced for the $\crlitv$ rule for transitive
verbs (which was extrapolated from the DRT treatment
in~\cite{kamp1993discourse}). Instead of returning the proposition as the
result of evaluating the sentence, we add it as a condition using
$\op{assert}!$, which is actually what the DRS construction algorithm ends
up doing.

\begin{align*}
\abs{trans} &: V \limp NP \limp NP \limp S \\
\sem{\abs{trans}} &= \lam{\alpha Y X}{(\alpha \apr X \aplr Y) \hsbind \op{assert}!}
\end{align*}

This means that we can build up our dynamic semantics using computations
that do not return anything, only modify the context using side
effects. This is very much in the spirit of dynamic semantics: meaning is
context change potential~\cite{sep-dynamic-semantics}.\footnote{When
  studying the monadic structure of TTDL
  in~\ref{ssec:ttdl-monadic-structure}, we have found that dynamic
  propositions correspond to monadic computations with the trivial result
  type $1$.}

The switch from $\FF_E(o)$ to $\FF_{E \uplus DRT}(1)$ is very much like the
one from $\FF_E((\iota \to o) \to o)$ to
$\FF_{E \uplus \op{scope}}(\iota)$: we found a way to encode
quantifiers/truth conditions as side effects and so we move the extra
structure from the return type to the effect signature. The choice between
the two is rather arbitrary. Keeping $o$ as the return type for
computations that interpret sentences is more consistent with what we have
been doing in Chapter~\ref{chap:introducing-effects}. On the other hand,
using $1$ as the return type has several advantages:

\begin{itemize}
\item it is more uniform by not admitting both $\etaE{A}$ and
  $\app{\op{assert}}{A}{(\lam{\_}{\etaE{\top}})}$
\item this in turn leads to nicer canonical representations and equational
  theory in~\ref{ssec:algebraic-drt}
\item and in order to correctly treat the cancellation of presuppositions
  in~\ref{sec:presuppositions}, we will need to add the truth conditions
  generated by verbs into the context using something like $\op{assert}$
  anyway
\end{itemize}

For the remainder of this chapter, we will use the encoding that models
sentences as computations of return type $1$.


\subsection{Algebraic Considerations}
\label{ssec:algebraic-drt}

Now that we have handlers for our computations, we can study which
computations share the same interpretations and try to derive some
equational theory over them.

We will first start by looking at how $\op{get}$ behaves w.r.t.\ itself and
the other operations.

\begin{align*}
   \app{\op{get}}{\star}{(\lam{e}{\app{\op{get}}{\star}{(\lam{e'}{M(e, e')})}})}
&= \app{\op{get}}{\star}{(\lam{e}{M(e, e)})} \\
   M
&= \app{\op{get}}{\star}{(\lam{e}{M})}
\end{align*}

As with the $\op{speaker}$ getter from~\ref{sec:deixis}, we get two laws
telling us that asking for the context is idempotent (first equation) and
that it has no other bearing on the result of the computation (second
equation).

Since we know how $\op{assert}$ and $\op{introduce}$ modify the context, we
can reorder $\op{get}$ w.r.t.\ these two operations:

\begin{align*}
   \app{\op{assert}}{A}{(\lam{u}{\app{\op{get}}{\star}{(\lam{e}{M(u, e)})}})}
&= \app{\op{get}}{\star}{(\lam{e}{\app{\op{assert}}{A}{(\lam{u}{M(u, A \cons e)})}})} \\
   \app{\op{introduce}}{\star}{(\lam{x}{\app{\op{get}}{\star}{(\lam{e}{M(x, e)})}})}
&= \app{\op{get}}{\star}{(\lam{e}{\app{\op{introduce}}{\star}{(\lam{x}{M(x, x \cons e)})}})} \\
\end{align*}

This means we can assume that every computation of type $\FF_{E_\DRT}(1)$
uses $\op{get}$ exactly once and does so at the very beginning, i.e.\ it is
of the form $\app{\op{get}}{\star}{(\lam{e}{M(e)})}$ where
$M(e) : \FF_{\{\op{implicate}, \op{assert}\}}(1)$.\footnote{When writing
  effect signatures in subscripts, we will often omit the types of
  operations, which are presumed to be constant.}

If we assume that the relative order of discourse referents and conditions
is not important (e.g.\ they are both separate parts, as in a DRS), or in
other words we have that $(x \cons p \cons e) = (p \cons x \cons e)$ for
every $x : \iota$, $p : o$ and $e : \gamma$, then we get the following
equation:

$$
  \app{\op{assert}}{A}{(\lam{u}{\app{\op{introduce}}{\star}{(\lam{x}{M(u, x)})}})} 
= \app{\op{introduce}}{\star}{(\lam{x}{\app{\op{assert}}{A}{(\lam{u}{M(u, x)})}})}
$$

This will allows us to move $\op{introduce}$ operations above $\op{assert}$
operations so that we can have the following canonical representation for
computations of type $\FF_{E_\DRT}(1)$:

\begin{align*}
  &\app{\op{get}}{\star}{(\lam{e}{ \\
  &\app{\op{introduce}}{\star}{(\lam{x_1}{ \\
  &\qquad \vdots \\
  &\app{\op{introduce}}{\star}{(\lam{x_n}{ \\
  &\app{\op{assert}}{c_1}{(\lam{\_}{ \\
  &\qquad \vdots \\
  &\app{\op{assert}}{c_m}{(\lam{\_}{ \\
  &\etaE{\star}})}})}})}})}})}
\end{align*}

In other words, the computation examines its context $e$ and then produces
the DRS:

$$
\drs{$x_1$\ \ldots\ $x_n$}{$c_1$ \\ $\vdots$ \\ $c_m$}
$$

Note that as in TTDL, discourse referents correspond to $\lambda$-binders
in $\banana{\lambda}$ and their standard notion of $\alpha$-equivalence
gives rise to $\alpha$-equivalence for our representations.

If we were to further assume that the order in contexts does not matter at
all (e.g.\ the discourse referents and conditions form sets, as in a DRS),
meaning that we have $(x \cons y \cons e) = (y \cons x \cons e)$ and
$(p \cons q \cons e) = (q \cons p \cons e)$ for every $x, y : \iota$,
$p, q : o$ and $e : \gamma$, then we get the following:

\begin{align*}
   \app{\op{assert}}{A}{(\lam{u_1}{\app{\op{assert}}{B}{(\lam{u_2}{M(u_1, u_2)})}})} 
&= \app{\op{assert}}{B}{(\lam{u_2}{\app{\op{assert}}{A}{(\lam{u_1}{M(u_1, u_2)})}})} \\
   \app{\op{introduce}}{\star}{(\lam{x}{\app{\op{introduce}}{\star}{(\lam{y}{M(x, y)})}})} 
&= \app{\op{introduce}}{\star}{(\lam{y}{\app{\op{introduce}}{\star}{(\lam{x}{M(x, y)})}})}
\end{align*}

Since the discourse referents and conditions are (unordered) sets in the
presentation in~\cite{kamp1993discourse}, this would make our
representation closer to DRSs.

Furthermore, if we assume that the conditions in a context can be seen as a
big conjunction, i.e.\ $(p \cons q \cons e) = ((p \land q) \cons e)$ for
every $p, q : o$ and $e : \gamma$, then we admit the following equations:

$$
  \app{\op{assert}}{A}{(\lam{u}{\app{\op{assert}}{B}{(\lam{u'}{M(u, u')})}})} 
= \app{\op{assert}}{(A \land B)}{(\lam{u}{M(u, u)})}
$$

which gives us a simpler canonical representation:

\begin{align*}
  &\app{\op{get}}{\star}{(\lam{e}{ \\
  &\app{\op{introduce}}{\star}{(\lam{x_1}{ \\
  &\qquad \vdots \\
  &\app{\op{introduce}}{\star}{(\lam{x_n}{ \\
  &\app{\op{assert}}{p}{(\lam{\_}{ \\
  &\etaE{\star}})}})}})}})}
\end{align*}

This boils down a computation of type $\FF_{E_\DRT}(1)$ into a proposition
$p$ that depends on some context $e$ and introduces the new discourse
referents $x_1$, \ldots, $x_n$.

Finally, we will look at the particular case of the computation that serves
as the denotation of an anaphoric pronoun:

$$
  \begin{aligned}
   &\app{\op{get}}{\star}{(\lam{e}{ \\
   &\app{\op{introduce}}{\star}{(\lam{y}{ \\
   &\app{\op{assert}}{(\ap{\sel}{e} = y)}{(\lam{\_}{ \\
   &\etaE{y}})}})}})}
   \end{aligned}
   \qquad = \qquad
   \begin{aligned}
   &\app{\op{get}}{\star}{(\lam{e}{ \\
   &\app{\op{introduce}}{\star}{(\lam{y}{ \\
   &\app{\op{assert}}{(\ap{\sel}{e} = y)}{(\lam{\_}{ \\
   &\etaE{(\ap{\sel}{e})}})}})}})}
   \end{aligned}
   \qquad = \qquad
   \begin{aligned}
   &\app{\op{get}}{\star}{(\lam{e}{ \\
   &\etaE{(\ap{\sel}{e})}})}
   \end{aligned}
$$

The first equation, which exchanges $y$ with $\ap{\sel}{e}$, is licensed by
the fact that the $\BOX$ handler will interpret the first computation as
the proposition $\exists y.\, \ap{\sel}{e} = y \land \ap{k}{y}$ and the
second computation as the proposition
$\exists y.\, \ap{\sel}{e} = y \land \ap{k}{(\ap{\sel}{e})}$, both of which
are equivalent.

The simplification in the second equation is based on an assumption that
$((\ap{\sel}{e} = y) \cons y \cons e) = e$. In other words, if an
individual is already present in the context (the individual
$\ap{\sel}{e}$), adding it again under a different name ($y$) does not
change the context. While certain strategies of anaphora resolution might
rely on individuals being repeatedly added to the context on every
use,\footnote{For example when contexts are lists of individuals ordered by
  saliency and adding the same individual multiple times increases its
  saliency.} we allow ourselves this modification to simplify the
derivations in the coming examples and make the resulting logical formulas
more readable. Therefore, we will be using this simplified denotation for
anaphoric pronouns:

\begin{align*}
  \sem{\abs{he}} =\ &\app{\op{get}}{\star}{(\lam{e}{ \\
                    &\etaE{(\ap{\sel}{e})}})}
\end{align*}


\section{Presuppositions}
\label{sec:presuppositions}

In our $\banana{\lambda}$ analysis of anaphora, we have completely omitted
proper nouns, even though they are treated by DRT
in~\cite{kamp1993discourse} and feature in
Example~\ref{ex:jones-porsche}. This is due to the fact that proper nouns
trigger presuppositions: \emph{Jones sleeps} presupposes that there is some
(contextually salient) entity named Jones. These presuppositions project
outside of entailment-cancelling operators such as negation, outside of the
DRSs in which they are contained.

\begin{exe}
  \ex \label{ex:jones-mercedes} It is not the case that Jones$_1$ owns a
  Porsche. He$_1$ owns a Mercedes.
\end{exe}

In Example~\ref{ex:jones-mercedes}, the proper noun \emph{Jones}
contributes a discourse referent which is then picked up in the second
sentence. This would be impossible to achieve using $\op{introduce}$, since
that would contribute the referent only to the DRS ($\BOX$) that is being
negated and the discourse referent would not reach the second sentence.

\begin{figure}
\centering
\crpnbox
\caption{\label{fig:crpn} $\crpn$: The construction rule for proper nouns.}
\end{figure}

If we look at the construction rule for proper nouns in DRT, $\crpn$,
displayed on Figure~\ref{fig:crpn}, we will see that the discourse referent
and the condition describing it are being inserted into the main DRS and
not into the DRS $K$ in which the condition being reduced appears.

In TTDL, this issue was resolved by adding exceptions into the lambda
calculus used for the semantic terms~\cite{lebedeva2012expression}. The
lexical entry for a presupposition trigger such as a proper noun or a
definite description throws the exception
$\texttt{AbsentIndividualExc}\ P$. This exception carries the predicate $P$
that describes the entity that is presupposed to exist. At the top level, a
handler catches these exceptions and accommodates these presuppositions. We
have seen that in $\banana{\lambda}$, dynamic propositions are modelled as
computations and these computations already have a notion of throwing
exceptions (effects) and handling them (handlers). We will introduce an
operation named $\op{presuppose}$. Its input type will be $\iota \to o$, a
predicate that describes the entity whose existence is presupposed. The
output type will be $\iota$, the presupposed entity satisfying the
predicate.

$$
\typedop{presuppose}{(\iota \to o)}{\iota}
$$

The type of this operation is not exactly equivalent to the exception
$\texttt{AbsentIndividualExc}$ from~\cite{lebedeva2012expression}. As we
have seen in Chapter~\ref{ssec:expressions-as-computations}, exceptions are
effects that have the impossible output type $0$, which means that no
handler will be able to resume the computation by using the
continuation. In Lebedeva's approach, when the toplevel handler intercepts
the exception, it accommodates the presupposition, rewinds the dynamic
state and evaluates the sentence again, this time with a context which now
contains the presupposed entity. This is not suitable to our approach
because of two reasons:

\begin{itemize}
\item We will deal with many other effects besides dynamic state and
  rewinding all of their effects in order to evaluate the sentence again in
  a new context would be needlessly complex.
\item This approach over-generates by licencing the reading ``He$_1$ loves
  John's$_1$ car''. When evaluating \emph{John}, the existence of John is
  presupposed and the sentence is evaluated again, this time in a context
  in which John is accessible. However, this will allow the pronoun in
  subject position to resolve to John and end up being bound by the object.
\end{itemize}

The effects in $\banana{\lambda}$ differ from traditional exceptions in
that they are resumable. Besides having the input type (which is the
message type of a traditional exception), they also have an output
type. Handlers can then resume computation at the point of the effect by
calling the continuation with a value of the output type. We make full use
of this in our treatment of presuppositions by using $\iota$ as the output
type of $\op{presuppose}$. This way, we do not have to abort the evaluation
of the sentence, rewind all of the effects and evaluate it again; we return
the presupposed entity immediately and the evaluation of the sentence
continues. This strategy also avoid the over-generation mentioned above, in
which a presupposition trigger binds a pronoun preceding it.

We have shown how the $\op{presuppose}$ operation can be motivated on the
grounds of the analysis done by Lebedeva
in~\cite{lebedeva2012expression}. We can also look at how it ties to the
DRT construction rule for presupposition triggers such as $\crpn$. When
translating construction rules into computations, we have implemented the
\textbf{Introduce in $\universe_K$} command as the $\op{introduce}$
operation and the \textbf{Introduce in $\conditions_K$} command as the
$\op{assert}$ operation. We might therefore proceed the same way and
translate the \textbf{Introduce into the universe of the main DRS} command
as some operation $\typedop{introduce\_main}{\star}{\iota}$ and
\textbf{Introduce into the condition set of the main DRS} command as
$\typedop{assert\_main}{o}{1}$. However, by looking at the construction
rules of presupposition triggers, we see that they tend to use the two
operations in tandem: first introduce a new discourse referent and then
some condition(s) describing it. Therefore, we can fuse the two into a
single operation $\typedop{presuppose}{(\iota \to o)}{\iota}$, which
introduces and outputs a new discourse referent $x$ while at the same it
introduces the condition $\ap{P}{x}$, where $P$ is its argument.

Besides lowering the number of basic operations that we have to introduce,
this also has an advantage when we start to consider ambiguous ways of
accommodating presuppositions (\ref{ssec:ambiguous-accommodation}). Suppose
we have two operations, $\op{introduce\_somewhere}$ and
$\op{assert\_somewhere}$, that let us introduce discourse referents and
conditions into arbitrary DRSs on the projection line\footnote{A
  \emph{projection line} is a path in the immediate-subordination tree from
  a sub-DRS to the root DRS~\cite{van1992presupposition}. See the
  definition of immediate subordination in~\ref{ssec:drt-context}.}. We
might then end up accommodating the discourse referent and the condition in
different DRS, yielding an undesired meaning. If we package the two
operations into a single $\op{presuppose\_somewhere}$, then we do not have
this problem.


\subsection{Revising the Dynamic Handler}
\label{ssec:revising-dynamic-handler}

We will want to introduce the $\op{presuppose}$ operation into our dynamic
semantics in such a way that $\op{presuppose}$ projects outside of boxes
(DRSs, applications of the $\BOX$ handler). This means that applying the
$\BOX$ handler to a computation should yield a computation free of
$\op{get}$, $\op{introduce}$ and $\op{assert}$ but still possibly using
$\op{presuppose}$: $\BOX$ will be an open handler for $\op{get}$,
$\op{introduce}$ and $\op{assert}$. The open handler will be more complex,
since where before we had continuations which returned simple propositions,
or rather functions from contexts to propositions, we will now have
continuations which return computations.

\begin{align*}
  \BOX &: \FF_{E_\DRT}(1) \to \gamma \to o \\
  \BOX &= \lbban \begin{aligned}[t]
  &\onto{\op{get}}{(\lam{\_ k e}{\app{k}{e}{e}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k e}{\exists x.\ \app{k}{x}{(x \cons e)}})}, \\
  &\onto{\op{assert}}{(\lam{p k e}{p \land \app{k}{\star}{(p \cons e)}})}, \\
  &\onto{\eta}{(\lam{\_ e}{\top})} \rbban\end{aligned} \\
  \\
  \BOX &:\ \FF_{E \uplus E_\DRT}(1) \to \gamma \to \FF_E(o) \\
  \BOX &= \lam{A e}{(\lban \begin{aligned}[t]
  &\onto{\op{get}}{(\lam{\_ k}{\etaE{(\lam{e}{\ap{k}{e} \apll e})}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k}{\etaE{(\lam{e}{\existsr x.\, \ap{k}{x} \apll (x \cons e)})}})}, \\
  &\onto{\op{assert}}{(\lam{p k}{\etaE{(\lam{e}{p \andr (\ap{k}{\star} \apll (p \cons e))})}})}, \\
  &\onto{\eta}{(\lam{\_}{\etaE{(\lam{e}{\top})}})} \rban\ A) \apll e\end{aligned}} \\
  \\
  \_ \apll \_ &: \FF_E(\alpha \to \FF_E(\beta)) \to \alpha \to \FF_E(\beta) \\
  F \apll x &= F \hsbind (\lam{f}{\ap{f}{x}}) \\
  \existsr &: (\iota \to \FF_E(o)) \to  \FF_E(o) \\
  \existsr P &= \exists \apr (\ap{\CC}{P})
\end{align*}

We include the closed $\BOX$ handler for comparison. At the heart of the
open $\BOX$ handler, we have a $\banana{}$ of type $\FF_{E \uplus
  E_\DRT}(1) \to \FF_E(\gamma \to \FF_E(o))$. This $\banana{}$ differs from
the closed $\bbanana{}$ in the following ways:

\begin{itemize}
\item Since the interpretations are no longer functions (type
  $\gamma \to o$), but computations that produce functions (type
  $\FF_E(\gamma \to \FF_E(o))$), we start all the clauses with
  $\etaE{(\lam{e}{\ldots})}$ instead of $\lam{e}{\ldots}$
\item When we apply the continuation $k$ to the output (the context $e$ in
  $\op{get}$, the referent $x$ in $\op{introduce}$ and the trivial $\star$
  in $\op{assert}$), we now get a computation (type
  $\FF_E(\gamma \to \FF_E(o))$) instead of a function (type
  $\gamma \to o$). We need to first evaluate the computation to get a
  function and then apply that function to the new context. For that
  purpose, we define the $\apll$ combinator below.
\item The proposition that is the result of applying the continuation to
  the output and to the new context is now a computation (type $\FF_E(o)$)
  instead of a simple proposition (type $o$). In the $\op{assert}$ clause,
  if we want to conjoin a proposition $p$ to this proposition, we need to
  use the $\andr$ operator, which takes a computation as its right
  argument. In the $\op{introduce}$ clause, we have an impure predicate
  $\lam{x}{\ap{k}{x} \apll (x \cons e)}$ of type $\iota \to \FF_E(o)$. We
  use $\CC$ to push the effects out and get a computation that returns a
  pure predicate, type $\FF_E(\iota \to o)$. We can then apply the
  existential quantifier under the $\FF_E$ type wrapper using $\apr$. We
  write this way of applying the existential quantifier to an effectful
  predicate $P$ as $\existsr P$.
\end{itemize}

After having interpreted the $A : \FF_{E \uplus E_\DRT}(1)$ using the
$\banana{}$, we get a computation of type $\FF_E(\gamma \to \FF_E(o))$. In
order to apply it to an $e : \gamma$, we use the $\apll$ combinator one
last time.

The handler above is much more complicated than any we have seen so far in
this manuscript. However, note that:

\begin{itemize}
\item The translation from the closed $\BOX$ handler was mechanical. The
  open $\BOX$ handler does not include any ad-hoc features built into it to
  make it compatible with presuppositions. The only changes we made to the
  handler was adding $\eta$ and $\CC$ and replacing operators with versions
  that can act on computations ($\apr$ and $\apll$ for application, $\andr$
  for conjunction). In an impure calculus with call-by-value semantics in
  which a distinction between the types $\alpha$ and $\FF_E(\alpha)$ does
  not exist, neither $\eta$ nor the $\somelr$ operators would be needed;
  the only operator we would need to add would be $\CC$, which pushes
  effects out of a function body.
\item The cost of replacing the simpler closed handler with the open
  handler is a price we would have to pay anyway if we wanted to use this
  handler in a setting that involved other effects (such as quantification,
  deixis, conventional implicature); it is not limited to adding support
  for presuppositions. E.g., in Chapter~\ref{chap:composing-effects}, we
  will deal almost exclusively with open handlers.
\item The $\BOX$ handlers are by far the largest handlers in our
  analyses. Furthermore, open handlers that thread some mutable state
  throughout the computation are slightly awkward to write (as testified by
  all the uses of $\apll$) in pure languages without using some syntactic
  sugar, such as parameterized handlers that can automatically thread some
  parameter from operation to operation as
  in~\cite{kammar2013handlers,kiselyov2015freer}.
\end{itemize}

The open $\BOX$ handler outputs computations of propositions instead of
simple propositions, which is something we have to take into account when
using it in, e.g., negation:

$$
\dnot A = \app{\op{get}}{\star}{(\lam{e}{\app{\BOX}{A}{e} \hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}})})}
$$

Now that we have an open version of the $\BOX$ handler, there is one change
that we will make in how it actually functions. We will motivate it by the
following example.

\begin{exe}
  \ex \label{ex:not-john-car} It is not the case that John$_1$ likes his$_1$ car.
\end{exe}

The negation will use $\op{get}$ to retrieve the current context $e$ and
then proceed by evaluating the expression
$(\app{\BOX}{\sem{\text{John likes his car}}}{e})$. The proper noun
\emph{John} will then use $\op{presuppose}$, which will project out of the
$\BOX$ and introduce John into the global context. But now we have to
evaluate the pronoun \emph{his} in the context $e$ which was untouched by
\emph{John} and we will thus fail to retrieve John and get the expected
reading. The problem is in our definition of $\dnot A$. We want anaphoric
expressions within $A$ to have access to referents introduced outside of
$A$. We do this by using $\op{get}$ to recover the context $e$ in which we
are about to evaluate $\dnot A$ and then use that context as the initial
context when interpreting anaphora in $A$ with $\app{\BOX}{A}{e}$. While
this works well for TTDL, in which dynamic propositions have no way to
modify contexts other than the local one, it breaks when we let
$\op{presuppose}$ modify the top context.

The solution is to dismiss the assumption that surrounding contexts are
immutable. Whenever we handle a $\op{get}$, we use another $\op{get}$ to
gather the current state of the surrounding (global) context and then
combine that with the local context. This solution will actually simplify
the definition of $\dnot$ and the type of $\BOX$, since $\BOX$ does not
need to be seeded with its surrounding context but retrieves it itself when
necessary. Furthermore, note that this solution was not available to us
before we made the handler open, since it interprets computations of type
$\FF_{E_\DRT}(1)$ as computations of type $\FF_{\{\op{get}\}}(o)$.

\begin{align*}
  &\BOX :\FF_{E \uplus E_\DRT}(1) \to \FF_{E \uplus \{\op{get}\}}(o) \\
  &\BOX = \lam{A}{(\ap{\begin{aligned}[t]\lban
  &\onto{\op{get}}{(\lam{\_ k}{\etaE{(\lam{e}{\app{\op{get}}{\star}{(\lam{e'}{\ap{k}{(e \cat e')} \apll e})}})}})}, \\
  &\onto{\op{introduce}}{(\lam{\_ k}{\etaE{(\lam{e}{\existsr x.\, \ap{k}{x} \apll (x \cons e)})}})}, \\
  &\onto{\op{assert}}{(\lam{p k}{\etaE{(\lam{e}{p \andr (\ap{k}{\star} \apll (p \cons e))})}})}, \\
  &\onto{\eta}{(\lam{\_}{\etaE{(\lam{e}{\top})}})}\rban}{A}) \apll \nil
    \end{aligned}}
\end{align*}

The $\op{get}$ now uses another $\op{get}$ to retrieve the current
surrounding context $e'$, which is then combined with the local context $e$
as the answer to the original $\op{get}$. In order to combine the two
contexts, we assume that there is some operation
$(\cat) : \gamma \to \gamma \to \gamma$. If contexts are (pairs of) lists,
then this operation would be (pointwise) list concatenation. Since we
always ask again for the surrounding context, we do not need the
surrounding context as an argument to $\BOX$. Instead, we pass in $\nil$ as
the initial local context, where $\nil : \gamma$ is a constant representing
the empty context, e.g.\ an empty list.

As we no longer need to supply the initial surrounding context, dynamic
negation becomes simpler:

$$
\dnot A = \ap{\BOX}{A} \hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}})
$$


\subsection{Presupposition in Action}
\label{ssec:presupposition-in-action}

With $\op{presuppose}$ in place, we can now translate the DRT construction
rule for proper nouns, $\crpn$, into $\banana{\lambda}$:

\vspace{6mm}

\hspace{-1cm}
\begin{minipage}{0.69\textwidth}
\crpnbox
\end{minipage}
\begin{minipage}{0.31\textwidth}
\vspace{-4mm}
\begin{align*}
\abs{proper} &: PN \limp NP \\
\sem{PN} &= \iota \to o \\
\sem{NP} &= \FF_E(\iota)
\end{align*}
\vspace{2mm}
\begin{align*}
  \sem{\abs{proper}} =
  \lam{\alpha}{&\app{\op{presuppose}}{&(\lam{u}{ \\
               \\
               &\ap{\alpha}{u}})}{&(\lam{u}{ \\
               \\ \\
               & \ap{\eta}{u}})}}
\end{align*}
\end{minipage}

\vspace{6mm}

We model the introduction of a discourse referent and a condition into the
main DRS with the $\op{presuppose}$ operation. As with the lexical
insertion rules for common nouns and transitive verbs, this rule is
parameterized by a lexical item, this time a proper noun. In DRT, proper
nouns are described using predicates and so we introduce an abstract atomic
type $PN$ for proper nouns whose interpretation $\sem{PN}$ is the type of
predicates. The definition of $\abs{proper}$ above is expanded in order to
parallel the construction. We can actually make it a lot shorter:

\begin{align*}
  \sem{\abs{proper}}
  =\ &\lam{\alpha}{\app{\op{presuppose}}{(\lam{u}{\ap{\alpha}{u}})}{(\lam{u}{\ap{\eta}{u}})}} \\
  \to_\eta\ &\lam{\alpha}{\app{\op{presuppose}}{\alpha}{(\lam{u}{\ap{\eta}{u}})}} \\
  =\ &\lam{\alpha}{\ap{\op{presuppose}!}{\alpha}} \\
  \to_\eta\ &\op{presuppose}!
\end{align*}

We will also need a handler to give a meaning to the $\op{presuppose}$
operation. The meaning behind $\op{presuppose}$ is clear: it will introduce
a discourse referent and a condition.

\begin{align*}
  \accommodate &: \FF_{E \uplus \{\op{presuppose}\}}(\alpha) \to \FF_E(\alpha) \\
  \accommodate &= \banana{\onto{\op{presuppose}}{(\lam{P k}{\app{\op{introduce}}{\star}{(\lam{x}{\app{\op{assert}}{(\ap{P}{x})}{(\lam{\_}{\ap{k}{x}})}})}})}}
\end{align*}

The accommodate handler turns presupposed content into asserted
content. The place we want to do that is usually on the level of the
topmost DRS.\@ We can define a combinator which corresponds to the idea of
a top DRS.

\begin{align*}
  \TOP &: \FF_{E \uplus E_\DRT \uplus \{\op{presuppose}\}}(1) \to \FF_{E \uplus \{\op{get}\}}(o) \\
  \TOP &= \BOX \circ \accommodate
\end{align*}

We can now deal with Example~\ref{ex:jones-mercedes}. We start by computing
the denotation of the first sentence.

\begin{align*}
  \sem{S_1} =
     &\ \sem{\appp{\abs{trans}}{\abs{owns}}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{Porsche}})})}{(\ap{\abs{proper}}{\abs{Jones}})}} \\
\tto &\ \app{\op{presuppose}}{\obj{Jones}}{(\lam{x}{ \\
     &\ \app{\op{introduce}}{\star}{(\lam{y}{ \\
     &\ \app{\op{assert}}{(\ap{\obj{Porsche}}{y})}{(\lam{\_}{ \\
     &\ \app{\op{assert}}{(\app{\obj{own}}{x}{y})}{(\lam{\_}{ \\
     &\ \etaE{\star}})}})}})}})}
\end{align*}

Wrapping a dynamic negation over this will resolve all the $\op{introduce}$
and $\op{assert}$ operations but the $\op{presuppose}$ will prevail.

\begin{align*}
&\dnot\ \sem{S_1} \\
\tto &\ \ap{\BOX}{\sem{S_1}} \hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}})\\
\tto &\ \app{\op{presuppose}}{\obj{Jones}}{(\lam{x}{ \\
     &\ \etaE{(\exists y.\, \ap{\obj{Porsche}}{y} \land \app{\obj{own}}{x}{y})}})} \hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}}) \\
\tto &\ \app{\op{presuppose}}{\obj{Jones}}{(\lam{x}{ \\
     &\ \app{\op{assert}}{(\lnot (\exists y.\, \ap{\obj{Porsche}}{y} \land \app{\obj{own}}{x}{y}))}{(\lam{\_}{ \\
     &\ \etaE{\star}})}})}
\end{align*}

We now turn to the second sentence in Example~\ref{ex:jones-mercedes},
whose meaning is derived below.

\begin{align*}
  \sem{S_2} =
     &\ \sem{\appp{\abs{trans}}{\abs{owns}}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{Mercedes}})})}{\abs{he}}} \\
\tto &\ \app{\op{get}}{}{(\lam{e}{ \\
     &\ \app{\op{introduce}}{\star}{(\lam{y}{ \\
     &\ \app{\op{assert}}{(\ap{\obj{Mercedes}}{y})}{(\lam{\_}{ \\
     &\ \app{\op{assert}}{(\app{\obj{own}}{(\ap{\sel}{e})}{y})}{(\lam{\_}{ \\
     &\ \etaE{\star}})}})}})}})}
\end{align*}

Dynamic propositions of type $\FF_{E_\DRT}(1)$ are conjoined by chaining
their computations. By chaining the two computations, we get a meaning for
the whole discourse in Example~\ref{ex:jones-mercedes}.

\begin{align*}
  \sem{\text{not $S_1$. $S_2$}} = &\ (\dnot\ \sem{S_1}) \hsbind (\lam{\_}{\sem{S_2}}) \\
\tto &\ \app{\op{presuppose}}{\obj{Jones}}{(\lam{x}{ \\
     &\ \app{\op{assert}}{(\lnot (\exists y.\, \ap{\obj{Porsche}}{y} \land \app{\obj{own}}{x}{y}))}{(\lam{\_}{ \\
     &\ \app{\op{get}}{}{(\lam{e}{ \\
     &\ \app{\op{introduce}}{\star}{(\lam{y}{ \\
     &\ \app{\op{assert}}{(\ap{\obj{Mercedes}}{y})}{(\lam{\_}{ \\
     &\ \app{\op{assert}}{(\app{\obj{own}}{(\ap{\sel}{e})}{y})}{(\lam{\_}{ \\
     &\ \etaE{\star}})}})}})}})}})}})}
\end{align*}

We can now embed this in the top-level box.

\begin{align*}
  \ap{\TOP}{\sem{\text{not $S_1$. $S_2$}}} = &\ \ap{\BOX}{(\ap{\accommodate}{\sem{\text{not $S_1$. $S_2$}}})} \\
\tto \ap{\BOX}{(
     &\ \app{\op{introduce}}{\star}{(\lam{x}{ \\
     &\ \app{\op{assert}}{(\ap{\obj{Jones}}{x})}{(\lam{\_}{ \\
     &\ \app{\op{assert}}{(\lnot (\exists y.\, \ap{\obj{Porsche}}{y} \land \app{\obj{own}}{x}{y}))}{(\lam{\_}{ \\
     &\ \app{\op{get}}{}{(\lam{e}{ \\
     &\ \app{\op{introduce}}{\star}{(\lam{y}{ \\
     &\ \app{\op{assert}}{(\ap{\obj{Mercedes}}{y})}{(\lam{\_}{ \\
     &\ \app{\op{assert}}{(\app{\obj{own}}{(\ap{\sel}{e})}{y})}{(\lam{\_}{ \\
     &\ \etaE{\star}})}})}})}})}})}})}})}\ )} \\
\tto &\ \app{\op{get}}{\star}{(\lam{e}{ \\
     &\ \etaE{(\exists x.\
          \ap{\obj{Jones}}{x} \land
          \lnot (\exists y.\, \ap{\obj{Porsche}}{y} \land \app{\obj{own}}{x}{y}) \land
          (\exists y.\, \ap{\obj{Mercedes}}{y} \land \obj{own}(\sel(e'), y)))}})}
\end{align*}

where

$$
e' = \lnot (\exists y.\, \ap{\obj{Porsche}}{y} \land \app{\obj{own}}{x}{y}) \cons
     \ap{\obj{Jones}}{x} \cons x \cons e
$$

By assuming that $x$ is \emph{the} salient antecedent for the pronoun or by
evaluating in the empty context $\nil$, we get the intended reading.

\begin{align*}
  \EMPTY &: \FF_{E \uplus \{\op{get}\}}(\alpha) \to \FF_E(\alpha) \\
  \EMPTY &= \banana{\onto{\op{get}}{(\lam{\_ k}{\ap{k}{\nil}})}} \\
  &\ap{\EMPTY}{(\ap{\TOP}{\sem{\text{not $S_1$. $S_2$}}})} \\
  &\tto \etaE{(\exists x.\
          \ap{\obj{Jones}}{x} \land
          \lnot (\exists y.\, \ap{\obj{Porsche}}{y} \land \app{\obj{own}}{x}{y}) \land
          (\exists y.\, \ap{\obj{Mercedes}}{y} \land \app{\obj{own}}{x}{y}))}
\end{align*}


\subsection{Cancelling Presuppositions}
\label{ssec:cancelling-presuppositions}

It has been observed that not every presupposition projects. A
presupposition can be blocked or cancelled in certain contexts. The
sentence ``John's car is cheap'' presupposes that there is someone named
John who owns a car. However, if we put this sentence into a conditional
context, as in Example~\ref{ex:cancel}, the presupposition that John owns a
car disappears.

\begin{exe}
  \ex \label{ex:cancel} If John owns a car, then his car is cheap.
\end{exe}

Lebedeva~\cite{lebedeva2012expression} solves this in TTDL by making the
presupposition triggers first search the context for their referent. If the
necessary referent is present in an accessible context, then it is
retrieved and no presupposition is triggered. We can do the same in our
setting. Let $\selP : (\iota \to o) \to \gamma \to (\iota + 1)$ be a
function that retrieves from a context of type $\gamma$ the salient
individual that satisfies the predicate of type $\iota \to o$, if such an
individual exists in the context. Otherwise, it returns $\ap{\inr}{\star}$.

\begin{align*}
  \find &: (\iota \to o) \to \FF_{E \uplus \{\op{get}, \op{presuppose}\}}(\iota) \\
  \find &= \lam{P}{\app{\op{get}}{\star}{(\lam{e}{\case{\app{\selP}{P}{e}}{x}{\etaE{x}}{\_}{\ap{\op{presuppose}!}{P}}})}}
\end{align*}

$\find$ examines its context and searches it for an individual satisfying
the predicate. If no such individual is found, it triggers a
presupposition. The type of $\find$ is (almost\footnote{The type of
  $\op{presuppose}!$ is
  $(\iota \to o) \to \FF_{E \uplus \{\op{presuppose}\}}(\iota)$. However,
  $\find$ relies not only on $\op{presuppose}$, but also on $\op{get}$. In
  most contexts, both are available and so the two are interchangeable.})
the same as that of $\op{presuppose}!$ and so we can replace all uses of
$\op{presuppose}!$ with $\find$ to get the correct behavior w.r.t.\
cancelling of presuppositions.

\begin{align*}
  \abs{proper} &: PN \limp NP \\
  \lex{proper}{\find} \\
  \abs{poss} &: NP \limp N \limp NP \\
  \lex{poss}{\lam{X N}{X \hsbind (\lam{x}{N \hsbind (\lam{n}{\ap{\find}{(\lam{y}{\ap{n}{y} \land \app{\obj{own}}{x}{y}})}})})}}
\end{align*}

The possessive construction \emph{X's N} uses $\find$ to behave either as a
bound pronoun, using $\selP$ to retrieve its referent from the context, or
if there is no suitable referent, as a presupposition trigger.

The final part of the puzzle is how to make the context of the antecedent
(\emph{John owns a car}) available in the consequent (\emph{his car is
  cheap}). DRT has special accessibility rules for implications, but
in~\ref{sec:intro-drt} we have seen how to translate DRT implications into
negations and conjunctions while preserving accessibility\footnote{The same
  technique is applied in the TTDL of~\cite{lebedeva2012expression}.}. We
will use the same strategy to correctly deal with accessibility in
conditional utterances.

\begin{align*}
  \abs{if-then} &: S \limp S \limp S \\
  \lex{if-then}{\lam{A B}{A \dimp B}} \\
  &= \lam{A B}{\dnot (A \dand \dnot B)} \\
  &= \lam{A B}{\dnot (A \hsbind (\lam{\_}{\dnot B}))}
\end{align*}

The dynamic implication used in $\sem{\abs{if-then}}$ explains how
conditionals can filter presuppositions. A new box is opened using the
outer negation. Into that box, $A$ will introduce new discourse referents
and truth conditions. These will then be able available to $B$, which might
resolve some of $B$'s presuppositions. Since the whole conditional is
inside a box due to the dynamic negation, the filtering effect will subside
after the consequent, i.e.\ dynamic implication is externally
static~\cite{groenendijk1991dynamic}.

In Example~\ref{ex:cancel}, the sentence in the antecedent introduces into
the context John ($x$, $\ap{\obj{John}}{x}$), a car ($y$,
$\ap{\obj{car}}{y}$) and the fact that John owns the car
($\app{\obj{own}}{x}{y}$). The sentence in the consequent then has access
to this context and can resolve \emph{his} to $x$ and then retrieve $y$
using $\selP$, thus preventing the triggering of a presupposition.

Instead of using $\find$ in the lexical entry of every presupposition
trigger, there is also an alternative realization that is more in the
spirit of $\banana{\lambda}$. We can change the semantics of
$\op{presuppose}$ from ``introduce a new top-level discourse referent
satisfying the predicate'' to ``find a salient individual satisfying the
predicate''. If the context can satisfy the $\op{presuppose}$ operation by
binding the presupposition trigger to an existing discourse referent, it
might choose to do so. This way, all presupposition triggers consistently
use $\op{presuppose}$. The cancelling then happens at the level of a $\BOX$
(a DRS) which might decide to satisfy the presupposition by supplying an
existing discourse referent.

\begin{align*}
  \useFind &: \FF_{E \uplus \{\op{presuppose}\}}(\alpha) \to \FF_{E \uplus \{\op{get}, \op{presuppose}\}}(\alpha) \\
  \useFind &= \banana{\onto{\op{presuppose}}{(\lam{P k}{\ap{\find}{P} \hsbind k})}} \\
  \DBOX &: \FF_{E \uplus E_\DRT \uplus \{\op{presuppose}\}}(1) \to \FF_{E \uplus \{\op{get}, \op{presuppose}\}}(o) \\
  \DBOX &= \BOX \circ \useFind
\end{align*}

We define a handler for $\op{presuppose}$ called $\useFind$ that tries to
cancel the presupposition by looking into the current context for a
possible referent. In case there is no such referent, the presupposition is
projected onwards. Since $\useFind$ can be defined on its own, we can
define the new $\BOX$ that cancels presuppositions, $\DBOX$, by composing
the old $\BOX$ with $\useFind$.\footnote{We also replace all uses of $\BOX$
  with $\DBOX$, i.e.\ the one in dynamic negation.} The $\useFind$ handler,
which is included in $\DBOX$, handles some uses of $\op{presuppose}$ and
projects others. This captures the reality that some contexts cancel some
presuppositions. If we use the $\DBOX$ handler, we can now use
$\op{presuppose}$ in the lexical entries of presupposition triggers without
having to remember to use $\find$ in order to consistently get the correct
prediction w.r.t.\ the cancellation of presuppositions.

\begin{align*}
  \abs{proper} &: PN \limp NP \\
  \lex{proper}{\op{presuppose}!} \\
  \abs{poss} &: NP \limp N \limp NP \\
  \lex{poss}{\lam{X N}{X \hsbind (\lam{x}{N \hsbind (\lam{n}{\ap{\op{presuppose}!}{(\lam{y}{\ap{n}{y} \land \app{\obj{own}}{x}{y}})}})})}}
\end{align*}

We can now compute the denotation of Example~\ref{ex:cancel}. The meaning
of Example~\ref{ex:cancel} is equal to
$\sem{\app{\abs{if-then}}{S_1}{S_2}} = \sem{S_1} \dimp \sem{S_2} =
\dnot(\sem{S_1} \dand \dnot \sem{S_2})$, where $S_1$ is the antecedent and
$S_2$ is the consequent. We start with the denotation of the consequent,
$S_2$: \emph{his car is cheap}.

\begin{align*}
  \sem{S_2}
  &= \sem{\ap{\abs{is-cheap}}{(\app{\abs{poss}}{\abs{he}}{(\ap{\abs{common}}{\abs{car}})})}} \\
  &\tto \begin{aligned}[t]
    &\app{\op{get}}{\star}{(\lam{e}{ \\
    &\app{\op{presuppose}}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{(\ap{\sel}{e})}{z}})}{(\lam{z}{ \\
    &\app{\op{assert}}{(\ap{\obj{cheap}}{z})}{\lam{\_}{ \\
    &\etaE{\star}}}})}})}
    \end{aligned}
\end{align*}

Now we will work towards the dynamic negation of $\sem{S_2}$, starting with
$\ap{\DBOX}{\sem{S_2}}$.

\begin{align*}
  \ap{\DBOX}{\sem{S_2}}
  &= \ap{\BOX}{(\ap{\useFind}{\sem{S_2}})} \\
  &\tto \ap{\BOX}{(\begin{aligned}[t]
     &\app{\op{get}}{\star}{(\lam{e}{ \\
     &\app{\op{get}}{\star}{(\lam{e'}{ \\
     &(\casenl{\app{\selP}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{(\ap{\sel}{e})}{z}})}{e'}}
       {z}{\etaE{z}}
       {\_}{\ap{\op{presuppose}!}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{(\ap{\sel}{e})}{z}})}}) \hsbind (\lam{z}{ \\
     &\app{\op{assert}}{(\ap{\obj{cheap}}{z})}{(\lam{\_}{ \\
     &\etaE{\star}})}})})}})})
     \end{aligned}} \\
  &\approx \begin{aligned}[t]
     &\app{\op{get}}{\star}{(\lam{e}{ \\
     &(\casenl{\app{\selP}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{(\ap{\sel}{e})}{z}})}{e}}
       {z}{\etaE{z}}
       {\_}{\ap{\op{presuppose}!}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{(\ap{\sel}{e})}{z}})}}) \hsbind (\lam{z}{ \\
     &\etaE{(\ap{\obj{cheap}}{z})}})})}
     \end{aligned}
\end{align*}

We see that the meaning $\ap{\DBOX}{\sem{S_2}}$ is anaphoric, it uses
$\op{get}$ to find an antecedent for \emph{his} and \emph{his
  car}. Furthermore, depending on the retrieved context $e$, it might
trigger a presupposition about the existence of \emph{his car}. In reducing
the expression, we have also allowed ourselves to collapse the two
successive uses of $\op{get}$, since we have derived an equation for
dynamic computations that tells us that $\op{get}$ is idempotent under the
handlers we use (see~\ref{ssec:algebraic-drt}), hence the use of the
$\approx$. To finish computing $\dnot \sem{S_2}$, we take
$\ap{\DBOX}{S_2}$, replace the final $\eta$ with an $\op{assert}!$ and
negate its argument.

\begin{align*}
  \dnot \sem{S_2}
  &= \ap{\DBOX}{\sem{S_2}} \hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}}) \\
  &\tto \begin{aligned}[t]
    &\app{\op{get}}{\star}{(\lam{e}{ \\
    &(\casenl{\app{\selP}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{(\ap{\sel}{e})}{z}})}{e}}
      {z}{\etaE{z}}
      {\_}{\ap{\op{presuppose}!}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{(\ap{\sel}{e})}{z}})}}) \hsbind (\lam{z}{ \\
    &\app{\op{assert}}{(\lnot (\ap{\obj{cheap}}{z}))}{\lam{\_}{ \\
    &\etaE{\star}}}})})}
    \end{aligned}
\end{align*}

We now move to up to the antecedent $S_1$: \emph{John owns a car}.

\begin{align*}
  \sem{S_1}
  &= \sem{\appp{\abs{trans}}{\abs{owns}}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{car}})})}{(\ap{\abs{proper}}{\abs{John}})}} \\
  &\tto \begin{aligned}[t]
      &\app{\op{presuppose}}{\obj{John}}{(\lam{x}{ \\
      &\app{\op{introduce}}{\star}{(\lam{y}{ \\
      &\app{\op{assert}}{(\ap{\obj{car}}{y})}{(\lam{\_}{ \\
      &\app{\op{assert}}{(\app{\obj{own}}{x}{y})}{(\lam{\_}{ \\
      &\etaE{\star}})}})}})}})}
    \end{aligned}
\end{align*}

We can now compute the conjunction of $\sem{S_1}$ and $\dnot \sem{S_2}$ and
observe how the context of $\sem{S_1}$ cancels the presupposition in
$\dnot \sem{S_2}$.

\begin{align*}
  \sem{S_1} \dand \dnot \sem{S_2}
  &= \sem{S_1} \hsbind (\lam{\_}{\dnot \sem{S_2}}) \\
  &\tto \begin{aligned}[t]
      &\app{\op{presuppose}}{\obj{John}}{(\lam{x}{ \\
      &\app{\op{introduce}}{\star}{(\lam{y}{ \\
      &\app{\op{assert}}{(\ap{\obj{car}}{y})}{(\lam{\_}{ \\
      &\app{\op{assert}}{(\app{\obj{own}}{x}{y})}{(\lam{\_}{ \\
      &\app{\op{get}}{\star}{(\lam{e}{ \\
      &(\casenl{\app{\selP}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{(\ap{\sel}{e})}{z}})}{e}}
        {z}{\etaE{z}}
        {\_}{\ap{\op{presuppose}!}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{(\ap{\sel}{e})}{z}})}}) \hsbind (\lam{z}{ \\
      &\app{\op{assert}}{(\lnot (\ap{\obj{cheap}}{z}))}{\lam{\_}{ \\
      &\etaE{\star}}}})})}})}})}})}})}
    \end{aligned} \\
  &\approx \begin{aligned}[t]
      &\app{\op{presuppose}}{\obj{John}}{(\lam{x}{ \\
      &\app{\op{get}}{\star}{(\lam{e}{ \\
      &\app{\op{introduce}}{\star}{(\lam{y}{ \\
      &\app{\op{assert}}{(\ap{\obj{car}}{y})}{(\lam{\_}{ \\
      &\app{\op{assert}}{(\app{\obj{own}}{x}{y})}{(\lam{\_}{ \\
      &(\casenl{\app{\selP}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{(\ap{\sel}{e'})}{z}})}{e'}}
        {z}{\etaE{z}}
        {\_}{\ap{\op{presuppose}!}{(\lam{z}{\ap{\obj{car}}{z} \land \obj{own}(\sel(e'), z)})}}) \hsbind (\lam{z}{ \\
      &\app{\op{assert}}{(\lnot (\ap{\obj{cheap}}{z}))}{\lam{\_}{ \\
      &\etaE{\star}}}})})}})}})}})}})}
    \end{aligned}
\end{align*}

where

$$
e' = \app{\obj{own}}{x}{y} \cons \ap{\obj{car}}{y} \cons y \cons e
$$

We compose the two dynamic propositions by concatenating their effects. We
then make use of our equations from ~\ref{ssec:algebraic-drt} to move
$\op{get}$ above the $\op{introduce}$ and $\op{assert}$ to make it clear
that the context $e'$ that is given as argument to $\sel$ and $\selP$
contains the necessary material. We do not move $\op{get}$ above
$\op{presuppose}$ since we cannot predict how $\op{presuppose}$ will modify
the context: if the presupposition gets cancelled and bound by an existing
discourse referent, it does not modify the context, but if it is novel and
gets accommodated, then it introduces a new discourse referent into the
context. However, in all cases we can assume that after performing
$\ap{\op{presuppose}}{P}$, the context for the subsequent dynamic
operations will contain some referent $x$ satisfying the predicate
$P$. Assuming that the context $e$, and therefore by extension $e'$,
contains the discourse referent $x$ and the condition $\ap{\obj{John}}{x}$,
$\ap{\sel}{e'}$ can choose the $x$ as the antecedent for \emph{his}. We can
now compute the denotation of the noun phrase \emph{his car} in this
context and see that the presupposition is cancelled.

\begin{align*}
  &\casenl{\app{\selP}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{(\ap{\sel}{e'})}{z}})}{e'}}
          {z}{\etaE{z}}
          {\_}{\ap{\op{presuppose}!}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{(\ap{\sel}{e'})}{z}})}} \\
=\ &\casenl{\app{\selP}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{x}{z}})}{e'}}
          {z}{\etaE{z}}
          {\_}{\ap{\op{presuppose}!}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{x}{z}})}} \\
=\ &\casenl{\ap{\inl}{y}}
          {z}{\etaE{z}}
          {\_}{\ap{\op{presuppose}!}{(\lam{z}{\ap{\obj{car}}{z} \land \app{\obj{own}}{x}{z}})}} \\
\to_{\beta.+1}\ &\etaE{y}
\end{align*}

We can plug this result back into the computation for $\sem{S_1} \dand
\dnot \sem{S_2}$:

\begin{align*}
  &\sem{S_1} \dand \dnot \sem{S_2} \\
  &\tto \begin{aligned}[t]
      &\app{\op{presuppose}}{\obj{John}}{(\lam{x}{ \\
      &\app{\op{get}}{\star}{(\lam{e}{ \\
      &\app{\op{introduce}}{\star}{(\lam{y}{ \\
      &\app{\op{assert}}{(\ap{\obj{car}}{y})}{(\lam{\_}{ \\
      &\app{\op{assert}}{(\app{\obj{own}}{x}{y})}{(\lam{\_}{ \\
      &\etaE{y} \hsbind (\lam{z}{ \\
      &\app{\op{assert}}{(\lnot (\ap{\obj{cheap}}{z}))}{\lam{\_}{ \\
      &\etaE{\star}}}})})}})}})}})}})}
    \end{aligned} \\
  &\to_{\eta.\hsbind} \begin{aligned}[t]
      &\app{\op{presuppose}}{\obj{John}}{(\lam{x}{ \\
      &\app{\op{introduce}}{\star}{(\lam{y}{ \\
      &\app{\op{assert}}{(\ap{\obj{car}}{y})}{(\lam{\_}{ \\
      &\app{\op{assert}}{(\app{\obj{own}}{x}{y})}{(\lam{\_}{ \\
      &\app{\op{assert}}{(\lnot (\obj{cheap}(y)))}{\lam{\_}{ \\
      &\etaE{\star}}}})}})}})}})}
    \end{aligned}
\end{align*}

We use the $\to_{\eta.\hsbind}$ that we derived in
Proposition~\ref{prop:bind-rules} and we also drop the $\op{get}$ since we
no longer use the context $e$ (an equation from~\ref{ssec:algebraic-drt}
admissible under our handlers). The denotation of Example~\ref{ex:cancel}
is then the dynamic negation of this computation.

\begin{align*}
  \sem{\app{\abs{if-then}}{S_1}{S_2}}
  &= \sem{S_1} \dimp \sem{S_2} \\
  &= \dnot (\sem{S_1} \dand \dnot \sem{S_2}) \\
  &\tto \begin{aligned}[t]
    &\app{\op{get}}{\star}{(\lam{e}{ \\
    &(\casenl{\app{\selP}{\obj{John}}{e}}
       {x}{\etaE{x}}
       {\_}{\ap{\op{presuppose}!}{\obj{John}}}) \hsbind (\lam{x}{ \\
    &\app{\op{assert}}{(\lnot (\exists y.\, \ap{\obj{car}}{y} \land \app{\obj{own}}{x}{y} \land \lnot (\obj{cheap}(y))))}{(\lam{\_}{ \\
    &\etaE{\star}})}})})}
    \end{aligned}
\end{align*}

Note that the resulting denotation is still accessing the context to
determine whether it will presuppose the existence of John or whether it
will retrieve John from some (potentially hypothetical) context. This means
our solution is compositional and if we were to place this denotation
inside the following context, the presupposition of there being some
salient John will be cancelled:

\begin{exe}
  \ex If there is a poor man called John, then if John owns a car, his car
  is cheap. \label{ex:john-presupposed}
\end{exe}

If we consider the sentence of Example~\ref{ex:cancel} in an empty, ``out
of the blue'' context, into which John will need to be accommodated, we get
the intended reading.

\begin{align*}
  &\ap{\EMPTY}{(\ap{\TOP}{\sem{\app{\abs{if-then}}{S_1}{S_2}}})} \\
  &\tto \etaE{(\exists x.\ \ap{\obj{John}}{x} \land \lnot (\exists y.\, \ap{\obj{car}}{y} \land \app{\obj{own}}{x}{y} \land \lnot (\obj{cheap}(y))))} \\
  &= \etaE{(\exists x.\ \ap{\obj{John}}{x} \land (\forall y.\ (\ap{\obj{car}}{y} \land \app{\obj{own}}{x}{y}) \to \obj{cheap}(y)))}
\end{align*}


\subsection{Ambiguous Accommodation}
\label{ssec:ambiguous-accommodation}

Presuppositions do not always have to accommodate at the top
level. Consider the following example from~\cite{sep-presupposition}.

\begin{exe}
  \ex \label{ex:wilma} ($c_0$) Maybe ($c_1$) Wilma thinks that ($c_2$) her husband is having an affair.
\end{exe}

The NP \emph{her husband} presupposes that Wilma is married. If the
sentence is uttered in a context in which it was not yet established that
Wilma is married, the fact will need to be accomodated somewhere. We can do
so in the global context $c_0$, which would mean interpreting the sentence
as ``\emph{Wilma is married and maybe she thinks that her husband is having
  an affair}''. However, we can also accommodate the presupposition in the
intermediate context $c_1$ to get the interpretation ``\emph{Maybe Wilma is
  married and she thinks that her husband is having an affair}''. Finally,
we can even accommodate the presupposition in the local context $c_2$ to
get ``\emph{Maybe Wilma thinks that she is married and her husband is
  having an affair}''.

If we look at the different possible accommodation sites in
Example~\ref{ex:wilma}, we remark that they are all lexically
generated. There is the possible context/accommodation site $c_1$ in the
argument of the modal operator \emph{maybe} and there is $c_2$ in the
argument of the attitude verb \emph{think}. At these points, we would like
to be able to interrupt presuppositions and accommodate them. In
$\banana{\lambda}$, this would mean applying a $\op{presuppose}$ handler to
these arguments. However, at the same time, we want to also have the
reading in which the presupposition projects
out.

In~\ref{ssec:quantifier-ambiguity}, we dealt with ambiguity by changing the
syntax, moving quantifiers into their scope using $\abs{QR}$. This would
not be suitable for presuppositions since they can be accommodated in
positions which do not correspond to sentences (e.g.\ the restrictor of a
quantified noun phrase). This time, instead of having a different
abstract term for every possible reading, we will make it so that a single
object term (i.e.\ denotation) will represent multiple readings, as when
using underspecified representations. Our denotations are computations and
we want the denotations to evaluate to multiple different values. This is a
feature of nondeterministic computations and we can implement
nondeterminism using effects.

$$
\typedop{amb}{1}{2}
$$

The $\op{amb}$ operation allows us to branch into two different
computations. We can imagine this as asking an oracle or flipping a
coin. We give no input and we receive a Boolean: either $\true$
($\ap{\inl}{\star}$) or $\false$ ($\ap{\inr}{\star}$). A handler for
$\op{amb}$ might then consult some oracle, flip (pseudo-)random coins,
collect all the possibilities in a list or a set or just return one of the
results by always answering $\true$. If we look back to the algebraic
formulation of $\banana{\lambda}$ computations given in
Chapter~\ref{chap:definitions}, we find that $\op{amb}$ corresponds to a
single binary operation on computations. This algebraic notation will
actually be more useful then the computational one we usually use and so we
introduce the following:

\begin{align*}
  \_+\_ &: \FF_{E \uplus \{\op{amb}\}}(\alpha) \to \FF_{E \uplus \{\op{amb}\}}(\alpha) \to \FF_{E \uplus \{\op{amb}\}}(\alpha) \\
  M + N &= \app{\op{amb}}{\star}{(\lam{b}{\ifte{b}{M}{N}})}
\end{align*}

We can now write a handler that tries both projecting a presupposition and
accommodating it.

\begin{align*}
  \maybeAccommodate &: \FF_{E \uplus \{\op{presuppose}\}}(\alpha) \to
                      \FF_{E \uplus \{\op{presuppose},\op{amb}\}}(\alpha) \\
  \maybeAccommodate &= \banana{\onto{\op{presuppose}}{(\lam{P k}{
    \app{\op{presuppose}}{P}{k} +
    \app{\op{introduce}}{\star}{(\lam{x}{\app{\op{assert}}{(\ap{P}{x})}{(\lam{\_}{\ap{k}{x}})}})}})}}
\end{align*}

Now we need to include this handler into the lexical entries of our
grammar, wherever presuppositions can be accommodated. Here, we can follow
existing analyses. Projective DRT~\cite{venhuizen2013parsimonious} lets
presupposed content accommodate within DRSs on the projection
line. Lebedeva's use of exceptions for presuppositions in
TTDL~\cite{lebedeva2012expression} employs an exception handler
($\textsf{iacc}$) that allows for accommodation at every point where a
discourse referent is being bound (i.e.\ at every dynamic existential
quantification). We can achieve the same result in our $\banana{\lambda}$
analysis by including the $\maybeAccommodate$ in the $\DBOX$ handler:

\begin{align*}
  \DBOX &: \FF_{E \uplus E_\DRT \uplus \{\op{presuppose}\}}(1) \to \FF_{E \uplus \{\op{get}, \op{presuppose}, \op{amb}\}}(o) \\
  \DBOX &= \BOX \circ \maybeAccommodate \circ \useFind
\end{align*}

Now, if our semantics for the modal operator \emph{maybe} and the attitude
verb \emph{think} uses boxes, then we get as denotation of
Example~\ref{ex:wilma} a nondeterministic computation that yields the three
readings mentioned above. Looking back at those three readings,
\cite{sep-presupposition} states that while they are all possible, the
first reading (global accommodation at $c_0$) is strongly preferred to the
other readings. This is generalized to the following empirically motivated
principle:

\begin{quote}
PGA (Preference for Global Accommodation): Global accommodation is
preferred to non-global accommodation.
\flushright{\cite{sep-presupposition}, 5.1}
\end{quote}

If it were only for this principle, we might wonder why we bothered with
allowing accommodation in any DRS on the projection line instead of always
accommodating globally. However, there are other forces which push in the
opposite direction and impose constraints on presupposition projection. The
one that we will tend to in this section is the effect of variable
binding. A proposition being presupposed cannot escape the scope of a
binder that binds one of its variables. In~\cite{sep-presupposition}, this
is illustrated on the following example.

\begin{exe}
  \ex \label{ex:most-germans-wash} Most Germans wash their car on Saturday.
\end{exe}

The expression \emph{their car} triggers the presupposition of the
existence of a car belonging to the referent of \emph{their}. We could
accommodate this presupposition locally, in the nucleus of the quantifier
\emph{most Germans}, giving the reading ``\emph{Most Germans have a car and
  they wash it on Saturday.}''. We could also accommodate it in the
restrictor of that quantifier (which is accessible, i.e.\ on the projection
line, from the nucleus), giving us ``\emph{Most Germans who have a car wash
  it on Saturday}''.

However, we cannot get the global accommodation reading. The problem is
that the referent of \emph{their} is a variable being quantified over by
the quantifier \emph{most Germans}. If this variable is $x$, then the
presupposition being triggered is the existence of an individual satisfying
$\lam{y}{\ap{\obj{car}}{y} \land \app{\obj{own}}{x}{y}}$. This predicate contains a
free variable $x$, which means that for every different value $x$, we
actually have a different predicate that identifies a different car. The
solution to this \emph{binding problem} in theories that implement
accommodation, such as van der Sandt's DRT
approach~\cite{van1992presupposition} and Lebedeva's extension of
TTDL~\cite{lebedeva2012expression}, is to reflect this logical
impossibility into a linguistic constraint. Presupposed material cannot
project out of a binder that binds some part of that material.

We will look at how a similar example turns out in our system.

\begin{exe}
  \ex \label{ex:man-angry} ($c_0$) If ($c_1$) a man gets angry, ($c_2$) his
  children get frightened.
\end{exe}

Example~\ref{ex:man-angry}, taken from~\cite{van1992presupposition}, is
similar in nature to Example~\ref{ex:most-germans-wash}. We have a
presupposition trigger which can be accommodated in a local context ($c_2$)
and in an intermediate context ($c_1$), but not in the global context
($c_0$), because of a bound variable. Furthermore,
Example~\ref{ex:man-angry} is built out of constructions we have already
covered and so we are ready to compute the denotation. We do not analyze
the construction \emph{$X$'s children} as a possessive
($\app{\abs{poss}}{X}{\abs{children}}$), which would refer to some children
owned by $X$. Since \emph{children} is a relational noun, we assume a
binary relation $\app{\obj{children}}{y}{x}$ expressing that $y$ are children of
$x$. We then analyze \emph{$X$'s children} as $\ap{\abs{children}}{X}$
where the semantics of $\abs{children}$ makes use of the relation
$\obj{children}$. For the construction \emph{$X$ gets $A$}, where $A$ is an
adjective, we introduce the abstract constant $\abs{get}$.

\begin{align*}
  \abs{children} &: NP \limp NP \\
  \lex{children}{\lam{X}{X \hsbind (\lam{x}{\ap{\op{presuppose}!}{(\lam{y}{\app{\obj{children}}{y}{x}})}})}} \\
  \abs{get} &: ADJ \limp NP \limp S \\
  \sem{ADJ} &= \iota \to o \\
  \lex{get}{\lam{a X}{X \hsbind (\lam{x}{\ap{\op{assert}!}{(\ap{a}{x})}})}}
\end{align*}

We can now compute the denotation of Example~\ref{ex:man-angry}. The
structure of Example~\ref{ex:man-angry} is $\app{\abs{if-then}}{S_1}{S_2}$
where $S_1$ and $S_2$ are the antecedent and consequent, respectively. Its
semantics, $\sem{\app{\abs{if-then}}{S_1}{S_2}}$, is
$S_1 \dimp S_2 = \dnot (\sem{S_1} \dand \dnot \sem{S_2})$. We start with
the denotation of the consequent $S_2$: \emph{his children get frightened}.

\begin{align*}
  \sem{S_2}
  &= \sem{\app{\abs{get}}{\abs{frightened}}{(\ap{\abs{children}}{\abs{he}})}} \\
  &\tto 
    \begin{aligned}[t]
      (&\app{\op{get}}{\star}{(\lam{e}{ \\
       &\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{(\ap{\sel}{e})}})}{(\lam{y}{ \\
       &\app{\op{assert}}{(\ap{\obj{frightened}}{y})}{(\lam{\_}{ \\
       &\etaE{\star}})}})}})})
    \end{aligned}
\end{align*}

Our next step will be computing $\dnot \sem{S_2}$. Dynamic negation is
defined by boxing and then asserting the negation of the boxed
proposition. We start by boxing $\sem{S_2}$, i.e.\ evaluating
$\ap{\DBOX}{\sem{S_2}}$.

\begin{align*}
  \ap{\DBOX}{\sem{S_2}}
  &\tto \ap{\DBOX}{
    \begin{aligned}[t]
      (&\app{\op{get}}{\star}{(\lam{e}{ \\
       &\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{(\ap{\sel}{e})}})}{(\lam{y}{ \\
       &\app{\op{assert}}{(\ap{\obj{frightened}}{y})}{(\lam{\_}{ \\
       &\etaE{\star}})}})}})})
    \end{aligned}} \\
  &= \ap{\BOX}{(\ap{\maybeAccommodate}{(\ap{\useFind}{
    \begin{aligned}[t]
      (&\app{\op{get}}{\star}{(\lam{e}{ \\
       &\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{(\ap{\sel}{e})}})}{(\lam{y}{ \\
       &\app{\op{assert}}{(\ap{\obj{frightened}}{y})}{(\lam{\_}{ \\
       &\etaE{\star}})}})}})})
    ))\end{aligned}}}} \\
  &\tto \ap{\BOX}{(\ap{\maybeAccommodate}{
    \begin{aligned}[t]
      (&\app{\op{get}}{\star}{(\lam{e}{ \\
       &\app{\op{get}}{\star}{(\lam{e}{ \\
       &\casenl{\app{\selP}{(\lam{y}{\app{\obj{children}}{y}{(\ap{\sel}{e})}})}{e}}{y}{\etaE{y}}{\_}{\ap{\op{presuppose}!}{(\lam{y}{\app{\obj{children}}{y}{(\ap{\sel}{e})}})}} \hsbind (\lam{y}{ \\
       &\app{\op{assert}}{(\ap{\obj{frightened}}{y})}{(\lam{\_}{ \\
       &\etaE{\star}})}})})}})})
    )\end{aligned}}} \\
  &\approx \ap{\BOX}{(\ap{\maybeAccommodate}{
    \begin{aligned}[t]
      (&\app{\op{get}}{\star}{(\lam{e}{ \\
       &\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{(\ap{\sel}{e})}})}{(\lam{y}{ \\
       &\app{\op{assert}}{(\ap{\obj{frightened}}{y})}{(\lam{\_}{ \\
       &\etaE{\star}})}})}})})
    )\end{aligned}}} \\
  &\tto \ap{\BOX}{
    \begin{aligned}[t]
      (&\app{\op{get}}{\star}{(\lam{e}{ \\
       &\quad \begin{aligned}[t]
           (&\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{(\ap{\sel}{e})}})}{(\lam{y}{ \\
            &\app{\op{assert}}{(\ap{\obj{frightened}}{y})}{(\lam{\_}{ \\
            &\etaE{\star}})}})})
           \end{aligned} \\
       &+ \begin{aligned}[t]
           (&\app{\op{introduce}}{\star}{(\lam{y}{ \\
            &\app{\op{assert}}{(\app{\obj{children}}{y}{(\ap{\sel}{e})})}{(\lam{\_}{ \\
            &\app{\op{assert}}{(\ap{\obj{frightened}}{y})}{(\lam{\_}{ \\
            &\etaE{\star}})}})}})})})})
          \end{aligned}
    \end{aligned}} \\
  &\tto
    \begin{aligned}[t]
      &\app{\op{get}}{\star}{(\lam{e}{ \\
      &\quad \begin{aligned}[t]
          (&\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{(\ap{\sel}{e})}})}{(\lam{y}{ \\
           &\etaE{(\ap{\obj{frightened}}{y})}})})
         \end{aligned} \\
      &+ (\etaE{(\exists y.\, \app{\obj{children}}{y}{(\ap{\sel}{e})} \land \ap{\obj{frightened}}{y})})})}
    \end{aligned}
\end{align*}

$\DBOX$ is composed of $\BOX$, $\maybeAccommodate$ and $\useFind$. We apply
all of these handlers in turn. We start with $\useFind$, where we assume
that the sentence is uttered in a context in which the existence of
\emph{his children} was not established. This means that $\selP$ will not
find a referent within $e$ and the presupposition will not be cancelled. We
also rely on the idempotence of $\op{get}$ to collapse the two $\op{get}$s
into one and so $\useFind$ ends up having no effect. Next up is
$\maybeAccommodate$ that tries both projecting the presupposition and
accommodating it using $\op{introduce}$ and $\op{assert}$. Finally, $\BOX$
translates the dynamic propositions that use $\op{introduce}$ and
$\op{assert}$ into simple propositions. We have one proposition with a
presupposition projecting out of it and another one in which the
presupposition was accommodated using an existential quantifier. The
dynamic negation will negate these propositions and wrap them in
$\op{assert}$:

\begin{align*}
  \dnot \sem{S_2}
  &= \ap{\DBOX}{\sem{S_2}} \hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}}) \\
  &\tto 
    \begin{aligned}[t]
      &\app{\op{get}}{\star}{(\lam{e}{ \\
      &\quad \begin{aligned}[t]
          (&\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{(\ap{\sel}{e})}})}{(\lam{y}{ \\
           &\etaE{(\ap{\obj{frightened}}{y})}})})
         \end{aligned} \\
      &+ (\etaE{(\exists y.\, \app{\obj{children}}{y}{(\ap{\sel}{e})} \land \ap{\obj{frightened}}{y})}) \\
      &\hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}})})}
       \end{aligned} \\
  &\tto 
    \begin{aligned}[t]
      &\app{\op{get}}{\star}{(\lam{e}{ \\
      &\quad \begin{aligned}[t]
          (&\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{(\ap{\sel}{e})}})}{(\lam{y}{ \\
           &\app{\op{assert}}{(\lnot (\ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}})})
         \end{aligned} \\
      &+ \begin{aligned}[t]
          (&\app{\op{assert}}{(\lnot (\exists y.\, \app{\obj{children}}{y}{(\ap{\sel}{e})} \land \ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}))
         \end{aligned}}}
    \end{aligned}
\end{align*}

We now turn to the antecedent $S_1$: \emph{a man gets angry}.

\begin{align*}
  \sem{S_1}
  &= \sem{\app{\abs{get}}{\abs{angry}}{(\ap{\abs{a}}{(\ap{\abs{common}}{\abs{man}})})}} \\
  &\tto \begin{aligned}[t]
      &\app{\op{introduce}}{\star}{(\lam{x}{ \\
      &\app{\op{assert}}{(\ap{\obj{man}}{x})}{(\lam{\_}{ \\
      &\app{\op{assert}}{(\ap{\obj{angry}}{x})}{(\lam{\_}{ \\
      &\etaE{\star}})}})}})}
    \end{aligned}
\end{align*}

The denotation of Example~\ref{ex:man-angry} is
$\dnot (\sem{S_1} \dand \dnot \sem{S_2})$ and so we have to compute
$\sem{S_1} \dand \dnot \sem{S_2}$ and then the dynamic negation of the
result.

\begin{align*}
  \sem{S_1} \dand \dnot \sem{S_2}
  &= \sem{S_1} \hsbind (\lam{\_}{\dnot \sem{S_2}}) \\
  &\tto \begin{aligned}[t]
      &\app{\op{introduce}}{\star}{(\lam{x}{ \\
      &\app{\op{assert}}{(\ap{\obj{man}}{x})}{(\lam{\_}{ \\
      &\app{\op{assert}}{(\ap{\obj{angry}}{x})}{(\lam{\_}{ \\
      &\app{\op{get}}{\star}{(\lam{e}{ \\
      &\quad \begin{aligned}[t]
          (&\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{(\ap{\sel}{e})}})}{(\lam{y}{ \\
           &\app{\op{assert}}{(\lnot (\ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}})})
         \end{aligned} \\
      &+ \begin{aligned}[t]
          (&\app{\op{assert}}{(\lnot (\exists y.\, \app{\obj{children}}{y}{(\ap{\sel}{e})} \land \ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})})))))
         \end{aligned}}}}}}}}}
    \end{aligned}
\end{align*}

We start computing $\dnot (\sem{S_1} \dand \dnot \sem{S_2})$ by boxing
$\sem{S_1} \dand \dnot \sem{S_2}$:

\begin{align*}
  &\ap{\DBOX}{(\sem{S_1} \dand \dnot \sem{S_2})} \\
  &\tto \ap{\DBOX}{(\begin{aligned}[t]
      &\app{\op{introduce}}{\star}{(\lam{x}{ \\
      &\app{\op{assert}}{(\ap{\obj{man}}{x})}{(\lam{\_}{ \\
      &\app{\op{assert}}{(\ap{\obj{angry}}{x})}{(\lam{\_}{ \\
      &\app{\op{get}}{\star}{(\lam{e}{ \\
      &\quad \begin{aligned}[t]
          (&\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{(\ap{\sel}{e})}})}{(\lam{y}{ \\
           &\app{\op{assert}}{(\lnot (\ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}})})
         \end{aligned} \\
      &+ \begin{aligned}[t]
          (&\app{\op{assert}}{(\lnot (\exists y.\, \app{\obj{children}}{y}{(\ap{\sel}{e})} \land \ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}))))))
         \end{aligned}}}}}}}}}
    \end{aligned}} \\
  &\tto \ap{\BOX}{(\ap{\maybeAccommodate}{(\begin{aligned}[t]
      &\app{\op{introduce}}{\star}{(\lam{x}{ \\
      &\app{\op{assert}}{(\ap{\obj{man}}{x})}{(\lam{\_}{ \\
      &\app{\op{assert}}{(\ap{\obj{angry}}{x})}{(\lam{\_}{ \\
      &\app{\op{get}}{\star}{(\lam{e}{ \\
      &\quad \begin{aligned}[t]
          (&\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{(\ap{\sel}{e})}})}{(\lam{y}{ \\
           &\app{\op{assert}}{(\lnot (\ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}})})
         \end{aligned} \\
      &+ \begin{aligned}[t]
          (&\app{\op{assert}}{(\lnot (\exists y.\, \app{\obj{children}}{y}{(\ap{\sel}{e})} \land \ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})})))))))
         \end{aligned}}}}}}}}}
    \end{aligned}}} \\
  &\tto \ap{\BOX}{(\begin{aligned}[t]
      &\app{\op{introduce}}{\star}{(\lam{x}{ \\
      &\app{\op{assert}}{(\ap{\obj{man}}{x})}{(\lam{\_}{ \\
      &\app{\op{assert}}{(\ap{\obj{angry}}{x})}{(\lam{\_}{ \\
      &\app{\op{get}}{\star}{(\lam{e}{ \\
      &\quad \begin{aligned}[t]
          (&\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{(\ap{\sel}{e})}})}{(\lam{y}{ \\
           &\app{\op{assert}}{(\lnot (\ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}})})
         \end{aligned} \\
      &+ \begin{aligned}[t]
          (&\app{\op{introduce}}{\star}{(\lam{y}{ \\
           &\app{\op{assert}}{(\app{\obj{children}}{y}{(\ap{\sel}{e})})}{(\lam{\_}{ \\
           &\app{\op{assert}}{(\lnot (\ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}})}})})
         \end{aligned} \\
      &+ \begin{aligned}[t]
          (&\app{\op{assert}}{(\lnot (\exists y.\, \app{\obj{children}}{y}{(\ap{\sel}{e})} \land \ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}))))))
         \end{aligned}}}}}}}}}
    \end{aligned}} \\
  &\approx \ap{\BOX}{(\begin{aligned}[t]
      &\app{\op{get}}{\star}{(\lam{e}{ \\
      &\app{\op{introduce}}{\star}{(\lam{x}{ \\
      &\app{\op{assert}}{(\ap{\obj{man}}{x})}{(\lam{\_}{ \\
      &\app{\op{assert}}{(\ap{\obj{angry}}{x})}{(\lam{\_}{ \\
      &\quad \begin{aligned}[t]
          (&\app{\op{presuppose}}{(\lam{y}{\obj{children}(y, \ap{\sel}{(\ap{\obj{angry}}{x} \cons \ap{\obj{man}}{x} \cons x \cons e)})})}{(\lam{y}{ \\
           &\app{\op{assert}}{(\lnot (\ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}})})
         \end{aligned} \\
      &+ \begin{aligned}[t]
          (&\app{\op{introduce}}{\star}{(\lam{y}{ \\
           &\app{\op{assert}}{(\obj{children}(y, \ap{\sel}{(\ap{\obj{angry}}{x} \cons \ap{\obj{man}}{x} \cons x \cons e)}))}{(\lam{\_}{ \\
           &\app{\op{assert}}{(\lnot (\ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}})}})})
         \end{aligned} \\
      &+ \begin{aligned}[t]
          (&\app{\op{assert}}{(\lnot (\exists y.\, \obj{children}(y, \ap{\sel}{(\ap{\obj{angry}}{x} \cons \ap{\obj{man}}{x} \cons x \cons e)}) \land \ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}))))))
         \end{aligned}}}}}}}}}
    \end{aligned}}
\end{align*}

We skip $\useFind$, since, as before, it does not cancel any
presupposition. Then $\maybeAccommodate$ will take the presupposition and
consider the two alternatives: projecting this presupposition further down
the projection line or accommodating it here, in the antecedent. In the
last step, we commute $\op{get}$ with $\op{introduce}$ and $\op{assert}$
using the equations from~\ref{ssec:algebraic-drt}. This makes it more
obvious that $x$ is one of the available discourse referents for the
pronoun \emph{his} in the consequent. Assuming that this pronoun will
actually resolve to $x$ and not to some other referent (i.e.\
$\ap{\sel}{(\ap{\obj{angry}}{x} \cons \ap{\obj{man}}{x} \cons x \cons e)} = x$), then the
argument to $\op{presuppose}$ will be $\lam{y}{\app{\obj{children}}{y}{x}}$, in
which $x$ occurs free.

The computation is nondeterministic and uses $\op{amb}$ ($+$) to split into
three possible interpretations:

\begin{itemize}
\item projecting the presupposition out of the conditional (the way of
  global accommodation)
\item accommodating the presupposition at the level of the entire
  conditional (intermediate accommodation)
\item accommodating the presupposition already at the level of the
  consequent of the conditional (local accommodation)
\end{itemize}

We continue by applying the $\BOX$ handler.

\begin{align*}
   &\ap{\BOX}{(\begin{aligned}[t]
      &\app{\op{get}}{\star}{(\lam{e}{ \\
      &\app{\op{introduce}}{\star}{(\lam{x}{ \\
      &\app{\op{assert}}{(\ap{\obj{man}}{x})}{(\lam{\_}{ \\
      &\app{\op{assert}}{(\ap{\obj{angry}}{x})}{(\lam{\_}{ \\
      &\quad \begin{aligned}[t]
          (&\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{x}})}{(\lam{y}{ \\
           &\app{\op{assert}}{(\lnot (\ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}})})
         \end{aligned} \\
      &+ \begin{aligned}[t]
          (&\app{\op{introduce}}{\star}{(\lam{y}{ \\
           &\app{\op{assert}}{(\app{\obj{children}}{y}{x})}{(\lam{\_}{ \\
           &\app{\op{assert}}{(\lnot (\ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}})}})})
         \end{aligned} \\
      &+ \begin{aligned}[t]
          (&\app{\op{assert}}{(\lnot (\exists y.\, \app{\obj{children}}{y}{x} \land \ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
           &\etaE{\star}})}))))))
         \end{aligned}}}}}}}}}
    \end{aligned}} \\
   &\ttoffrom \begin{aligned}[t]
      &\begin{aligned}[t]
         \ap{\BOX}{(&\app{\op{introduce}}{\star}{(\lam{x}{ \\
                    &\app{\op{assert}}{(\ap{\obj{man}}{x})}{(\lam{\_}{ \\
                    &\app{\op{assert}}{(\ap{\obj{angry}}{x})}{(\lam{\_}{ \\
                    &\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{x}})}{(\lam{y}{ \\
                    &\app{\op{assert}}{(\lnot (\ap{\obj{frightened}}{y}))}{(\lam{\_}{ \\
                    &\etaE{\star}})}})}})}})}})})}
       \end{aligned} \\
      &+ \etaE{(\exists x.\ \ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land
                \exists y.\, \app{\obj{children}}{y}{x} \land
                \lnot (\ap{\obj{frightened}}{y}))} \\
      &+ \etaE{(\exists x.\ \ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land
                \lnot (\exists y.\, \app{\obj{children}}{y}{x} \land \ap{\obj{frightened}}{y}))}
    \end{aligned} \\
   &\tto \begin{aligned}[t]
      &\existsr x.\, \begin{aligned}[t]
          &\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{x}})}{(\lam{y}{ \\
          &\etaE{(\ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land \lnot (\ap{\obj{frightened}}{y}))}})}
        \end{aligned} \\
      &+ \etaE{(\exists x.\ \ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land
                \exists y.\, \app{\obj{children}}{y}{x} \land
                \lnot (\ap{\obj{frightened}}{y}))} \\
      &+ \etaE{(\exists x.\ \ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land
                \lnot (\exists y.\, \app{\obj{children}}{y}{x} \land \ap{\obj{frightened}}{y}))}
    \end{aligned}
\end{align*}

As a result, we get two propositions and one stuck computation. The two
propositions will (after negation) gives us the intermediate accommodation
reading and the local accommodation reading, whereas the stuck computation
represents the impossibility of the global accommodation reading. The term
$\existsr x.\,
\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{x}})}{M_\petitc}$ is
stuck, because when we expand $\existsr$, it becomes
$\exists \apr
(\ap{\CC}{(\lam{x}{\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{x}})}{M_\petitc}})})$. There
is no rule in $\banana{\lambda}$ to reduce
$\ap{\CC}{(\lam{x}{\app{\op{presuppose}}{M_\petitp}{M_\petitc}})}$ when $x$
occurs free in $M_\petitp$ and the $\banana{\lambda}$ denotational
semantics would assign $\bot$ to this expression.

We finish computing the denotation of Example~\ref{ex:man-angry} by
wrapping up the dynamic negation: negating and asserting the propositions.

\begin{align*}
  \sem{\app{\abs{if-then}}{S_1}{S_2}}
  &= \dnot (\sem{S_1} \dand \dnot \sem{S_2}) \\
  &= \ap{\DBOX}{(\sem{S_1} \dand \dnot \sem{S_2})} \hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}}) \\
  &\tto \begin{aligned}[t]
    &(\existsr x.\, \begin{aligned}[t]
         &\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{x}})}{(\lam{y}{ \\
         &\etaE{(\ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land \lnot (\ap{\obj{frightened}}{y}))}})}
       \end{aligned} \\
    &+ \etaE{(\exists x.\ \ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land
              \exists y.\, \app{\obj{children}}{y}{x} \land
              \lnot (\ap{\obj{frightened}}{y}))} \\
    &+ \etaE{(\exists x.\ \ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land
              \lnot (\exists y.\, \app{\obj{children}}{y}{x} \land
              \ap{\obj{frightened}}{y}))})
    \end{aligned} \\
  &\qquad \hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}}) \\
  &\tto\footnotemark \begin{aligned}[t]
     &((\existsr x.\, \begin{aligned}[t]
         &\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{x}})}{(\lam{y}{ \\
         &\etaE{(\ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land \lnot (\ap{\obj{frightened}}{y}))}})}) \\
         &\hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}})) \\
       \end{aligned} \\
     &+ (\begin{aligned}[t]
           &\etaE{(\exists x.\ \ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land
                   \exists y.\, \app{\obj{children}}{y}{x} \land
                   \lnot (\ap{\obj{frightened}}{y}))} \\
           &\hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}}))
         \end{aligned} \\
     &+ (\begin{aligned}[t]
           &\etaE{(\exists x.\ \ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land
                  \lnot (\exists y.\, \app{\obj{children}}{y}{x} \land
                  \ap{\obj{frightened}}{y}))} \\
           &\hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}}))
         \end{aligned}
    \end{aligned} \\
  &\tto \begin{aligned}[t]
     &((\existsr x.\, \begin{aligned}[t]
         &\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{x}})}{(\lam{y}{ \\
         &\etaE{(\ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land \lnot (\ap{\obj{frightened}}{y}))}})}) \\
         &\hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}})) \\
       \end{aligned} \\
     &+ (\ap{\op{assert}!}
          {(\lnot (\exists x.\ \ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land
                   \exists y.\, \app{\obj{children}}{y}{x} \land
                   \lnot (\ap{\obj{frightened}}{y})))}) \\
     &+ (\ap{\op{assert}!}
          {(\lnot (\exists x.\ \ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land
                   \lnot (\exists y.\, \app{\obj{children}}{y}{x} \land
                   \ap{\obj{frightened}}{y})))}) \\
   \end{aligned} \\
  &= \begin{aligned}[t]
     &((\existsr x.\, \begin{aligned}[t]
         &\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{x}})}{(\lam{y}{ \\
         &\etaE{(\ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land \lnot (\ap{\obj{frightened}}{y}))}})}) \\
         &\hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}})) \\
       \end{aligned} \\
     &+ (\ap{\op{assert}!}
          {(\forall x y.\ (\ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land
                          \app{\obj{children}}{y}{x}) \to \ap{\obj{frightened}}{y})}) \\
     &+ (\ap{\op{assert}!}
          {(\forall x.\ (\ap{\obj{man}}{x} \land \ap{\obj{angry}}{x}) \to (\exists y.\, \app{\obj{children}}{y}{x} \land \ap{\obj{frightened}}{y}))})
   \end{aligned}
\end{align*}

\footnotetext{Here we are making use of the following rule:
  $(A + B) \hsbind F \, \to \, (A \hsbind F) + (B \hsbind F)$. However,
  this rule is not derivable in $\calc$. The $A + B$ is de-sugared into two
  parts: the $\op{amb}$ operation and an if expression (case analysis). The
  $\op{op}.\hsbind$ rule lets us move the $\hsbind$ under the
  operation. However, we have no rule which lets us commute a $\hsbind$
  (which is a handler) and case analysis (we will speak more about this
  in~\ref{ssec:future-work-calculus}). Nevertheless, in this example, we
  permit ourselves to apply this rule as it does not affect the denotation
  of the term nor the final value and makes the notation a bit more
  bearable. If we were stricter, we would not be able to proceed with the
  $\hsbind$ until after we have selected the preferred reading using the
  $\search$ handler that we will present next.}

In the steps above, we pass $\hsbind$ operator through the $\op{amb}$
operation symbol, which is represented by $+$. We then perform the negation
and assertion on the two successful computations. We also change the
resulting propositions into equivalent but more readable ones. The
resulting denotation is a nondeterministic computation that can either
produce the intermediate accommodation reading (``\emph{If a man who has
  children gets angry, then his children get frightened}''), the local
accommodation reading (``\emph{If a man gets angry, then he also has
  children who get frightened}'') or get stuck. The PGA principle holds
here since the intermediate accommodation reading is preferred to the local
accommodation one.

We can write a handler that will recover the reading where the
presupposition projects as far as possible without getting blocked by a
binding. Our operation symbol for nondeterminism was called $\op{amb}$
because of its similarity to McCarthy's $amb$ operator for writing
ambiguous (i.e.\ nondeterministic)
functions~\cite{mccarthy1961basis,abelson1996structure}. The expression
$C[amb(M, N)]$ reduces to either $C[M]$ or $C[N]$, provided that the
resulting expression successfully produces a value. This kind of choice
operator is sometimes called ``angelic'' because it watches out for us by
making choices that will lead to a successful evaluation. This is the kind
of oversight we need in our choice operator as well. Consider the
$\op{presuppose}$ clause of the $\maybeAccommodate$ handler:

$$
  \maybeAccommodate = \banana{\onto{\op{presuppose}}{(\lam{P k}{
    \app{\op{presuppose}}{P}{k} +
    \app{\op{introduce}}{\star}{(\lam{x}{\app{\op{assert}}{(\ap{P}{x})}{k}})}})}}
$$

Neither $\app{\op{presuppose}}{P}{k}$ nor
$\app{\op{introduce}}{\star}{(\lam{x}{\app{\op{assert}}{(\ap{P}{x})}{k}})}$
are stuck computations, but if in some larger context we decide to choose,
e.g., the former, we might end up being stuck. This was the case in the
denotation of Example~\ref{ex:man-angry}: we decided twice to project the
presupposition and later, when we applied the $\BOX$ handler, we were
stuck.

The $amb$ operator can be implemented in Scheme using
continuations~\cite{sitaram1998teach} and so we should be able to do the
same using effects and handlers in $\banana{\lambda}$. We will give $amb$
the following semantics: $C[amb(M, N)]$ reduces to $C[M]$ if $C[M]$ reduces
to a value; otherwise, $C[amb(M, N)]$ reduces to $N$. Our choice operator
will be left-leaning, preferring to take the first choice but accepting the
second if the first one leads to a failure. This way, we can encode a
notion of preference into the choices. As when implementing $\shift$ in
Chapter~\ref{chap:continuations}, we will use an operation for the $amb$
operator, the $\op{amb}$ operation symbol, written using $+$, and a handler
to delimit the context $C$ whose result we do not want to get stuck.

\begin{align*}
  \search &: \FF_{E \uplus \{\op{amb}\}}(\alpha) \to \FF_E(\alpha) \\
  \search &= \banana{\onto{\op{amb}}{(\lam{\_ k}{\ap{k}{\true};\ \ap{k}{\false}})}}
\end{align*}

In the above, we use a new construction $M; N$. The $amb$ operator
considers the result of a decision inside some context and then checks
whether the result is a success or not in order to decide. The provisioning
of the context is handled by $\search$, whereas checking whether a
computation is stuck is done by the $M; N$ construction. The idea behind
$M; N$ is that $M; N$ should reduce to $N$ if $M$ is stuck; otherwise, it
should reduce to $M$. We will give a formal definition shortly.

If we apply this handler to the denotation of Example~\ref{ex:man-angry},
we will get the inteded reading: the one in which the presupposition
projects as widely as possible without violating binding.\footnote{If we
  wanted to retrieve all admissible readings, we could write a handler that
  would use the $M; N$ construction to build a list containing all the
  non-stuck solutions.}

\begin{align*}
  \ap{\search}{\sem{\app{\abs{if-then}}{S_1}{S_2}}}
  &\tto \ap{\search}{(\begin{aligned}[t]
     &((\existsr x.\, \begin{aligned}[t]
         &\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{x}})}{(\lam{y}{ \\
         &\etaE{(\ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land \lnot (\ap{\obj{frightened}}{y}))}})}) \\
         &\hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}})) \\
       \end{aligned} \\
     &+ (\ap{\op{assert}!}
          {(\forall x y.\ (\ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land
                          \app{\obj{children}}{y}{x}) \to \ap{\obj{frightened}}{y})}) \\
     &+ (\ap{\op{assert}!}
          {(\forall x.\ (\ap{\obj{man}}{x} \land \ap{\obj{angry}}{x}) \to (\exists y.\, \app{\obj{children}}{y}{x} \land \ap{\obj{frightened}}{y}))}))
   \end{aligned}} \\
  &\tto \begin{aligned}[t]
     &((\existsr x.\, \begin{aligned}[t]
         &\app{\op{presuppose}}{(\lam{y}{\app{\obj{children}}{y}{x}})}{(\lam{y}{ \\
         &\etaE{(\ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land \lnot (\ap{\obj{frightened}}{y}))}})}) \\
         &\hsbind (\lam{a}{\ap{\op{assert}!}{(\lnot a)}})); \\
       \end{aligned} \\
     &(\ap{\op{assert}!}
        {(\forall x y.\ (\ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land
                        \app{\obj{children}}{y}{x}) \to \ap{\obj{frightened}}{y})}); \\
     &(\ap{\op{assert}!}
        {(\forall x.\ (\ap{\obj{man}}{x} \land \ap{\obj{angry}}{x}) \to (\exists y.\, \app{\obj{children}}{y}{x} \land \ap{\obj{frightened}}{y}))})
   \end{aligned} \\
  &\tto \ap{\op{assert}!}
          {(\forall x y.\ (\ap{\obj{man}}{x} \land \ap{\obj{angry}}{x} \land
                           \app{\obj{children}}{y}{x}) \to \ap{\obj{frightened}}{y})}
\end{align*}


\subsubsection{Identifying Stuck Computations}

We will now give a formal semantics to the $M; N$ construction. We will not
specify the reduction relation as a reduction rule using pattern matching
because stuck computations are not easy to distinguish syntactically. The
stuck redex can be buried deep within the term $M$ and even if $M$ contains
a stuck redex, it is possible that this redex might disappear through some
other reduction and therefore not cause the resulting computation to get
stuck. Instead of identifying stuck computations syntactically, we will use
our denotational semantics from~\ref{ssec:denotational-semantics}, which
already identifies stuck computations with $\bot$. However, the
constructors for computation types are not strict. If their arguments are
$\bot$, the results do not have to be (e.g.\ if $\sem{M}(e) = \bot$, then
$\sem{\etaE{M}}(e) = \eta(\bot) \neq \bot$). We will consider a computation
successful if it does not contain $\bot$, a notion we define formally as
being $\bot$-less. But first, we give the typing rule for $M; N$
expressions.

\begin{definition}\label{def:semi-typing-rule}
  The \demph{types of $M; N$} are given by the following inference rule:

   \begin{prooftree}
    \AxiomC{$\Gamma \vdash M : \alpha$}
    \AxiomC{$\Gamma \vdash N : \alpha$}
    \RightLabel{$[;]$}
    \BinaryInfC{$\Gamma \vdash M; N : \alpha$}
  \end{prooftree}
\end{definition}

\begin{definition}
  For every $\banana{\lambda}$ type $\tau$, we define a predicate
  ``\demph{is $\bot$-less}'' on the domain of $\tau$, $\sem{\tau}$.

  By induction on the structure of type $\tau$:

  \begin{itemize}
  \item $x \in \sem{\nu}$ is $\bot$-less if $x \neq \bot$
  \item $f \in \sem{\alpha \to \beta}$ is $\bot$-less if $f \neq \bot$ and
    for every $\bot$-less $x \in \sem{\alpha}$, $f(x)$ is $\bot$-less
  \item $e \in \sem{\FF_E(\gamma)}$, by induction on the structure of $e$
    \begin{itemize}
    \item $\bot$ is not $\bot$-less
    \item $\eta(x)$ is $\bot$-less if $x$ is $\bot$-less
    \item $\op{op}(p, c)$ is $\bot$-less if $p$ is $\bot$-less and for
      every $x \in \sem{\beta}$, $c(x)$ is $\bot$-less
      ($\typedop{op}{\alpha}{\beta} \in E$)
    \end{itemize}
  \end{itemize}
\end{definition}

\begin{definition}
  For $\Gamma \vdash M; N : \tau$, the \demph{interpretation $\sem{M; N}$}
  is defined as the following function from $\sem{\Gamma}$ to $\sem{\tau}$:

  $$
  \sem{M; N}(e) = \begin{cases}
    \sem{M}(e), & \text{if $\sem{M}(e)$ is $\bot$-less} \\
    \sem{N}(e), & \text{otherwise}
  \end{cases}
  $$
\end{definition}

We now have a denotational semantics for $M; N$. We can use this
denotational semantics to produce a reduction semantics for the
construction.

\begin{definition}\label{def:semi-reduction-rule}
  We define a binary \demph{reduction relation $R_;$} on the terms of
  $\banana{\lambda}$. We write $\to_;$ for its context
  closure.\footnote{The notion of evaluation context being expanded to
    include $C ::= C; M\ |\ M; C$.}
  
  \begin{itemize}
  \item $(M; N) \; R_; \; M$ if for every $\Gamma$ and $\tau$ such that
    $\Gamma \vdash M; N : \tau$ and for every $e \in \sem{\Gamma}$,
    $\sem{M}(e)$ is $\bot$-less
  \item $(M; N) \; R_; \; N$ if for every $\Gamma$ and $\tau$ such that
    $\Gamma \vdash M; N : \tau$ and for every $e \in \sem{\Gamma}$,
    $\sem{M}(e)$ is not $\bot$-less
  \end{itemize}
\end{definition}

Adding the $\to_;$ reduction relation into the reduction relation $\to$ of
$\banana{\lambda}$ preserves subject reduction
(Property~\ref{prop:subject-reduction}) since $M; N : \alpha$ always
reduces to either $M : \alpha$ or $N : \alpha$. It also preserves the
soundness of our denotational semantics
(Property~\ref{prop:denotation-soundness}) because soundness relies on two
properties: the compositionality of the denotational semantics, which we
preserve, and the fact that the individual reduction rules preserve
denotations, which the $\to_;$ rule does by definition. The new
construction and its reduction rule also preserve confluence and
termination, as we will show below, and therefore they also preserve strong
normalization.

\begin{notation}
  The \demph{$\calc^;$ calculus} is the $\calc$ calculus with the $M; N$
  construction and its reduction rule, $\to_;$.
\end{notation}

\begin{lemma}\label{lem:semibanana-termination}
  \demph{Termination of $\calc^;$}

  The reduction relation $\to$ of $\calc^;$ is terminating.
\end{lemma}

\begin{proof}
  We consider $\calc$ with the $M; N$ construction and the following two
  reduction rules.

  \begin{align*}
    M; N &\to M \\
    M; N &\to N
  \end{align*}

  This calculus, which we will call $\calc^{;\to}$, is not confluent but,
  as we will show below, it is terminating. Since the reduction relation of
  $\calc^;$ is a subset of the reduction relation of $\calc^{;\to}$, then
  the reduction relation of $\calc^;$ will turn out to be terminating as
  well.

  For every type $\alpha$, we add a binary function symbol $(;_\alpha)$ of
  type $\alpha \To \alpha \To \alpha$ and typed versions of the two
  reduction rules above to the IDTS $\labidts$ from~\ref{sec:termination},
  forming a new IDTS $\overline{\calc^{;\to}_\tau}$. Since we have added no
  constructor symbols and the right-hand sides of the new reduction rules
  use no function symbols (and therefore are not recursive), we still
  validate the General Schema and Theorem~\ref{thm:labidts-termination}
  holds for $\overline{\calc^{;\to}_\tau}$. Following the proof of
  Corollary~\ref{cor:intcalc-termination}, we know that $\calc^{;\to}$
  without $\eta$-reduction, $\calc^{;\to}_{-\eta}$, terminates.

  We now need to show that adding $\eta$-reduction still preserves
  termination. The original proof stood on Lemma~\ref{lem:eta-exchange},
  which states that we can delay $\eta$-reduction until the very end of
  evaluation and which relies on the idea that $\eta$-reduction never opens
  up a new redex which would neccessitate the use of another rule. This is
  still the case since $\eta$-reduction cannot make a new $;$-redex appear
  without actually inserting a new semicolon and because the two reduction
  rules for $M; N$ given above are not sensitive to the structure of $M$
  and $N$.
\end{proof}

To prove that $\calc^;$ is confluent, we prove that $\to_;$ is confluent
and that $\to_;$ and the reduction relation of $\calc$ commute. We prove
the latter using Lemma~\ref{lem:commutativity}, as we did for $\to_\eta$
and $\intcalc$ in Lemma~\ref{lem:eta-commutes}, and for the former we use
the following lemma, which is a special case of Proposition~1.0.2
in~\cite{klop1992term}.

\begin{lemma}\label{lem:subcommutativity}
  A relation $\to$ is confluent iff its reflexive-transitive $\tto$ is
  subcommutative, i.e.\ if for all $a, b, c$ such that $a \to b$ and
  $a \to c$, there exists a $d$ such that $b \to^= d$ and $c \to^= d$.
\end{lemma}

\begin{proof}
  Follows from Proposition~1.0.2 in~\cite{klop1992term}.
\end{proof}

\begin{lemma}\label{lem:semicolon-confluent}
  The $\to_;$ reduction relation is confluent.
\end{lemma}

\begin{proof}
  We will proceed by proving that $\to_;$ is subcommutative (i.e.\ that
  $\forall a, b, c.\ (a \to_; b \land a \to_; c) \To \exists d.\ (b \to_;^=
  d \land c \to_;^= d)$) using structural induction on the term $a$, as
  in~\ref{lem:eta-commutes}. We will consider the relative positions of the
  redex in the reductions $a \to_; b$ and $a \to_; c$.

  \begin{enumerate}
  \item If both reductions occurred within a proper subterm of $a$, then we
    use the induction hypothesis and the context closure of $\to_;$ (see
    the analogous proof of~\ref{lem:eta-commutes} for technical details).

  \item If the reductions occurred in non-overlapping subterms, then we can
    take the common reduct $d$ as the term in which both subterms have been
    reduced.

  \item If the redex in $a \to_; b$ is the entire term $a$ and the redex in
    $a \to_; c$ is a proper subterm of $a$:

    Then $a = M; N$ for some $M$ and $N$. We split the proof based on
    whether the redex $R$ of $a \to_; c$ is a subterm of $M$ or $N$ and
    whether $b$ is equal to $M$ or $N$.
    \begin{itemize}
    \item $b = M$ and $M = C[R]$ with $R \to_; R'$ ($c = C[R']; N$)

      We will choose $d = C[R']$. Since $R \to_; R'$ and $\to_;$ is closed
      on contexts, we have that $b = M = C[R] \to_; C[R'] = d$. Since
      $\to_;$ preserves denotations, then $\sem{R} = \sem{R'}$ and by
      compositionality of denotations,
      $\sem{M} = \sem{C[R]} = \sem{C[R']}$. Because of $M; N \to_; M$, we
      know that for every $e$, $\sem{M}(e)$ is $\bot$-less and therefore so
      is $\sem{C[R']}(e)$. Since $\sem{C[R']}(e)$ is $\bot$-less for all
      $e$, $c = C[R']; N \to_; C[R'] = d$.

    \item $b = N$ and $M = C[R]$ with $R \to_; R'$ ($c = C[R']; N$)

      We will choose $d = N$. We immediately have $b = N \to_;^= N = d$. By
      the same argument is in the previous case, we have that
      $\sem{C[R]} = \sem{C[R']}$. For $M; N$ to have reduced to $N$,
      $\sem{M}(e)$ must have \emph{not} been $\bot$-less for any $e$, the
      same being the case for $\sem{C[R']}(e)$. Because $\sem{C[R'](e)}$ is
      not $\bot$-less for any $e$, we have $c = C[R']; N \to_; N = d$.

    \item $b = M$ and $N = C[R]$ with $R \to_; R'$ ($c = M; C[R']$)

      We will choose $d = M$. This case is symmetric to the previous one
      where we have $M; N$ reducing to one branch and the inner reduction
      happening in the abandoned branch.

    \item $b = N$ and $N = C[R]$ with $R \to_; R'$ ($c = M; C[R']$)

      We will choose $d = C[R']$. This case is symmetric to the first one
      in which the inner reduction ($R \to_; R'$) happens in the chosen
      branch ($M$ in the first case, $N$ in this one).
    \end{itemize}

  \item If the redex in $a \to_; c$ is the entire term $a$ and the redex in
    $a \to_; b$ is a proper subterm of $a$:

    Symmetric to the previous case.

  \item If the redex in both $a \to_; b$ and $a \to_; c$ is the entire term
    $a$, then $b = c$ and their common reduct is $d = b = c$. If $b$ and
    $c$ were different, i.e. $M; N \to_; M$ and at the same time
    $M; N \to_; N$, then $\sem{M}(e)$ would have to be simultaneously both
    $\bot$-less and not $\bot$-less for every $e$, which is a
    contradiction.
  \end{enumerate}
\end{proof}

\begin{lemma}\label{lem:semicolon-commutes}
  The reduction relation $\to_\calc$ of $\calc$ commutes with $\to_;$.
\end{lemma}

\begin{proof}
  As in the proof of Lemma~\ref{lem:eta-commutes}, we will make us of
  Hindley's Lemma~\ref{lem:commutativity}. We will be proving that for
  every $\calc^;$ terms $a,b,c$ such that $a \to_\calc b$ and $a \to_; c$,
  there exists a $d$ such that $b \tto_; d$ and $c \to_\calc^= d$. The
  proof will be analogous to the one of Lemma~\ref{lem:eta-commutes},
  proceeding by induction on the structure of $a$ and considering the
  relative positions of the redexes in the reductions $a \to_\calc b$ and
  $a \to_; c$.

  \begin{itemize}
  \item If both reductions occur in a proper subterm of $a$, then we use
    the induction hypothesis and the context closure of the two relations.

  \item If the reductions occur in non-overlapping subterms of $a$, then
    the common reduct $d$ is a term in which both subterms have been
    reduced.

  \item If the redex in $a \to_\calc b$ is the entire term $a$ and the
    redex in $a \to_; c$ is some proper subterm of $a$:

    Let $l \to r$ be the $\calc$ rule used in $a \to_\calc b$. None of the
    left-hand sides of the reduction rules in $\calc$ contain the semicolon
    operator and so the $;$-redex in $a$ must be matched by some
    metavariable in $l$. Let $M$ be that metavariable. We decompose the
    left-hand side $l$ into $L(M)$ and the right-hand side $r$ into
    $R(M)$. We have $a = L(a')$, $b = R(a')$ and $a' \to_; a''$ with
    $c = L(a'')$ for some $a'$ and $a''$. Our common reduct $d$ will be
    $R(a'')$. For $b$, we have $b = R(a') \tto_; R(a'') = d$ by
    $a \to_; a'$ and the context closure of $\to_;$. Note that $R(a')$
    might contain multiple copies of $a'$ or maybe even no copies of $a'$
    (as is the case when rules copy or delete terms). No matter the number
    of copies, we always have $R(a') \tto_; R(a'')$, because $\tto_;$ is
    reflexive and transitive. For $c$, we have
    $c = L(a'') \to_\calc R(a'') = d$ because $L(a'') \to R(a'')$ is an
    instance of the $\calc$ rule $l \to r$.

  \item If the redex in $a \to_; c$ is the entire term $a$ and the redex in
    $a \to_\calc b$ is some proper subterm of $a$:

    Let $a = M; N$. We proceed the same way as in case 3 in the proof of
    Lemma~\ref{lem:semicolon-confluent}. We have an outer $;$-reduction and
    an inner denotation-preserving reduction. Performing the inner
    reduction $a \to_\calc b$ first does not change the denotation and so
    we can still apply the $;$-reduction $b \to_; d$. Performing the outer
    reduction $a \to_; c$ first either throws away the redex for the
    $\calc$ reduction and so we have $c = d$, or it preserves it whole and
    then we can still perform the reduction $c \to_\calc d$.

  \item $a$ is at the same time a $\calc$-redex and a $;$-redex:

    This is impossible because there is no rule in $\calc$ whose left-hand
    side is headed by the $M; N$ construction, which is on the other hand
    the case in every $;$-redex.
  \end{itemize}
\end{proof}

\begin{corollary}\label{cor:semibanana-confluence}
  \demph{Confluence of $\calc^;$}
  
  The reduction relation of $\calc^;$ is confluent.
\end{corollary}

\begin{proof}
  Corollary of Lemma~\ref{lem:semicolon-confluent},
  Lemma~\ref{lem:semicolon-commutes} and the Lemma of Hindley-Rosen
  (Lemma~\ref{lem:hindley-rosen}).
\end{proof}

\begin{theorem}
  \demph{Strong normalization of $\calc^;$}

  $\calc^;$ is strongly normalizing, i.e.\ there are no infinite reduction
  chains in $\calc^;$ and all maximal reduction chains originating in a
  $\calc^;$ term $M$ terminate in the same term, the normal form of $M$.
\end{theorem}

\begin{proof}
  Corollary of Lemma~\ref{lem:semibanana-termination} and
  Corollary~\ref{cor:semibanana-confluence}.
\end{proof}


\subsection{Comparison with TTDL}
\label{ssec:comparison-ttdl}

The $\CC$ construction introduced partiality to $\calc$. With the $M; N$
construction in our calculus, we now have a way to react to partiality, to
avoid stuck terms. We have seen how to use that feature together with
effects and handlers to implement McCarthy's ambiguous operator $amb$ and
then use that to implement the presupposition accommodation strategy used
in Lebedeva's extension of TTDL~\cite{lebedeva2012expression}, which
projects presupposition as widely as possible without breaking variable
binding. Our solution improves in some aspects on Lebedeva's work:

\begin{itemize}
\item The underlying calculus is strongly normalizing.

  Lebedeva extends the simply-typed lambda-calculus with (unrestricted)
  exceptions and the resulting calculus is non-terminating, as shown by
  Lillibridge's encoding of recursive
  types~\cite{lillibridge1995exceptions}. Our first attempt at formalizing
  $\calc$ actually had the same deficiency and we were able to encode
  recursive types using Lillibridge's method.\footnote{The non-terminating
    $\calc$ assumed a global effect signature $E$ and used computation
    types $\FF(\alpha)$ which all shared the effect signature $E$ (i.e.\
    every $\FF(\alpha)$ was implicitly $\FF_E(\alpha)$). This was
    problematic because one could use the type $\FF(\alpha)$ somewhere in
    the type of one of the operations in $E$. This created a loop where $E$
    explicitly referenced $\FF(\alpha)$ which implicitly referenced $E$ and
    it is this loop which is exploited by Lillibridge's encoding of
    recursive types. This no longer works in the version of $\calc$
    presented in this manuscript since the type $\FF_E(\alpha)$ now has to
    explicitly mention $E$ and if $E$ contains $\FF_E(\alpha)$, then it
    leads to an infinite type. This was sufficient to make Lillibridge's
    encoding impossible since we have proven $\calc$ terminating
    in~\ref{sec:termination}.} Furthermore, when Lebedeva sketched out a
  possible solution to the binding problem, she defined a recursive
  function which was then part of the lexical semantic
  entries.\footnote{The function in question is the $\textsf{iacc}$ handler
    for intermediate accommodation from Definition~6.29. This handler is
    part of the definition of the dynamic existential quantifier, which is
    the only operator using which new variables are introduced.} This is
  also problematic since general recursion precludes termination. Our
  calculus gets around this by relying on inductive types to provide a
  limited form of recursion which can be proven terminating.

  The $\calc$ calculus, as it is presented in this manuscript, is
  terminating and strongly normalizing, while still allowing us to
  implement the accommodation strategy used by van der
  Sandt~\cite{van1992presupposition} and
  Lebedeva~\cite{lebedeva2012expression}.
  
\item Our analysis fixes a bug which allowed presupposition triggers to
  bind pronouns preceding them.

  The exceptions used in Lebedeva's extension of the simply-typed lambda
  calculus are not resumable. If a referential noun phrase triggers a
  presupposition about the existence of its referent, the evaluation of the
  sentence is restarted with the presupposed referent now in the
  context. However, this overgenerates by allowing any anaphoric
  expressions in the same sentence to bind to that referent, even those
  expressions which precede the presupposition trigger.

  \begin{exe}
    \ex[*]{He$_1$ loves John's$_1$ car. \label{ex:cataphora}}
  \end{exe}

  The operations in $\calc$ are resumable exceptions. Since we can resume
  the interpretation of a sentence after accommodating the presupposition,
  we do not have to restart the evaluation of the sentence and therefore we
  avoid the above situation.

\item We treat presuppositions using the same formal apparatus as dynamics
  and anaphora.

  Lebedeva uses terms to encode dynamic propositions, following de Groote's
  schema~\cite{de2006towards}. The terms and their types correspond to a
  monad of state and continuations. When this theory is then extended to
  cover presuppositions, instead of augmenting the monad to include another
  effect, the underlying lambda calculus is replaced by an impure calculus
  with order of evaluation, exceptions and handlers.

  Our approach is based on and heavily inspired by Lebedeva's use of
  exception mechanisms to treat presupposition but instead of using a term
  encoding for dynamicity and side effects, such as exceptions, for
  presupposition, we use a free monad for everything.\footnote{Not only for
    dynamicity and presuppositions, but also for quantification,
    conventional implicature and deixis.} Our free monad is a term encoding
  of a computation, much like de Groote's original approach was a term
  encoding of a dynamic proposition, which means that our calculus has no
  fixed order of evaluation (i.e.\ is pure). The free monad lets us combine
  both the dynamic effects of manipulating a state and a continuation
  together with the effect of throwing exceptions for presuppositions in a
  single encoding with relative ease.
\end{itemize}


\section{Double Negation}
\label{sec:double-negation}

We now turn our attention to another extension of TTDL.\@ In his
thesis~\cite{qian2014accessibility}, Sai Qian considers examples such as
the following one from Barbara Partee~\cite{roberts1989modal}:

\begin{exe}
  \ex \label{ex:bathroom} Either there's no bathroom$_1$ in the house, or
  it's$_1$ in a funny place.
\end{exe}

The bathroom mentioned in the first clause is embedded under a negation but
nevertheless, we can still access it in the second clause. If we look at
the disjunction $A \dor B$ in DRT and TTDL, it has the same truth
conditions and accessibility characteristics as
$\dnot (\dnot A \dand \dnot B)$. This is how TTDL defines dynamic
disjunction. If we take the meaning of \emph{there's no bathroom} to be
$\dnot A'$ where $A'$ is the meaning of \emph{there is a bathroom}, then
the meaning of Example~\ref{ex:bathroom} comes out as:

$$
\dnot A' \dor B = \dnot (\dnot (\dnot A') \dand \dnot B)
$$

In classical logic, we may use the law of double negation to go from
$\dnot (\dnot A')$ to $A'$.

$$
\dnot (\dnot (\dnot A') \dand \dnot B) = \dnot (A' \dand \dnot B) = A' \dimp B
$$

If we do so, the dynamic contributions of $A'$ will no longer be blocked by
a negation and will become accessible to any anaphoric pronouns in $B$. As
we see above, the sentence ends up being paraphrased as ``\emph{if there's
  a bathroom, then it's in a funny place}''.

In order for this line of reasoning to hold within the framework, we would
need the law of double negation to hold. However, that is not the case in
neither DRT nor TTDL.\@ For DRT, this problem is addressed by Krahmer and
Muskens in Double Negation DRT (DN-DRT)~\cite{krahmer1995negation} and for
TTDL with a very similar strategy by Qian in Double Negation TTDL
(DN-TTDL)~\cite{qian2014accessibility}.

The DN-TTDL approach is an instance of the following general strategy. Let
us imagine we have some set $A$ (e.g.\ the set of DRSs or TTDL dynamic
propositions) and a function $f : A \to A$ (e.g.\ negation) that we would
like to adapt into some involution $g$.\footnote{An \emph{involution} is a
  function which is its own inverse, i.e.\ $g(g(x)) = x$.} Applying $g$ to
a value once should have the same (or somehow similar) effect as applying
$f$ once (i.e.\ $g$ should simulate/extend $f$). Furthermore, applying $g$
twice must act as the identity function. We can consider an extended domain
$A \times A$ and for each value $x \in A$ pairs $i(x)$ of the form
$\left<x, f(x)\right>$. The swapping operation
$\lambda \left<a, b\right>.\ \left<b, a\right>$ is then just the function
$g$ we were looking for. We have the following:

\begin{align*}
\pi_1(i(x)) &= x \\
\pi_1(g(i(x))) &= f(x) \\
\pi_1(g(g(i(x)))) &= \pi_1(i(x)) = x
\end{align*}

The first equation shows us that the $i$ injection is a right inverse to
the $\pi_1$ projection. The second equation shows us that using $g$ in the
extended domain $A \times A$ is exactly like using $f$ in the original
domain $A$. Finally, the third equation shows us that $g$ is an involution.

This is exactly the approach adopted by Qian
in~\cite{qian2014accessibility}. The original domain is the type of dynamic
propositions $\Omega = \gamma \to (\gamma \to o) \to o$ and the function
$f$ is TTDL's dynamic negation. The domain of DN-TTDL is defined as the
type $\Omega \times \Omega$, propositions are injected from TTDL to DN-TTDL
using $i(x) = \left<x, f(x)\right>$ and DN-TTDL dynamic negation works by
swapping the two elements of the pair. We can conceive of this pair as the
positive and negative representation of a proposition, the second item of
the pair always being a negated form of the first one.

DN-DRT~\cite{krahmer1995negation} adopts a similar strategy. Two
interpretation functions are given: one for positive readings and another
for negative readings. Negation becomes a new constructor for DRSs, its
positive interpretation being the negative interpretation of its argument
and its negative interpretation being the positive interpretation of its
argument. Therefore, every DRS has two interpretations and negation is
implemented as exchanging these two interpretations.


\subsection{Double Negation as an Effect}

Our methodology is built on the assumption that the phenomena that we treat
using effects have a projective nature. If a certain construction does not
play a role in the phenomenon, it should transfer any operations related to
this phenomenon from its arguments up to its context. For example:

\begin{itemize}
\item An indefinite noun phrase like \emph{a man} introduces a new
  discourse referent $x$ along with the condition $\ap{\obj{man}}{x}$. If this
  NP becomes an argument of a verb, then the verb applies itself to the
  NP's referent and transfers these dynamic effects up to the nearest
  enclosing box. The meaning of \emph{a man sleeps} still introduces a new
  discourse referent $x$ along with the condition $\ap{\obj{man}}{x}$ while also
  introducing the condition $\ap{\obj{sleep}}{x}$. Since the verb had no
  interaction with dynamicity, all of the NP's effects were preserved.
\item An anaphoric pronoun such as \emph{he} accesses the context to find
  its antecedent $x$. Applying the predicate \emph{sleeps} preserves this
  context dependence and yields a computation that also starts by accessing
  the context to find an antecedent $x$ and then producing the proposition
  $\ap{\obj{sleep}}{x}$. Deictic and intensional meanings access some external
  information to find their referents as well and they behave the same in
  these scenarios.
\item A definite description such as \emph{the king of France} presupposes
  the existence of a king of France $x$ and again, we can compute the
  meaning of \emph{the king of France is bald} by applying the predicate
  $\obj{bald}$ to the referent $x$ while still presupposing the existence
  of the king of France $x$.
\end{itemize}

Lexical items that want to interact with a certain phenomenon, a certain
level of meaning, do so by either signalling an operation or handling
one. The entries of all the other lexical items which are not involved in
this phenomenon do not have to be modified in any way and they project
these requests automatically. As we have seen in the last two chapters, for
many phenomena this is the case. This way, semantics of deictic NPs are not
affected by the existence of anaphoric NPs or presuppositional NPs, and
neither of these affect the semantics of simple predicates (e.g.\
extensional transitive verbs denoting relations on individuals such as
\emph{loves}).

Now when we look at the treatment of double negation as an effect, it does
not follow the same pattern. The change in types in TTDL is from $\Omega$
to $\Omega \times \Omega$. If we want to treat this as an effect, we can
look at monads which employ similar types. Two come to mind: the writer
monad that maps the type $\alpha$ to $\alpha \times \Omega$ and the reader
monad that maps the type $\alpha$ to $2 \to \alpha$.


\subsubsection{Polarity Sensitivity --- Reader Monad}

In the reader monad approach, we look at the type $\Omega \times \Omega$ as
a family of dynamic propositions of type $\Omega$ indexed by the type $2$
(i.e.\ $\Omega \times \Omega \simeq 2 \to \Omega$). These computations live
in some context in which they have access to a polarity of type $2$ and
based on that polarity, they should either return a positive version of
themselves or a negative one. The corresponding operation would be
something like $\typedop{get\_polarity}{1}{2}$. We will see that such an
approach is problematic.

Let us look at the VP ``\emph{trusts nobody}'' whose meaning is a function
from individuals to polarity-sensitive propositions, that when given an
individual $x$ will ask for the polarity and if it is positive, return
``\emph{$x$ trusts nobody}'', and if it is negative, return ``\emph{$x$
  trusts somebody}''. If we then embed this VP inside the sentence
``\emph{I met a man who trusts nobody}'', the resulting meaning would ask
for the polarity and if it is positive, then return the meaning of
``\emph{I met a man who trusts nobody}'', and if it is negative, then
return ``\emph{I met a man who trusts somebody}'', which is not the desired
negation of the sentence. We do not get the correct meaning by ignoring the
$\op{get\_polarity}$ operation and applying the meaning of the context
``\emph{I met a man who $[]$}'' to (either of) the results.

If a proposition occurs in some context which is not a negation, then it
appears with positive polarity and we should apply a handler which signals
that. However, we would have to include this handler in \emph{all} lexical
entries that embed other propositions as arguments, which would defeat the
point of our method. Futhermore, if we would end up implementing negation
as a handler that switches polarity, then we would be obliged to also
change \emph{all} lexical entries that produce propositions so that they do
not forget to ask for polarity. The $\eta$ injection of the reader monad
maps a dynamic proposition $A$ to a function $\lam{p}{A}$, which ignores
the polarity $p$ and assigns the dynamic proposition $A$ to both. This is
clearly not what we want as it ends up making every dynamic proposition
equal to its negation.


\subsubsection{Providing Negations --- Writer Monad}

The writer monad is about computations outputting something: in our case
they would be outputting their suggested negations, as in the technique for
building up involutions using pairs shown above. This would correspond to
some operation $\typedop{negative}{\Omega}{1}$ with which a proposition
would suggest to its context a preferred negation that ought to be used if
someone would try to negate it.

In this case, the VP ``\emph{trusts nobody}'' would be a function from
individuals $x$ to dynamic propositions ``\emph{$x$ trusts nobody}'' that
would suggest ``\emph{$x$ trusts somebody}'' as their negation. If we then
look at the complex sentence ``\emph{I met a man who trusts nobody}'', its
meaning would be a computation that produces the meaning of ``\emph{I met a
  man $x$ who trusts nobody}'' but also suggests that ``\emph{$x$ trusts
  somebody}'' is its negation. Again, it becomes incorrect to ignore the
$\op{negative}$ effect in constructions that embed
propositions. Furthermore, what would be the semantics if a proposition
used the $\op{negative}$ effect multiple times? The writer monad expects
the type of the material being to form a monoid, which would be difficult
to arrange in our case.


\subsection{DN-TTDL is Not Monadic}

So far, we have tried taking existing monads which superficially look like
DN-TTDL (i.e.\ they use the same types) and we have seen that neither
models the semantics of DN-TTDL faithfully, forcing us to explicitly
introduce handlers in all lexical entries that work with propositions,
forfeiting the benefit of using $\banana{\lambda}$ computations in the
first place. In this and the next subsection, we will try to find out why
monads and effects are not a good fit for DN-TTDL.

We will start by showing that the constructions in DN-TTDL are not
monadic. We have seen the definition of a monad in~\ref{ssec:monad}: we
need to provide a functor $F$ and the combinators $\eta$ and $\hsbind$
which satisfy the monad laws.

\begin{align*}
  F(\Omega) &= \Omega \times \Omega \\
  \etaE{A} &= \left< A, \dnot A \right> \\
  A \hsbind f &= \ap{f}{(\ap{\pi_1}{A})}
\end{align*}

This captures the idea behind the DN-TTDL approach:

\begin{itemize}
\item the type of propositions is generalized to become the type of pairs
  of positive and negative propositions,
\item older values (simple dynamic propositions) are lifted by creating
  pairs in which the second item corresponds to the dynamic negation of the
  original value
\item if we want to apply a function $f$ on some DN-TTDL proposition, we
  extract its positive variant and use that as the argument of $f$
\end{itemize}

We can check that our translation is faithful by trying to use the two
combinators above to automatically raise operators such as dynamic
conjunction into the new double-negation theory. We can reuse the general
monadic lifting functions from~\ref{sec:lifting-semantics}.

\begin{align*}
  \liftl_{\alpha \limp \beta \limp \gamma} &: (\sem{\alpha} \to \sem{\beta} \to \sem{\gamma}) \to (F(\sem{\alpha}) \to F(\sem{\beta}) \to F(\sem{\gamma})) \\
  \ap{\liftl_{\alpha \limp \beta \limp \gamma}}{f}
     &= \lam{X Y}{X \hsbind (\lam{x}{Y \hsbind (\lam{y}{\etaE{(\app{f}{x}{y})}})})} \\
     &= \lam{X Y}{\left< \app{f}{(\ap{\pi_1}{X})}{(\ap{\pi_1}{Y})}, \dnot (\app{f}{(\ap{\pi_1}{X})}{(\ap{\pi_1}{Y})}) \right>} \\
  \ap{\liftl_{S \limp S \limp S}}{(\dand)}
     &= \lam{X Y}{\left< (\ap{\pi_1}{X}) \dand (\ap{\pi_1}{Y}), \dnot ((\ap{\pi_1}{X}) \dand (\ap{\pi_1}{Y})) \right>}
\end{align*}

By applying $\liftl_{S \limp S \limp S}$ to dynamic conjunction, we arrive
at the extended definition of conjunction used by Qian
in~\cite{qian2014accessibility}. Thus we manage to derive from the general
monadic lifting function and the two lines that define $\eta$ and $\hsbind$
for this monad the same operator that Qian introduced in his thesis. This
seems to suggest that this translation is indeed a faithful one.

However, there are two problems with the ``monad'' we just
introduced. First of all, $\eta$ is not general and is only applicable to
values of type $\Omega$ (dynamic propositions). It begs the question what
would be the interpretation of types such as $F(\iota)$, i.e.\ what is the
negation of an individual. Secondly, even if we ignore this and just stay
in the domain of dynamic propositions, permitting only types $F(\Omega)$,
we run into a more severe problem. The ``monad'' that we proposed does not
actually satisfy the right identity law (Law~\eqref{law:monad-right-id}).

$$
X \hsbind \eta = X
$$
 
The reason is simple. The $\hsbind$ operator forgets about the negative
form of $X$ and then $\eta$ replaces that negative form with the default
one produced by dynamic negation. The two terms are thus not equal, since
the one on the left replaces the proposed negative form $X$ with the
default dynamic negation.

In our method, we model denotations as $\banana{\lambda}$ computations and
$\banana{\lambda}$ computations form a monad, i.e.\ for any effect
signature $E$, $\left<\FF_E, \eta, \hsbind\right>$ is a monad. Likewise,
all of the phenomena we treat have a monadic structure as well: Barker's
continuization uses the continuation monad~\cite{barker2002continuations},
de Groote and Lebedeva's TTDL uses a combination of the state monad and the
continuation monad~\cite{de2006towards,lebedeva2012expression}
(see~\ref{ssec:truth-conditions-side-effects}), de Groote and Kanazawa's
intensionalization uses the reader monad~\cite{de2013note}, Giorgolo and
Asudeh's implementation of Potts' conventional implicature analysis uses
the writer monad~\cite{giorgolo2011multidimensional}. The fact that the
structure used by Qian~\cite{qian2014accessibility} is not a monad could be
a reason why its implementation using $\banana{\lambda}$ effects is
difficult.

We have shown that DN-TTDL is not monadic, but there are also other
abstractions which have weaker laws than monads and which are still
useful. The applicative functors (see~\ref{ssec:applicative-functor}) that
are used in Oleg Kiselyov's Applicative Abstract Categorial
Grammars~\cite{kiselyov2015applicative,kiselyov2015swing} are one such
example. However, as we will show next, DN-TTDL also violates the laws of
functors, which are even weaker than those of applicative functors.


\subsection{DN-TTDL is Not Functorial}

A functor $F$ maps types $\alpha$ to types $F(\alpha)$ and functions
$f : \alpha \to \beta$ to functions $F(f) : F(\alpha) \to F(\beta)$. The
functor underlying the almost-monad from the previous subsection is the
following:

\begin{align*}
  F(\Omega) &= \Omega \times \Omega \\
  F(f) &= \lam{X}{\left< \ap{f}{(\ap{\pi_1}{X})}, \dnot(\ap{f}{(\ap{\pi_1}{X})}) \right>}
\end{align*}

Same as for the monad, this is still applicable only to functions whose
return type is $\Omega$. However, even if we ignore this, we find out that
this structure does not satisfy the laws of a functor. Functors have to
adhere to two laws: homomorphism w.r.t.\ to function composition and
homomorphism w.r.t.\ to identities. It is the latter which this structure
fails. Consider the identity law of functors
(Law~\eqref{law:functor-identity}):

\begin{align*}
  F(\id_A) &= \id_{F(A)}
\end{align*}

If we try to elaborate $F(\id_\Omega)$ with this structure, we find that it
does not correspond to an identity:

\begin{align*}
  F(\id_\Omega) &= \lam{X}{\left< \ap{\pi_1}{X}, \dnot(\ap{\pi_1}{X}) \right>} \\
  \id_{F(\Omega)} &= \lam{X}{\left< \ap{\pi_1}{X}, \ap{\pi_2}{X} \right>} \\
  F(\id_\Omega) &\neq \id_{F(\Omega)}
\end{align*}

Therefore, the structure in DN-TTDL is not a functor and by extension
neither an applicative functor.

The failure in the functor identity law highlights why this kind of
strategy is incompatible with our approach. It is exactly because of the
fact that the negative variants of propositions are not things that project
--- if $A_\petitn$ is the negative variant of $A$, that does not mean that
$A_\petitn$ is the negative variant of $A \land B$ --- that this structure
breaks the functor laws. In order to stop the projection of the proposed
negative variant out of a context, the functor forgets the old negative
variant and replaces it with a new one. However, this kind of behavior that
suppresses this extra information is non-functorial, since if we apply the
functor to the identity function, we get a function that forgets the extra
annotation (the negative variant) and therefore we do not have an identity
function.

When we say that this solution to the double negation problem is
incompatible with our approach, we mean that we cannot find effects that
implement this kind of functionality. However, this does not mean that we
cannot combine our technique of using $\banana{\lambda}$ computations with
the technique proposed by Qian~\cite{qian2014accessibility}. We have seen
how to implement TTDL in $\banana{\lambda}$, on which DN-TTDL is built. We
can therefore use the DN-TTDL schema by replacing the TTDL implementation
using our $\banana{\lambda}$ implementation. The downside is that we have
to then always work with pairs of computations of propositions everywhere,
which is a heavy price to pay for the offered empirical coverage increase.


\section{Summary}
\label{sec:summary-dynamic-semantics}

In this chapter, we have seen how to implement dynamic semantics in the
$\banana{\lambda}$ framework. Our goal was to motivate a core set of
operations which characterize dynamic meanings. In order to do that, we
have taken DRT, a well-established theory of dynamic semantics, and shown
how its canonical formulation in Kamp and Reyle's
textbook~\cite{kamp1993discourse} can be seen as a collection of effectful
programs~(\ref{sec:drt-as-pl}). This validated our intuition that dynamic
semantics can be suitably modelled as effectful computation and also shown
us what effect signature to choose and how to use those effects to give
denotations to lexical items in our grammar~(\ref{sec:banana-drt}). In
translating the DRT fragment into an ACG+$\calc$ fragment, we have made it
compositional by showing that what DRT actually composes are instructions
on how to build DRSs. We have then connected our analysis to de Groote's
Type-Theoretic Dynamic Logic~\cite{de2006towards,lebedeva2012expression},
another compositional theory of dynamic semantics using ACGs and
continuations, by interpreting the computations as dynamic
propositions. Finally, inspired by the algebraic effects
literature\cite{hyland2006combining,plotkin2009handlers,pretnar2010logic,plotkin2013handling},
we have given a system of equations which derives DRSs as the canonical
forms of dynamic computations (a collection variables accessible to
subsequent formulas coupled with a collection of simple propositions about
those variables)~(\ref{ssec:algebraic-drt}).

After having introduced anaphora, we moved onto another effect that is
closely related: presuppositions~(\ref{sec:presuppositions}). Our
treatment of presuppositions, which was in the style of
Lebedeva~\cite{lebedeva2012expression} and van der
Sandt~\cite{van1992presupposition}, was built on top of our dynamic
semantics and was the first time we got to see how to combine side
effects from different phenomena. We first started with changing the
dynamic effects handler from a closed handler into an open
handler~(\ref{ssec:revising-dynamic-handler}). While this involved some
complicated $\lambda$ terms, this is a price we will have to pay only
once. Now that we have an open handler for dynamics, we can combine dynamics
with other effects with much less effort. Then we took the following steps
to integrate presuppositions into our dynamic semantics:

\begin{enumerate}
\item \label{item:fixbug} We have fixed a bug in the dynamics handler
  ($\BOX$) which relied on the assumption that the contents of DRSs higher
  up on the projection line than the closest immediate DRS will not change;
  an assumption that would be invalidated by the introduction of
  presuppositions~(\ref{ssec:revising-dynamic-handler}). While without
  fixing this, our analysis was undergenerating, Lebedeva's
  analysis~\cite{lebedeva2012expression} suffers from a similar bug and is
  overgenerating (licensing the reading ``He$_1$ loves John's$_1$ car'').
  
\item \label{item:presuppose-op} We introduced a new operation
  $\typedop{presuppose}{(\iota \to o)}{\iota}$ and used it in lexical
  entries such as $\abs{proper}$ for proper names and $\abs{poss}$ for
  possessive constructions.

\item \label{item:accommodate-handler} We introduced a handler for
  $\op{presuppose}$ called $\accommodate$ and we added it to a handler
  representing the top-level DRS.\@ At this point, we could analyze
  discourses such as Example~\ref{ex:jones-mercedes}, repeated below, which
  were not covered by the original TTDL~\cite{de2006towards} and which
  motivated the use of exceptions in Lebedeva's
  extension~\cite{lebedeva2012expression}.

  \begin{exe}
    \exr{ex:jones-mercedes} It is not the case that Jones$_1$ owns a
    Porsche. He$_1$ owns a Mercedes.
  \end{exe}

\item \label{item:maybe-accommodate} We introduced a new handler,
  $\useFind$, that tried resolving presuppositions by looking up the
  referent in the context instead of always presupposing its existence, as
  in~\cite{lebedeva2012expression}. This let us analyze cases such as
  Example~\ref{ex:cancel} without projecting a presupposition.

  \begin{exe}
    \exr{ex:cancel} If John owns a car, then his car is cheap.
  \end{exe}

\item \label{item:nondet-accommodation} We enriched the $\BOX$ handler with
  a clause for nondeterministically accommodating presuppositions,
  $\maybeAccommodate$. This allowed us to account for the ambiguity
  inherent in the accommodation of presuppositions, such as in
  Example~\ref{ex:wilma}:

  \begin{exe}
    \exr{ex:wilma} ($c_0$) Maybe ($c_1$) Wilma thinks that ($c_2$) her husband is having an affair.
  \end{exe}

\item \label{item:pga-amb} We have encoded the Preference for Global
  Accommodation principle and its binding problem constraint by introducing
  an operator to $\banana{\lambda}$ for identifying stuck computations and
  by writing a handler for nondeterministic choice that gave it the
  semantics of McCarthy's $amb$ operator~\cite{mccarthy1961basis}. With
  this, we analyzed Example~\ref{ex:man-angry}:

  \begin{exe}
    \exr{ex:man-angry} ($c_0$) If ($c_1$) a man gets angry, ($c_2$) his
    children get frightened.
  \end{exe}
\end{enumerate}

Notably, we did not need to touch the dynamic denotations that we have
developed in~\ref{sec:banana-drt} in order to make them
presupposition-compatible. We only modified dynamic negation, $\dnot$, by
adding new clauses to the $\BOX$ handler to implement the interaction
between DRSs and presuppositions. Our objective was to have empirical
parity with Lebedeva's analysis~\cite{lebedeva2012expression} while using
the same mechanism to implement both dynamics and presuppositions ($\calc$
computations) and without having to use a calculus with a non-standard
evaluation order. In this, we have succeeded\footnote{We have not covered
  the interplay of quantification and dynamics, which TTDL studies as
  well. This will be the subject of Chapter~\ref{chap:composing-effects}.}
and we have also shown an example in which we can overcome an empirical
limitation of Lebedeva's approach.

Finally, we addressed another extension of TTDL, Qian's
DN-TTDL~\cite{qian2014accessibility}. We have analyzed his proposal and
shown that it is out of the scope of our approach as it involves a
non-functorial structure at its core. While we cannot translate Qian's
technique into effects and handlers, we can use his technique directly to
model propositions as pairs of computations. As this would be a heavy
change to our fragment, we avoid this technique in the rest of the
manuscript.
