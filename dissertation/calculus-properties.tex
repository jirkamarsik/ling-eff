\chapter{Properties}
\label{chap:properties}

We have given a formal definition of $\banana{\lambda}$ in
Chapter~\ref{chap:definitions} and then demonstrated it on examples in
Chapter~\ref{chap:examples}. We now turn back to a formal study of
$\banana{\lambda}$ and we derive some formal properties.

\minitoc

\section{Derived Rules}
\label{sec:derived-rules}

At the end of Chapter~\ref{chap:definitions},
in~\ref{sec:common-combinators}, we have introduced some new syntax for
$\banana{\lambda}$ terms and we have translated that syntax into terms of
the core $\banana{\lambda}$ calculus. However, in
Chapter~\ref{chap:examples}, we have then seen that expanding these
syntactic extensions during the reduction of a term is a tedious process
and we have introduced some shortcuts to allow us to proceed faster and at
a higher level of abstraction (e.g.\ the $\eta.\hsbind$ rule). In this
section, we will give typing rules and reduction rules to these new
constructions and prove their correctness.


\subsection{Function Composition ($\circ$)}
\label{ssec:function-composition}

The first piece of syntactic sugar we have introduced was an infix symbol
for function composition.

$$
f \circ g = \lam{x}{\ap{f}{(\ap{g}{x})}}
$$

In order to type terms containing this symbol, it will be useful to have a
typing rule.

\begin{proposition}
  The following typing rule is derivable in $\banana{\lambda}$:

  \begin{prooftree}
    \AxiomC{$\Gamma \vdash M : \beta \to \gamma$}
    \AxiomC{$\Gamma \vdash N : \alpha \to \beta$}
    \RightLabel{$[\circ]$}
    \BinaryInfC{$\Gamma \vdash M \circ N : \alpha \to \gamma$}
  \end{prooftree}
\end{proposition}

\begin{proof}
  Since $M \circ N = \lam{x}{\ap{M}{(\ap{N}{x})}}$, we can prove the
  validity of this rule with the typing rule below:
  
  \begin{prooftree}
    \AxiomC{$\Gamma, x : \alpha \vdash M : \beta \to \gamma$}
    \AxiomC{$\Gamma, x : \alpha \vdash N : \alpha \to \beta$}
    \AxiomC{$\Gamma, x : \alpha \vdash x : \alpha$}
    \RightLabel{[app]}
    \BinaryInfC{$\Gamma, x : \alpha \vdash \ap{N}{x} : \beta$}
    \RightLabel{[app]}
    \BinaryInfC{$\Gamma, x : \alpha \vdash \ap{M}{(\ap{N}{x})} : \gamma$}
    \RightLabel{[abs]}
    \UnaryInfC{$\Gamma \vdash \lam{x}{\ap{M}{(\ap{N}{x})}} : \alpha \to \gamma$}
  \end{prooftree}

  $x$ is presumed to be fresh for $M$ and $N$ and so we can equate
  $\Gamma, x : \alpha \vdash M : \beta \to \gamma$ with
  $\Gamma \vdash M : \beta \to \gamma$ and the same for $N$.
\end{proof}

The result of function composition is another function and functions can be
applied to arguments. The following reduction rule will this come in handy.

\begin{proposition}
  The following reduction is derivable in $\banana{\lambda}$:

  \vspace{2mm}
  \begin{tabular}{>{$}r<{$} >{$}c<{$} >{$}l<{$}}
    \ap{(M_1 \circ M_2)}{N} & \to_\circ & \ap{M_1}{(\ap{M_2}{N})} \\
  \end{tabular}
  \vspace{2mm}
\end{proposition}

\begin{proof}
  \begin{align*}
    \ap{(M_1 \circ M_2)}{N}
    &= \ap{(\lam{x}{\ap{M_1}{(\ap{M_2}{x})}})}{N} \\
    &\to_\beta \ap{M_1}{(\ap{M_2}{N})}
  \end{align*}
\end{proof}


\subsection{Monadic Bind ($\hsbind$)}
\label{ssec:bind}

As a reminder, we give the definition of $\hsbind$
from~\ref{ssec:composing-functions}.

\begin{align*}
  M \hsbind N &= \ap{N^*}{M} \\
              &= \ap{\banana{\onto{\eta}{N}}}{M}
\end{align*}

First, we will prove the correct typing for $\hsbind$.

\begin{proposition}
  The following typing rule is derivable in $\banana{\lambda}$:

  \begin{prooftree}
    \AxiomC{$\Gamma \vdash M : \FF_E(\alpha)$}
    \AxiomC{$\Gamma \vdash N : \alpha \to \FF_E(\beta)$}
    \RightLabel{$[\hsbind]$}
    \BinaryInfC{$\Gamma \vdash M \hsbind N : \FF_E(\beta)$}
  \end{prooftree}
\end{proposition}

\begin{proof}
  We note that $M \hsbind N = \ap{\banana{\onto{\eta}{N}}}{M}$ and
  construct the following typing derivation in $\banana{\lambda}$:
  
  \begin{prooftree}
    \AxiomC{$\Gamma \vdash N : \alpha \to \FF_E(\beta)$}
    \RightLabel{[$\banana{}$]}
    \UnaryInfC{$\Gamma \vdash \banana{\onto{\eta}{N}} : \FF_E(\alpha) \to \FF_E(\beta)$}
    \AxiomC{$\Gamma \vdash M : \FF_E(\alpha)$}
    \RightLabel{[app]}
    \BinaryInfC{$\Gamma \vdash \ap{\banana{\onto{\eta}{N}}}{M} : \FF_E(\beta)$}
  \end{prooftree}
\end{proof}

Next, we will prove the validity of two reduction rules for $\hsbind$.

\begin{proposition}
  The following reductions are derivable in $\banana{\lambda}$:

  \vspace{2mm}
  \begin{tabular}{>{$}r<{$} >{$}c<{$} >{$}l<{$}}
    \etaE{M} \hsbind N & \to_{\eta.\hsbind} & \ap{N}{M} \\
    \app{\op{op}}{M_{\mathrm{p}}}{(\lam{x}{M_{\mathrm{c}}})} \hsbind N & \to_{\op{op}.\hsbind} & \app{\op{op}}{M_{\mathrm{p}}}{(\lam{x}{M_{\mathrm{c}} \hsbind N})}
  \end{tabular}
  \vspace{2mm}
\end{proposition}

\begin{proof}
  \begin{align*}
    \etaE{M} \hsbind N
    &= \ap{\banana{\onto{\eta}{N}}}{(\etaE{M})} \\
    &\to_{\banana{\eta}} \ap{N}{M}
  \end{align*}
  \begin{align*}
    \app{\op{op}}{M_\petitp}{(\lam{x}{M_\petitc})} \hsbind N
    &= \ap{\banana{\onto{\eta}{N}}}{(\app{\op{op}}{M_\petitp}{(\lam{x}{M_\petitc})})} \\
    &\to_{\banana{\op{op}'}} \app{\op{op}}{M_\petitp}{(\lam{x}{\ap{\banana{\onto{\eta}{N}}}{M_\petitc}})} \\
    &= \app{\op{op}}{M_\petitp}{(\lam{x}{M_\petitc \hsbind N})}
  \end{align*}
\end{proof}


\subsection{Closed Handlers ($\bbanana{}$)}
\label{ssec:closed-handlers}

In~\ref{ssec:operations-and-handlers}, we have also a notation for closed
handlers. Even though we define closed handlers in terms of (open)
handlers, their typing and reduction rules are actually simpler, since they
do not have to go out of their way to support openness (i.e.\ passing
through uninterpreted operations).

$$
\ap{\cibbanana}{N} = \ap{\cherry}{(\ap{\banana{(\onto{\op{op}_i}{(\lam{x k}{\ap{\eta}{(\ap{\ap{M_i}{x}}{(\cherry \circ k)})}})})_{i \in I},\ \onto{\eta}{(\lam{x}{\etaE{(\ap{M_\eta}{x})}})}}}{N})}
$$

We will first go through the typing rule.

\begin{proposition}
  The following typing rule is derivable in $\banana{\lambda}$:

  \begin{prooftree}
  \AxiomC{$E = \{\typedopg{\op{op}_i}{\alpha_i}{\beta_i}\}_{i \in I}$}
  \def\extraVskip{0pt}
  \noLine
  \UnaryInfC{$[\Gamma \vdash M_i : \alpha_i \to (\beta_i \to \delta) \to \delta]_{i \in I}$}
  \noLine
  \UnaryInfC{$\Gamma \vdash M_\eta : \gamma \to \delta$}
  \noLine
  \UnaryInfC{$\Gamma \vdash N : \FF_E(\gamma)$}
  \def\extraVskip{2pt}
  \RightLabel{$[\bbanana{}]$}
  \UnaryInfC{$\Gamma \vdash \ap{\cibbanana}{N} : \delta$}
  \end{prooftree}
\end{proposition}

\begin{proof}
  We have
  $\ap{\cibbanana}{N} = \ap{\cherry}{(\ap{\banana{(\onto{\op{op}_i}{(\lam{x
            k}{\ap{\eta}{(\ap{\ap{M_i}{x}}{(\cherry \circ k)})}})})_{i \in
          I},\ \onto{\eta}{(\lam{x}{\etaE{(\ap{M_\eta}{x})}})}}}{N})}$ and
  we will proceed by building a typing derivation for this term.

  \begin{prooftree}
    \AxiomC{$E = \{\typedopg{\op{op}_i}{\alpha_i}{\beta_i}\}_{i \in I}$}
    \def\extraVskip{0pt}
    \noLine
    \UnaryInfC{$[\Gamma \vdash \lam{x k}{\ap{\eta}{(\ap{\ap{M_i}{x}}{(\cherry \circ k)})}} : \alpha_i \to (\beta_i \to
      \FF_\emptyset(\delta)) \to \FF_\emptyset(\delta)]_{i \in I}$}
    \noLine
    \UnaryInfC{$\Gamma \vdash \lam{x}{\etaE{(\ap{M_\eta}{x})}} : \gamma \to \FF_\emptyset(\delta)$}
    \noLine
    \UnaryInfC{$\Gamma \vdash N : \FF_E(\gamma)$}
    \def\extraVskip{2pt}
    \RightLabel{[$\banana{}$]}
    \UnaryInfC{$\Gamma \vdash \ap{\banana{(\onto{\op{op}_i}{(\lam{x k}{\ap{\eta}{(\ap{\ap{M_i}{x}}{(\cherry \circ k)})}})})_{i \in I},\ \onto{\eta}{(\lam{x}{\etaE{(\ap{M_\eta}{x})}})}}}{N} : \FF_\emptyset(\delta)$} 
    \RightLabel{[$\cherry$]}
    \UnaryInfC{$\Gamma \vdash \ap{\cherry}{(\ap{\banana{(\onto{\op{op}_i}{(\lam{x k}{\ap{\eta}{(\ap{\ap{M_i}{x}}{(\cherry \circ k)})}})})_{i \in I},\ \onto{\eta}{(\lam{x}{\etaE{(\ap{M_\eta}{x})}})}}}{N})} : \delta$} 
  \end{prooftree}

  We still need to prove both
  $\Gamma \vdash \lam{x k}{\ap{\eta}{(\ap{\ap{M_i}{x}}{(\cherry \circ
        k)})}} : \alpha_i \to (\beta_i \to \FF_\emptyset(\delta)) \to
  \FF_\emptyset(\delta)$ for every $i \in I$ and
  $\Gamma \vdash \lam{x}{\etaE{(\ap{M_\eta}{x})}} : \gamma \to
  \FF_\emptyset(\delta)$.

\begin{adjustwidth}[]{-1cm}{-1cm}
  \begin{prooftree}
    \AxiomC{$\Gamma \vdash M_i : \alpha_i \to (\beta_i \to \delta) \to \delta$}
    \AxiomC{$\Gamma, x : \alpha_i \vdash x : \alpha_i$}
    \RightLabel{[app]}
    \BinaryInfC{$\Gamma, x : \alpha_i \vdash \ap{M_i}{x} : (\beta_i \to \delta) \to \delta$}
    \AxiomC{$\Gamma \vdash \cherry : \FF_\emptyset(\delta) \to \delta$}
    \AxiomC{$\Gamma, k : \beta_i \to \FF_\emptyset(\delta) \vdash k : \beta_i \to \FF_\emptyset(\delta)$}
    \RightLabel{[$\circ$]}
    \BinaryInfC{$\Gamma, k : \beta_i \to \FF_\emptyset(\delta) \vdash \cherry \circ k : \beta_i \to \delta$}
    \RightLabel{[app]}
    \BinaryInfC{$\Gamma, x : \alpha_i, k : \beta_i \to \FF_\emptyset(\delta) \vdash \ap{\ap{M_i}{x}}{(\cherry \circ k)} : \delta$}
    \RightLabel{[$\eta$]}
    \UnaryInfC{$\Gamma, x : \alpha_i, k : \beta_i \to \FF_\emptyset(\delta) \vdash \ap{\eta}{(\ap{\ap{M_i}{x}}{(\cherry \circ k)})} : \FF_\emptyset(\delta)$}
    \RightLabel{[abs]}
    \UnaryInfC{$\Gamma, x : \alpha_i \vdash \lam{k}{\ap{\eta}{(\ap{\ap{M_i}{x}}{(\cherry \circ k)})}} : (\beta_i \to \FF_\emptyset(\delta)) \to \FF_\emptyset(\delta)$}
    \RightLabel{[abs]}
    \UnaryInfC{$\Gamma \vdash \lam{x k}{\ap{\eta}{(\ap{\ap{M_i}{x}}{(\cherry \circ k)})}} : \alpha_i \to (\beta_i \to \FF_\emptyset(\delta)) \to \FF_\emptyset(\delta)$}
  \end{prooftree}
  \end{adjustwidth}

  $x$ and $k$ are assumed to be fresh for $M_i$.

  \begin{prooftree}
    \AxiomC{$\Gamma, x : \gamma \vdash M_\eta : \gamma \to \delta$}
    \AxiomC{$\Gamma, x : \gamma \vdash x : \gamma$}
    \RightLabel{[app]}
    \BinaryInfC{$\Gamma, x : \gamma \vdash \ap{M_\eta}{x} : \delta$}
    \RightLabel{[$\eta$]}
    \UnaryInfC{$\Gamma, x : \gamma \vdash \etaE{(\ap{M_\eta}{x})} : \FF_\emptyset(\delta)$}
    \RightLabel{[abs]}
    \UnaryInfC{$\Gamma \vdash \lam{x}{\etaE{(\ap{M_\eta}{x})}} : \gamma \to \FF_\emptyset(\delta)$}
  \end{prooftree}

  $x$ is assumed to be fresh for $M_\eta$.
\end{proof}

We can also have reduction rules for closed handlers, which work exactly
the same way as the open handler reduction rules (only they do not include
cases for uninterpreted operations).

\begin{proposition}
  The following reductions are derivable in $\banana{\lambda}$:

  \vspace{2mm}
  \begin{tabular}{>{$}r<{$} >{$}c<{$} >{$}l<{$}}
    \ap{\cibbanana}{(\etaE{N})} & \to_{\bbanana{\eta}} & \ap{M_\eta}{N} \\
    \ap{\cibbanana}{(\app{\op{op}_i}{N_\petitp}{(\lam{x}{N_\petitc})})}
    & \to_{\bbanana{\op{op}}}
    & \app{M_i}{N_\petitp}{(\lam{x}{\ap{\cibbanana}{N_\petitc}})}
  \end{tabular}
  \vspace{2mm}
\end{proposition}

\begin{proof}
  \begin{align*}
    \ap{\cibbanana}{(\etaE{N})}
    &= \ap{\cherry}{(\ap{\banana{(\onto{\op{op}_i}{(\lam{x k}{\ap{\eta}{(\ap{\ap{M_i}{x}}{(\cherry \circ k)})}})})_{i \in I},\ \onto{\eta}{(\lam{x}{\etaE{(\ap{M_\eta}{x})}})}}}{(\etaE{N})})} \\
    &\to_{\banana{\eta}} \ap{\cherry}{(\ap{(\lam{x}{\etaE{(\ap{M_\eta}{x})}})}{N})} \\
    &\to_\beta \ap{\cherry}{({\etaE{(\ap{M_\eta}{N})}})} \\
    &\to_\cherry \ap{M_\eta}{N}
  \end{align*}

  \begin{align*}
    \ap{\cibbanana}{(\app{\op{op}_i}{N_\petitp}{(\lam{x}{N_\petitc})})}
    &= \ap{\cherry}{(\ap{\banana{(\onto{\op{op}_i}{(\lam{x k}{\ap{\eta}{(\ap{\ap{M_i}{x}}{(\cherry \circ k)})}})})_{i \in I},\ \onto{\eta}{(\lam{x}{\etaE{(\ap{M_\eta}{x})}})}}}{(\app{\op{op}_i}{N_\petitp}{(\lam{x}{N_\petitc})})})} \\
    &\to_{\banana{\op{op}}} \ap{\cherry}{(\app{(\lam{x k}{\ap{\eta}{(\ap{\ap{M_i}{x}}{(\cherry \circ k)})}})}{N_\petitp}{(\lam{x}{\ap{\banana{\ldots}}{N_\petitc}})})} \\
    &\to_\beta \ap{\cherry}{(\ap{(\lam{k}{\ap{\eta}{(\ap{\ap{M_i}{N_\petitp}}{(\cherry \circ k)})}})}{(\lam{x}{\ap{\banana{\ldots}}{N_\petitc}})})} \\
    &\to_\beta \ap{\cherry}{(\etaE{(\ap{\ap{M_i}{N_\petitp}}{(\cherry \circ (\lam{x}{\ap{\banana{\ldots}}{N_\petitc}}))})})} \\
    &\to_\cherry \ap{\ap{M_i}{N_\petitp}}{(\cherry \circ (\lam{x}{\ap{\banana{\ldots}}{N_\petitc}}))} \\
    &= \ap{\ap{M_i}{N_\petitp}}{(\lam{x}{\ap{\cherry}{(\ap{(\lam{x}{\ap{\banana{\ldots}}{N_\petitc}})}{x})}})} \\
    &\to_\beta \ap{\ap{M_i}{N_\petitp}}{(\lam{x}{\ap{\cherry}{(\ap{\banana{\ldots}}{N_\petitc})}})} \\
    &= \ap{\ap{M_i}{N_\petitp}}{(\lam{x}{\ap{\cherry}{(\ap{\banana{\ldots}}{N_\petitc})}})} \\
    &= \ap{\ap{M_i}{N_\petitp}}{(\lam{x}{\ap{\cibbanana}{N_\petitc}})}
  \end{align*}

  In the above, $\banana{\ldots}$ is taken to be a shortcut for
  $\banana{(\onto{\op{op}_i}{(\lam{x
        k}{\ap{\eta}{(\ap{\ap{M_i}{x}}{(\cherry \circ k)})}})})_{i \in I},\
    \onto{\eta}{(\lam{x}{\etaE{(\ap{M_\eta}{x})}})}}$.
\end{proof}


\section{Type Soundness}
\label{sec:type-soundness}

In Chapter~\ref{chap:definitions}, we have introduced both a type system
and a reduction semantics for $\banana{\lambda}$. Now we will give more
substance to these two definitions by proving properties which outline the
relationship between them.

Types can give us two guarantees: typed terms do not get stuck and typed
terms always terminate. The former property is known as \emph{progress} and
we will show a limited variant of it for $\banana{\lambda}$
in~\ref{ssec:progress}\footnote{Progress in $\banana{\lambda}$ is limited
  by definition since the $\CC$ operator corresponds to a partial
  function.}. The latter is known as \emph{termination} and its proof is
more involved, so we will delay it until~\ref{sec:termination}.

For both of these properties to hold, it will be essential to prove that a
typed term stays typed after performing a reduction. This will be the
object of the next subsection.


\subsection{Subject Reduction}
\label{ssec:subject-reduction}

We now turn our attention to the subject reduction property. We can
summarize subject reduction with the slogan ``reduction preserves
types''. The rest of this section will consider a formal proof of this
property for $\banana{\lambda}$, but before we begin, we present a small
lemma.

\begin{lemma}\label{lem:substitution-types}
  \demph{Substitution and types}
  
  Whenever we have $\Gamma, x : \alpha \vdash M : \tau$ and
  $\Gamma \vdash N : \alpha$, we also have
  $\Gamma \vdash \subst{M}{x}{N} : \tau$ (i.e.\ we can substitute in $M$
  while preserving the type).
\end{lemma}

\begin{proof}
  The proof is carried out by induction on the structure of $M$ (or rather
  the structure of the type derivation $\Gamma \vdash M : \tau$).

  \begin{itemize}
  \item $M = y$
    \begin{itemize}
    \item If $y = x$, then $\subst{M}{x}{N} = N$ and $\alpha = \tau$. We
      immediately have $\Gamma \vdash \subst{M}{x}{N} : \tau$ from the
      assumption that $\Gamma \vdash N : \alpha$.
    \item If $y \neq x$, then $\subst{M}{x}{N} = x$ and we get
      $\Gamma \vdash \subst{M}{x}{N} : \tau$ from the assumption that
      $\Gamma, x : \alpha \vdash M : \tau$ and the fact that
      $x \notin \FV(M)$.
    \end{itemize}
  
  \item All the other cases end up being trivial. We follow the definition
    of substitution which just applies substitution to all of the
    subterms. For every such subterm, we make appeal to the induction
    hypothesis and construct the new typing derivation.
  \end{itemize}
\end{proof}

\begin{property}\label{prop:subject-reduction}
  (\demph{Subject reduction})
  
  If $\Gamma \vdash M : \tau$ and $M \to N$, then $\Gamma \vdash N : \tau$.
\end{property}

\begin{proof}
  We prove this by induction on the reduction rule used in $M \to N$.
  
  \begin{itemize}
  \item \boxed{M \to_\beta N}

    It must be the case that $M = \ap{(\lam{x}{M'})}{M''}$ and
    $N = \subst{M'}{x}{M''}$. Since, $\Gamma \vdash M : \tau$, we must have the
    following typing derivation:
    
    \begin{prooftree}
      \AxiomC{$\Gamma, x : \alpha \vdash M' : \tau$}
      \RightLabel{[abs]}
      \UnaryInfC{$\Gamma \vdash \lam{x}{M'} : \alpha \to \tau$}
      \AxiomC{$\Gamma \vdash M'' : \alpha$}
      \RightLabel{[app]}
      \BinaryInfC{$\Gamma \vdash \ap{(\lam{x}{M'})}{M''} : \tau$}
    \end{prooftree}
    
    We apply Lemma~\ref{lem:substitution-types} to
    $\Gamma, x : \alpha \vdash M' : \tau$ and $\Gamma \vdash M'' : \alpha$
    to get a typing derivation for
    $\Gamma \vdash \subst{M'}{x}{M''} : \tau$.
    
  \item \boxed{M \to_\eta N}

    We have $M = \lam{x}{\ap{M'}{x}}$ with $x$ fresh for $M'$, $N = M'$ and
    $\tau = \tau_1 \to \tau_2$. Since $\Gamma \vdash M : \tau$, we have
    the following:

    \begin{prooftree}
      \AxiomC{$\Gamma, x : \tau_1 \vdash M' : \tau_1 \to \tau_2$}
      \AxiomC{$\Gamma, x : \tau_1 \vdash x : \tau_1$}
      \RightLabel{[app]}
      \BinaryInfC{$\Gamma, x : \tau_1 \vdash \ap{M'}{x} : \tau_2$}
      \RightLabel{[abs]}
      \UnaryInfC{$\Gamma \vdash \lam{x}{\ap{M'}{x}} : \tau_1 \to \tau_2$}
    \end{prooftree}
    
    From the above derivation, we can extract
    $\Gamma, x : \tau_1 \vdash M' : \tau_1 \to \tau_2$. However, since $x$
    is fresh for $M'$, we can strengthen this to
    $\Gamma \vdash M' : \tau_1 \to \tau_2$, which is what we wanted to
    prove.
    
  \item \boxed{M \to_{\banana{\eta}} N}
    
    We have $M = \ap{\cibanana}{(\etaE{M'})}$, $N = \ap{M_\eta}{M'}$,
    $\tau = \FF_{E'}(\delta)$ and the following typing derivation for $M$:
    
    \begin{prooftree}
      \AxiomC{$\Gamma \vdash M_\eta : \gamma \to \FF_{E'}(\delta)$}
      \AxiomC{$\Gamma \vdash M' : \gamma$}
      \UnaryInfC{$\Gamma \vdash \etaE{M'} : \FF_{E}(\gamma)$}
      \AxiomC{\ldots}
      \RightLabel{[$\banana{}$]}
      \TrinaryInfC{$\Gamma \vdash \ap{\cibanana}{(\etaE{M'})} : \FF_{E'}(\delta)$}
    \end{prooftree}
    
    From the inferred typing judgments for $M_\eta$ and $M'$, we can build
    the typing derivation for $\ap{M_\eta}{M'}$.

    \begin{prooftree}
      \AxiomC{$\Gamma \vdash M_\eta : \gamma \to \FF_{E'}(\delta)$}
      \AxiomC{$\Gamma \vdash M' : \gamma$}
      \RightLabel{[app]}
      \BinaryInfC{$\Gamma \vdash \ap{M_\eta}{M'} : \FF_{E'}(\delta)$}
    \end{prooftree}
    
  \item \boxed{M \to_{\banana{\op{op}}} N}
    
    We have
    $M = \ap{\cibanana}{(\app{\op{op}_j}{M_\petitp}{(\lam{x}{M_\petitc})})}$,
    $N = \app{M_j}{M_\petitp}{(\lam{x}{\ap{\cibanana}{M_\petitc}})}$ and
    $\tau = \FF_{E'}(\delta)$.
    
    \begin{prooftree}
      \AxiomC{$\Gamma \vdash M_j : \alpha_j \to (\beta_j \to \FF_{E'}(\delta)) \to \FF_{E'}(\delta)$}
      \AxiomC{$\Gamma \vdash M_\petitp : \alpha_j$}
      \AxiomC{$\Gamma, x : \beta_j \vdash M_\petitc : \FF_{E}(\gamma)$}
      \def\extraVskip{0pt}
      \noLine
      \BinaryInfC{$\typedopg{\op{op}_j}{\alpha_j}{\beta_j} \in E$}
      \def\extraVskip{2pt}
      \RightLabel{[$\op{op}$]}
      \UnaryInfC{$\Gamma \vdash \app{\op{op}_j}{M_\petitp}{(\lam{x}{M_\petitc})} : \FF_{E}(\gamma)$}
      \AxiomC{\ldots}
      \RightLabel{[$\banana{}$]}
      \TrinaryInfC{$\Gamma \vdash \ap{\cibanana}{(\app{\op{op}_j}{M_\petitp}{(\lam{x}{M_\petitc})})} : \FF_{E'}(\delta)$}
    \end{prooftree}
    
    From the types of $M_\petitp$, $M_\petitc$ and $M_j$, we can calculate
    the type of our redex,
    $\app{M_j}{M_\petitp}{(\lam{x}{\ap{\cibanana}{M_\petitc}})}$.
    
    \begin{adjustwidth}[]{-1cm}{-1cm}
    \begin{prooftree}
      \AxiomC{$\Gamma \vdash M_j : \alpha_j \to (\beta_j \to \FF_{E'}(\delta)) \to \FF_{E'}(\delta)$}
      \AxiomC{$\Gamma \vdash M_\petitp : \alpha_j$}
      \RightLabel{[app]}
      \BinaryInfC{$\Gamma \vdash \ap{M_j}{M_\petitp} : (\beta_j \to \FF_{E'}(\delta)) \to \FF_{E'}(\delta)$}
      \AxiomC{$\Gamma, x : \beta_j \vdash M_\petitc : \FF_{E}(\gamma)$}
      \AxiomC{\ldots}
      \RightLabel{[$\banana{}$]}
      \BinaryInfC{$\Gamma, x : \beta_j \vdash \ap{\cibanana}{M_\petitc} : \FF_{E'}(\delta)$}
      \RightLabel{[abs]}
      \UnaryInfC{$\Gamma \vdash \lam{x}{\ap{\cibanana}{M_\petitc}} : \beta_j \to \FF_{E'}(\delta)$}
      \RightLabel{[app]}
      \BinaryInfC{$\Gamma \vdash \app{M_j}{M_\petitp}{(\lam{x}{\ap{\cibanana}{M_\petitc}})} : \FF_{E'}(\delta)$}
    \end{prooftree}
    \end{adjustwidth}
    

  \item \boxed{M \to_{\banana{\op{op}'}} N}
    
    We have
    $M = \ap{\cibanana}{(\app{\op{op}}{M_\petitp}{(\lam{x}{M_\petitc})})}$,
    $N = \app{\op{op}}{M_\petitp}{(\lam{x}{\ap{\cibanana}{M_\petitc}})}$ and
    $\tau = \FF_{E'}(\delta)$.
    
    \begin{prooftree}
      \AxiomC{$\Gamma \vdash M_\petitp : \alpha$}
      \AxiomC{$\Gamma, x : \beta \vdash M_\petitc : \FF_{E}(\gamma)$}
      \def\extraVskip{0pt}
      \noLine
      \BinaryInfC{$\typedop{\op{op}}{\alpha}{\beta} \in E$}
      \def\extraVskip{2pt}
      \RightLabel{[$\op{op}$]}
      \UnaryInfC{$\Gamma \vdash \app{\op{op}}{M_\petitp}{(\lam{x}{M_\petitc})} : \FF_{E}(\gamma)$}
      \AxiomC{$\typedop{\op{op}}{\alpha}{\beta} \in E'$}
      \AxiomC{\ldots}
      \RightLabel{[$\banana{}$]}
      \TrinaryInfC{$\Gamma \vdash \ap{\cibanana}{(\app{\op{op}}{M_\petitp}{(\lam{x}{M_\petitc})})} : \FF_{E'}(\delta)$}
    \end{prooftree}
    
    From the inferred judgments, we can build a typing derivation for the
    redex.

    \begin{prooftree}
      \AxiomC{$\Gamma \vdash M_\petitp : \alpha$}
      \AxiomC{$\Gamma, x : \beta \vdash M_\petitc : \FF_{E}(\gamma)$}
      \AxiomC{\ldots}
      \RightLabel{[$\banana{}$]}
      \BinaryInfC{$\Gamma, x : \beta \vdash \ap{\cibanana}{M_\petitc} : \FF_{E'}(\delta)$}
      \AxiomC{$\typedop{\op{op}}{\alpha}{\beta} \in E'$}
      \RightLabel{[$\op{op}$]}
      \TrinaryInfC{$\Gamma \vdash \app{\op{op}}{M_\petitp}{(\lam{x}{\ap{\cibanana}{M_\petitc}})} : \FF_{E'}(\delta)$}
    \end{prooftree}
    
  \item \boxed{M \to_\cherry N}
    
    In this case, $M = \ap{\cherry}{(\etaE{M'})}$ and $N = M'$.
    
    \begin{prooftree}
      \AxiomC{$\Gamma \vdash M' : \tau$}
      \RightLabel{[$\eta$]}
      \UnaryInfC{$\Gamma \vdash \etaE{M'} : \FF_\emptyset(\tau)$}
      \RightLabel{[$\cherry$]}
      \UnaryInfC{$\Gamma \vdash \ap{\cherry}{(\etaE{M'})} : \tau$}
    \end{prooftree}
    
    We immediately get $\Gamma \vdash M' : \tau$, which is the sought after
    typing derivation of the redex.
    
  \item \boxed{M \to_{\CC_\eta} N}
    
    $M = \ap{\CC}{(\lam{x}{\etaE{M}})}$, $N = \etaE{(\lam{x}{M})}$ and
    $\tau = \FF_E(\gamma \to \delta)$.
    
    \begin{prooftree}
      \AxiomC{$\Gamma, x : \gamma \vdash M : \delta$}
      \RightLabel{[$\eta$]}
      \UnaryInfC{$\Gamma, x : \gamma \vdash \etaE{M} : \FF_E(\delta)$}
      \RightLabel{[abs]}
      \UnaryInfC{$\Gamma \vdash \lam{x}{\etaE{M}} : \gamma \to \FF_E(\delta)$}
      \RightLabel{[$\CC$]}
      \UnaryInfC{$\Gamma \vdash \ap{\CC}{(\lam{x}{\etaE{M}})} : \FF_E(\gamma \to \delta)$}
    \end{prooftree}
    
    From these judgments, we build a type for the redex.

    \begin{prooftree}
      \AxiomC{$\Gamma, x : \gamma \vdash M : \delta$}
      \RightLabel{[abs]}
      \UnaryInfC{$\Gamma \vdash \lam{x}{M} : \gamma \to \delta$}
      \RightLabel{[$\eta$]}
      \UnaryInfC{$\Gamma \vdash \etaE{(\lam{x}{M})} : \FF_E(\gamma \to \delta)$}
    \end{prooftree}
    
  \item \boxed{M \to_{\CC_{\op{op}}} N}
    
    $M = \ap{\CC}{(\lam{x}{\app{\op{op}}{M_\petitp}{(\lam{y}{M_\petitc})}})}$,
    $N = \app{\op{op}}{M_\petitp}{(\lam{y}{\ap{\CC}{(\lam{x}{M_\petitc})}})}$
    and $\tau = \FF_E(\gamma \to \delta)$.
    
    \begin{prooftree}
      \AxiomC{$\Gamma, x : \gamma \vdash M_\petitp : \alpha$}
      \AxiomC{$\Gamma, x : \gamma, y : \beta \vdash M_\petitc : \FF_{E}(\delta)$}
      \def\extraVskip{0pt}
      \noLine
      \BinaryInfC{$\typedop{\op{op}}{\alpha}{\beta} \in E$}
      \def\extraVskip{2pt}
      \RightLabel{[$\op{op}$]}
      \UnaryInfC{$\Gamma, x : \gamma \vdash \app{\op{op}}{M_\petitp}{(\lam{y}{M_\petitc})} : \FF_E(\delta)$}
      \RightLabel{[abs]}
      \UnaryInfC{$\Gamma \vdash \lam{x}{\app{\op{op}}{M_\petitp}{(\lam{y}{M_\petitc})}} : \gamma \to \FF_E(\delta)$}
      \RightLabel{[$\CC$]}
      \UnaryInfC{$\Gamma \vdash \ap{\CC}{(\lam{x}{\app{\op{op}}{M_\petitp}{(\lam{y}{M_\petitc})}})} : \FF_E(\gamma \to \delta)$}
    \end{prooftree}
    
    With the judgments above, we build the derivation below.
    
    \begin{prooftree}
      \AxiomC{$\Gamma \vdash M_\petitp : \alpha$}
      \AxiomC{$\Gamma, y : \beta, x : \gamma \vdash M_\petitc : \FF_E(\delta)$}
      \RightLabel{[abs]}
      \UnaryInfC{$\Gamma, y : \beta \vdash \lam{x}{M_\petitc} : \gamma \to \FF_E(\delta)$}
      \RightLabel{[$\CC$]}
      \UnaryInfC{$\Gamma, y : \beta \vdash \ap{\CC}{(\lam{x}{M_\petitc})} : \FF_E(\gamma \to \delta)$}
      \AxiomC{$\typedop{\op{op}}{\alpha}{\beta} \in E$}
      \RightLabel{[$\op{op}$]}
      \TrinaryInfC{$\Gamma \vdash \app{\op{op}}{M_\petitp}{(\lam{y}{\ap{\CC}{(\lam{x}{M_\petitc})}})} : \FF_E(\gamma \to \delta)$}
    \end{prooftree}
    
    In the above we get $\Gamma \vdash M_\petitp : \alpha$ from
    $\Gamma, x : \gamma \vdash M_\petitp : \alpha$ from the rule's
    condition that $x \notin \FV(M_\petitp)$.
    
  \item \boxed{C[M'] \to C[N']}
    
    The reduction relation of $\banana{\lambda}$ is defined as the context
    closure of the individual reduction rules. We have covered the rules
    themselves, we now address the context closure. By induction
    hypothesis, we know that the reduction from $M' \to N'$ preserves
    types, i.e.\ for any $\Delta$ and $\alpha$ such that
    $\Delta \vdash M' : \alpha$, we have $\Delta \vdash N' : \alpha$.

    We observe that the typing rules of $\banana{\lambda}$
    (Figure~\ref{fig:types}) are compositional, meaning that the type of a
    term depends only on the types of its subterms, not on their syntactic
    form. We can check this easily by looking at the premises of all of the
    typing rules. For every immediate subterm $T$, there is a premise
    $\Delta \vdash T : \alpha$ where $T$ is a metavariable. We can
    therefore replace $T$ and its typing derivation by some other $T'$ with
    $\Delta \vdash T' : \alpha$.

    Since the typing rules of $\banana{\lambda}$ are compositional, we can
    replace the $\Delta \vdash M' : \alpha$ in $\Gamma \vdash C[M'] : \tau$
    by $\Delta \vdash N' : \alpha$ and get $\Gamma \vdash C[N'] : \tau$.
  \end{itemize}
\end{proof}

We have proven subject reduction for core $\banana{\lambda}$. The syntax,
semantics and types that we have introduced for sums and products are
standard. Their proofs of subject reduction carry over into our setting as
well.


\subsection{Progress}
\label{ssec:progress}

Progress means that typed terms are never stuck. But what is a stuck term?
Among the terms of $\banana{\lambda}$, we will have to identify terms which
are acceptable stopping points for reduction. Progress will thus mean that
if a term is not in one of these acceptable positions, then there must be a
way to continue reducing. The term we will use for these acceptable results
is \emph{value}.

\begin{definition}
  A $\banana{\lambda}$ term is a \demph{value} if it can be generated by
  the following grammar:

\begin{align*}
  V ::= &\ \lam{x}{M} \\
   | \, &\ \app{\op{op}}{V}{(\lam{x}{M})} \\
   | \, &\ \etaE{V}
\end{align*}

  where $M$ ranges over $\banana{\lambda}$ terms.
\end{definition}

The above definition reflects the intuition that $\banana{\lambda}$
consists of functions and computations, where functions are built using
$\lambda$ and computations using $\op{op}$ and $\eta$. The other syntactic
constructions (application, $\banana{}$, $\cherry$ and $\CC$) all have
rules which are supposed to eventually replace them with other terms.

As with subject reduction, before we proceed to the main property, we will
start with a small lemma.

\begin{lemma}\label{lem:value-classification}
  (Value classification)

  Let $V$ be a closed well-typed value (i.e.\ $\emptyset \vdash V :
  \tau$). Then the following hold:

  \begin{itemize}
  \item if $\tau = \alpha \to \beta$, then $V = \lam{x}{M}$
  \item if $\tau = \FF_E(\alpha)$, then either
    $V = \app{\op{op}}{V_\petitp}{(\lam{x}{M_\petitc})}$ or $V = \etaE{V'}$
  \end{itemize}
\end{lemma}

\begin{proof}\hspace{1cm}

  \begin{itemize}
  \item Assume $\tau = \alpha \to \beta$. If
    $V = \app{\op{op}}{V_\petitp}{(\lam{x}{M_\petitc})}$ or
    $V = \etaE{V'}$, then $\tau$ must be a computation type
    $\FF_E(\gamma)$, which is a contradiction. The only remaining
    possibility is therefore $V = \lam{x}{M}$.
  \item Assume $\tau = \FF_E(\alpha)$. If $V = \lam{x}{M}$, then $\tau$
    must be a function type $\beta \to \gamma$, which is a
    contradiction. The only remaining possibilities are therefore
    $V = \app{\op{op}}{V_\petitp}{(\lam{x}{M_\petitc})}$ or
    $V = \etaE{V'}$.
  \end{itemize}
\end{proof}

\begin{property}\label{prop:progress}
  (Progress) 

  Every closed well-typed term $M$ from $\banana{\lambda}$ without $\CC$
  and constants\footnote{Constants are assumed to be reduced away by some
    external rule. In our case, this will be the application of an ACG
    lexicon (\ref{sec:abstract-categorial-grammars}).} is either a value or
  is reducible to some other term.
\end{property}

\begin{proof}
  We will proceed by induction on $M$.

  \begin{itemize}
  \item $M = \lam{x}{M'}$

    Then $M$ is already a value.

  \item $M = x$

    Impossible, since $M$ must be a closed term.

  \item $M = \ap{M_1}{M_2}$

    By induction hypothesis, $M_1$ and $M_2$ are either values or reducible
    terms. If either one is reducible, then our term is reducible as well
    and we are done. If neither is reducible, then they are both
    values. Since $M$ is a closed well-typed term (i.e.\
    $\emptyset \vdash M : \tau$), then
    $\empty \vdash M_1 : \alpha \to \tau$ for some $\alpha$. Thanks to
    Lemma~\ref{lem:value-classification}, we have that
    $M_1 = \lam{x}{M_1'}$. This means that $M = \ap{(\lam{x}{M_1'})}{M_2}$
    and is therefore reducible with $\beta$.

  \item $M = \app{\op{op}}{M_\petitp}{(\lam{x}{M_\petitc})}$

    By induction hypothesis, $M_\petitp$ is either reducible or a value. If
    $M_\petitp$ is reducible, then so is $M$. If it is a value, then so is
    $M$ as well.

  \item $M = \etaE{N}$

    The same argument as for $\op{op}$. By induction hypothesis $N$ is
    reducible or a value and therefore the same holds for $M$.

  \item $M = \ap{\cibanana}{N}$

    By induction hypothesis, $N$ is either a value or it is itself
    reducible. If it is reducible, then so is $M$. If it is not, then it
    must be a (closed) value. The type of $N$ is a computation type
    $\FF_E(\alpha)$ and so by Lemma~\ref{lem:value-classification}, it must
    either be $\app{\op{op}}{V_\petitp}{(\lam{x}{M_\petitc})}$ or
    $\etaE{V}$. If $N = \app{\op{op}}{V_\petitp}{(\lam{x}{M_\petitc})}$,
    then $\ap{\cibanana}{(\app{\op{op}}{V_\petitp}{(\lam{x}{M_\petitc})})}$
    is reducible by $\banana{\op{op}}$ or $\banana{\op{op}'}$ (depending on
    whether or not $\op{op} \in \{\op{op}_i\}_{i \in I}$). Otherwise, if
    $N = \etaE{V}$, then $\ap{\cibanana}{(\etaE{V})}$ is reducible by
    $\banana{\eta}$.

  \item $M = \ap{\cherry}{N}$

    By induction hypothesis, $N$ is either reducible or a value. As before,
    we only have to focus on the case when $N$ is a value. From
    Lemma~\ref{lem:value-classification}, we know that
    $N = \app{\op{op}}{V_\petitp}{(\lam{x}{M_\petitc})}$ or $N =
    \etaE{V}$. However, we can rule out the former since we know that
    $\emptyset \vdash N : \FF_\emptyset(\alpha)$, meaning that $\op{op}$ is
    not in the empty effect signature $\emptyset$. We therefore end up with
    $\ap{\cherry}{(\etaE{V})}$, which is reducible by $\cherry$.
  \end{itemize}
\end{proof}

We have shown progress for $\banana{\lambda}$ without $\CC$. It is easy to
see that we cannot do better, as the $\CC$ operator can violate progress
and get us stuck quite easily.

\begin{observation}
  There exists a closed well-typed term $M$ from $\banana{\lambda}$ without
  constants that is neither a value nor reducible to some other term.
\end{observation}

\begin{proof}
  The most trivial example is $\ap{\CC}{(\lam{x}{x})}$. The computation
  that is performed by the body of the function $\lam{x}{x}$ is entirely
  determined by the parameter $x$. It is therefore not possible to pull out
  this structure outside of the function. Therefore, applying the $\CC$
  operator to this function is undefined and evaluation gets stuck.
\end{proof}


\section{Algebraic Properties}
\label{sec:algebraic-properties}

In this section, we will clarify what we mean when we say that the
$\FF_E(\alpha)$ computation types form a functor/applicative functor/monad
and we will prove that the constructions in $\banana{\lambda}$ conform to
the laws of these algebraic structures.

The object on which we will build these mathematical structures will be the
meanings of $\banana{\lambda}$ terms. We will therefore start by building
an interpretation for $\banana{\lambda}$, a denotational semantics. Then we
will be in measure to define the algebraic structures mentioned above and
verify that their laws are satisfied.


\subsection{Denotational Semantics}
\label{ssec:denotational-semantics}

We start by identifying the domains of interpretation. For each type, we
designate a set such that all terms having that type will be interpreted in
that set. Before we do so, we introduce some notation on sets.

\begin{notation}
  Let $A$ and $B$ be sets. Then:

  \begin{itemize}
  \item $A^B$ is the set of functions from $B$ to $A$
  \item $A \times B$ is the cartesian product of $A$ and $B$
  \item $A \uplus B$ is the disjoint union of $A$ and $B$
  \item $A_\bot$ is the disjoint union of $A$ and $\{\bot\}$
  \end{itemize}
\end{notation}

\begin{definition}
  Given a set $A_\nu$ for every atomic type $\nu$, the
  \demph{interpretation of a type} $\tau$ is a set $\sem{\tau}$ defined
  inductively by:
  
  \begin{align*}
    \sem{\nu} &= (A_\nu)_\bot \\
    \sem{\alpha \to \beta} &= (\sem{\alpha} \to \sem{\beta})_\bot \\
    \sem{\FF_E(\gamma)} &=
      (\sem{\gamma} \uplus \biguplus_{\typedop{op}{\alpha}{\beta} \in E} \sem{\alpha} \times \sem{\FF_E(\gamma)}^{\sem{\beta}})_\bot
  \end{align*}
  
  Note that $\sem{\FF_E(\gamma)}$ is recursively defined not only by
  induction on the type itself but also by its use of $\sem{\FF_E(\gamma)}$
  on the right hand side. Formally, we take $\sem{\FF_E(\gamma)}$ to be the
  least fixed point of the monotone functional
  $F(X) = (\sem{\gamma} \uplus \biguplus_{\typedop{op}{\alpha}{\beta} \in
    E} \sem{\alpha} \times X^{\sem{\beta}})_\bot$, whose existence is
  guaranteed by the Knaster-Tarski theorem
  \cite{knaster1928theoreme,tarski1955lattice}.
\end{definition}

\begin{notation}
  We will use $\lambda$ notation to write down elements of
  $\sem{\alpha \to \beta}$:
  
  \begin{itemize}
  \item $\lam{x}{F[x]} \in \sem{\alpha \to \beta}$ when
    $F[x] \in \sem{\beta}$ for every $x \in \sem{\alpha}$
  \item $\bot \in \sem{\alpha \to \beta}$
  \end{itemize}

  We will use the following syntax to write down elements of
  $\sem{\FF_E(\gamma)}$:
  
  \begin{itemize}
  \item $\eta(x) \in \sem{\FF_E(\gamma)}$ with $x \in \sem{\gamma}$
  \item $\op{op}(p,c) \in \sem{\FF_E(\gamma)}$ with
    $\typedop{op}{\alpha}{\beta} \in E$, $p \in \sem{\alpha}$ and
    $c \in \sem{\FF_E(\gamma)}^{\sem{\beta}}$
  \item $\bot \in \sem{\FF_E(\gamma)}$
  \end{itemize}
\end{notation}

The definition of $\sem{\tau}$ follows the definition of a value
in~\ref{ssec:progress}: function types denote functions and computation
types either denote atomic algebraic expressions ($\eta$) or applications
of algebraic operations ($\op{op}$). In the denotational semantics, we also
take care of the fact that terms can get stuck and fail to yield the
expected value. We represent this by adding the element $\bot$ to the
interpretation of every type.

\begin{definition}
  We define the \demph{interpretation of a typing context} $\Gamma$
  as the set $\sem{\Gamma}$ of functions that map every
  $x : \alpha \in \Gamma$ to an element of $\sem{\alpha}$.
  
  We will call these functions \demph{valuations}. We will use the notation
  $\subst{e}{x}{f}$ to stand for the \demph{extension} of $e$ with
  $x \mapsto f$. The domain of the extension is $\dom(e) \cup x$. The
  extension maps $x$ to $f$ and every other variable in its domain to
  $e(x)$.
\end{definition}

\begin{definition}
  Assume given $\II(c) \in \sem{\alpha}$ for every constant
  $c : \alpha \in \Sigma$. For a well-typed term $M$ with
  $\Gamma \vdash M : \tau$, we define the \demph{interpretation of term}
  $M$ as a function $\sem{M}$ from $\sem{\Gamma}$ to $\sem{\tau}$. The
  definition proceeds by induction on $M$\footnote{In the definition, we
    make use of $\sem{\cibanana}(e)$ and $\sem{\CC}$. This notation is
    introduced right after this definition.}:
  
  \begin{align*}
    \sem{\lam{x}{M}}(e) &= \lam{X}{(\sem{M}(\subst{e}{x}{X}))} \\
    \sem{x}(e) &= e(x) \\
    \sem{\ap{M}{N}}(e) &= \begin{cases}
      \sem{M}(e)(\sem{N}(e)),& \text{if $\sem{M}(e)$ is a function} \\
      \bot, & \text{if $\sem{M}(e)$ is $\bot$}
    \end{cases} \\
    \sem{c}(e) &= \II(c) \\
    \sem{\app{\op{op}}{M_\petitp}{(\lam{x}{M_\petitc})}}(e) &=
      \op{op}(\sem{M_\petitp}(e), \lam{X}{(\sem{M_\petitc}({\subst{e}{x}{X}}))}) \\
    \sem{\etaE{M}}(e) &= \eta(\sem{M}(e)) \\
    \sem{\ap{\cibanana}{N}}(e) &= \sem{\cibanana}(e)(\sem{N}(e)) \\
    \sem{\ap{\cherry}{M}}(e) &= \begin{cases}
      x, & \text{if $\sem{M}(e) = \eta(x)$} \\
      \bot, & \text{otherwise} \\
    \end{cases} \\
    \sem{\ap{\CC}{M}}(e) &= \sem{\CC}(\sem{M}(e))
  \end{align*}
\end{definition}

\begin{definition}
  The \demph{interpretation of a handler} $\cibanana$ within a valuation
  $e$ (also written as $\sem{\cibanana}(e)$) is the function $h$ defined
  inductively by:

  \begin{align*}
    h(\eta(x)) &= \begin{cases}
      \sem{M_\eta}(e)(x), & \text{if $\sem{M_\eta}(e)$ is a function} \\
      \bot, & \text{otherwise} \\
    \end{cases} \\
    h(\op{op}_j(p, c)) &= \begin{cases} 
      \sem{M_j}(e)(p)(\lam{x}{h(c(x))}), & \text{if $j \in I$, and $\sem{M_j}(e)$ and $\sem{M_j}(e)(p)$ are both functions} \\
      \op{op}_j(p, \lam{x}{h(c(x))}), & \text{if $j \notin I$} \\
      \bot, & \text{otherwise} \\
    \end{cases} \\
    h(\bot) &= \bot
  \end{align*}
  
  The equations defining $h$ use $h$ on the right-hand side. Nevertheless,
  $h$ is well-defined since we can rely on induction. There is a
  \demph{well-founded ordering on the elements of $\sem{\FF_E(\gamma)}$},
  where $\forall x.\ \op{op}(p, c) > c(x)$.

  The monotonic functional
  $F(X) = (\sem{\gamma} \uplus \biguplus_{\typedop{op}{\alpha}{\beta} \in
    E} \sem{\alpha} \times X^{\sem{\beta}})_\bot$ used in defining
  $\sem{\FF_E(\gamma)}$ is also Scott-continuous (i.e.\ it is both
  monotonic and it preserves suprema). By Kleene fixed-point
  theorem~\cite{kleene1952introduction}, we have that the least fixed point
  of $F$ is the supremum of the series
  $\emptyset \subseteq F(\emptyset) \subseteq F(F(\emptyset)) \subseteq
  \ldots$.

  Let the \demph{rank} of $x$ be the smallest $n$ such that
  $x \in F^n(\emptyset)$. The ordering $<_\petitr$, defined as
  $x <_\petitr y$ whenever $\rank(x) < \rank(y)$, is a well-founded
  ordering. It is also the inductive ordering that we were looking
  for. Whenever $\rank(\op{op}(p, c)) = n$, then $c$ is a function whose
  codomain is $F^{n-1}(\emptyset)$ and therefore
  $\forall x.\ \op{op}(p, c) >_\petitr c(x)$.
\end{definition}

\begin{definition}
  The \demph{interpretation of the $\CC$ operator} is a function $g$
  defined inductively by:
  
  \begin{align*}
    g(f) &= \begin{cases}
      \eta(h), & \text{if $f$ is a function and $\exists h.\ \forall x.\ f(x) = \eta(h(x))$} \\
      \op{op}(p, \lam{y}{g(\lam{x}{c(x)(y)})}), & \text{if $f$ is a function and $\exists \op{op},p,c.\ \forall x.\ f(x) = \op{op}(p, c(x))$} \\
      \bot, & \text{otherwise} \\
    \end{cases}
  \end{align*}
  
  As with the previous definition, we have to show that this is actually a
  valid definition since we are using $g$ on the right-hand side of an
  equation defining $g$. This time around, the arguments to $g$ are
  functions whose codomain is the interpretation of some computation type
  $\FF_E(\beta)$. We can extend a well-founded ordering on the set
  $\sem{\FF_E(\beta)}$ to a \demph{well-founded ordering on
    $\sem{\alpha \to \FF_E(\beta)}$} by stating that $f < g$ whenever $f$
  and $g$ are both functions (not $\bot$) and
  $\forall x \in \sem{\alpha}.\ f(x) < g(x)$.
  
  We have to show that the recursive call to $g$ in the definition above is
  performed on an argument which is smaller than the original function. Let
  $f' = \lam{x}{c(x)(y)}$ be the function to which we recursively apply
  $g$. We have that $f(x) = \op{op}(p, c(x))$ and $f'(x) = c(x)(y)$. We
  know that $\forall y.\ \op{op}(p, c(x)) > c(x)(y)$, since that is the
  property of the well-founded ordering on the elements of
  $\sem{\FF_E(\gamma)}$ established above. Therefore, we have that
  $\forall x \in \sem{\alpha}.\ f(x) > f'(x)$ and so $f > f'$.
\end{definition}

This was the entire definition of our denotational semantics\footnote{We
  could also extend this interpretation to sums and products. The types
  would be interpreted by
  $\sem{\alpha \times \beta} = (\sem{\alpha} \times \sem{\beta})_\bot$ and
  $\sem{\alpha + \beta} = (\sem{\alpha} \uplus \sem{\beta})_\bot$. The term
  level definitions would be the standard definitions one would expect for
  pairs and variants (modulo the treatment of $\bot$).}. We will now
compare it to the reduction semantics introduced in~\ref{sec:reductions}.

\begin{observation}\label{obs:denotation-soundness}
  (Soundness of reduction w.r.t.\ denotations)

  Whenever $M \to N$ in $\banana{\lambda}$, then $\sem{M} = \sem{N}$.
\end{observation}

\begin{proof}
  To prove so for the $\beta$ rule is a matter of proving a lemma stating
  that $\sem{M}(\subst{e}{x}{\sem{N}(e)}) = \sem{\subst{M}{x}{N}}(e)$,
  which follows from the compositionality of our interpretation. For all
  the other rules, it suffices to use the definition of interpretation to
  calculate the denotation of both the left-hand side and the right-hand
  side and verify that they are the same object.
\end{proof}

We see that equalities from the reduction semantics are carried over to the
denotational semantics. The converse, however, is not the case.

\begin{observation}
  (Incompleteness of reduction w.r.t.\ denotations)
  
  There exist terms $M$ and $N$ in $\banana{\lambda}$ such that
  $\sem{M} = \sem{N}$ but $M$ and $N$ are not convertible.
\end{observation}

\begin{proof}
  Consider a stuck term such as $M = \ap{\CC}{(\lam{x}{x})}$ and another
  term $N = \ap{\banana{}}{M} =
  \ap{\banana{}}{(\ap{\CC}{(\lam{x}{x})})}$. Neither of these two terms is
  reducible and neither of them is a value. They are stuck and the
  denotational semantics assigns the value $\bot$ to both of them,
  therefore $\sem{M} = \sem{N}$. However, as a consequence of confluence
  (coming up in~\ref{sec:confluence}), a pair of different normal terms is
  never convertible, and therefore $M$ and $N$ are not convertible.
\end{proof}

And this concludes the definition of the denotational semantics of
$\banana{\lambda}$. Throughout most of the manuscript, we will be using the
reduction semantics introduced in~\ref{sec:reductions}, even though it is
incomplete, since it allows us to simplify terms in a mechanical and
transparent step-by-step manner. However, the denotational semantics will
be useful to us in the rest of this section since it will let us access
extra equalities needed to prove some general laws.


\subsection{Category}
\label{ssec:category}

We aim to show that the computation types in $\banana{\lambda}$ form a
functor, applicative functor and a monad. All these terms are defined
w.r.t.\ some category and so we will start by introducing the category
underlying $\banana{\lambda}$.

\begin{definition}
 A \demph{category} consists of:
\begin{itemize}
\item a set of objects
\item for every two objects $A$ and $B$, a set of arrows from $A$ to $B$
  (an arrow $f$ from $A$ to $B$ is written as $f : A \to B$)
\item for any two arrows $f : B \to C$ and $g : A \to B$, there exists the
  composition of the two arrows $f \circ g : A \to C$
\item for any object $A$, there exists a special arrow $\id_A : A \to A$
\item the following equations hold for any $f : C \to D$, $g : B \to C$ and
  $h : A \to B$:
  \begin{align}
    \label{law:cat-associativity}(f \circ g) \circ h &= f \circ (g \circ h) & \text{(Associativity)} \\
    \label{law:cat-left-identity}\id_D \circ f &= f & \text{(Left identity)} \\
    \label{law:cat-right-identity}f \circ \id_C &= f & \text{(Right identity)}
  \end{align}
\end{itemize}
\end{definition}

We will be working with a particular category, which we will call
$\banana{\lambda}$. The $\banana{\lambda}$ category consists of:
\begin{description}
\item[objects:] the types of the $\banana{\lambda}$ calculus
\item[arrows:] for any two types $\alpha$ and $\beta$, the arrows from
  $\alpha$ to $\beta$ are the functions from $\sem{\alpha}$ o
  $\sem{\beta}$
\item[composition:] composition of arrows is defined as composition of functions
\item[identities:] for every type $\alpha$, we define $\id_\alpha$ as the
  identity function with domain $\sem{\alpha}$
\end{description}

Since the arrows in our category are functions, the three laws of a
category (associativity (\ref{law:cat-associativity}), left identity
(\ref{law:cat-left-identity}) and right identity
(\ref{law:cat-right-identity})) fall out of the same properties for
functions.


\subsection{The Three Laws}
\label{ssec:three-laws}

Monads form a subset of applicative functors which in turn is a subset of
functors. Instead of incrementally building up from a functor all the way
to a monad, it will end up being more practical to first prove the monad
laws and then just show how they let us verify the functor and applicative
functor laws. Therefore, we first define our monadic bind operator and
prove the three monad laws.

\begin{definition}
  Let $X$ be from $\sem{\FF_E(\alpha)}$ and $f$ be a function from
  $\sem{\alpha}$ to $\sem{\FF_E(\beta)}$. We define $X \hsbind f$
  inductively on the structure of $X$:

  \begin{align*}
    \op{op}(p, c) \hsbind f &= \op{op}(p, \lam{x}{c(x) \hsbind f}) \\
    \eta(x) \hsbind f &= f(x) \\
    \bot \hsbind f &= \bot
  \end{align*}

  Note that $X \hsbind f$ is equivalent to
  $\sem{x \hsbind y}([x \mapsto X, y \mapsto f])$.
\end{definition}

\begin{law}\label{law:associativity}
  (Associativity of $\hsbind$)
  
  Let $X$ be from $\sem{\FF_E(\alpha)}$, $f$ be a function from
  $\sem{\alpha}$ to $\sem{\FF_E(\beta)}$ and $g$ be a function from
  $\sem{\beta}$ to $\sem{\FF_E(\gamma)}$. Then the following equation
  holds:
  
  $$
  (X \hsbind f) \hsbind g = X \hsbind (\lam{x}{f(x) \hsbind g})
  $$
\end{law}

\begin{proof}
  Proof by induction on the well-founded structure of $X$:
  
  \begin{itemize}
  \item $X = \bot$
    
    \vspace{-0.5cm}
    \begin{align*}
      (\bot \hsbind f) \hsbind g
      &= \bot \hsbind g \\
      &= \bot \\
      &= \bot \hsbind (\lam{x}{f(x) \hsbind g})
    \end{align*}
    
  \item $X = \eta(x)$

    \vspace{-0.5cm}
    \begin{align*}
      (\eta(x) \hsbind f) \hsbind g
      &= f(x) \hsbind g \\
      &= (\lam{x}{f(x) \hsbind g})(x) \\
      &= \eta(x) \hsbind (\lam{x}{f(x) \hsbind g})
    \end{align*}
    
  \item $X = \op{op}(p, c)$
    
    \vspace{-0.5cm}
    \begin{align*}
      (\op{op}(p, c) \hsbind f) \hsbind g
      &= \op{op}(p, \lam{y}{c(y) \hsbind f}) \hsbind g \\
      &= \op{op}(p, \lam{y}{(c(y) \hsbind f) \hsbind g}) \\
      &= \op{op}(p, \lam{y}{c(y) \hsbind (\lam{x}{(f(x) \hsbind g}))}) \\
      &= \op{op}(p, c) \hsbind (\lam{x}{f(x) \hsbind g})
    \end{align*}
  \end{itemize}
\end{proof}

\begin{law}\label{law:left-identity}
  (Left identity for $\hsbind$)
  
  Let $\eta(x)$ be from $\sem{\FF_E(\alpha)}$ and $f$ be a function from
  $\sem{\alpha}$ to $\sem{\FF_E(\beta)}$. Then the following holds:
  
  $$
  \eta(x) \hsbind f = f(x)
  $$
\end{law}

\begin{proof}
  Follows immediately from the definition of $\hsbind$.
\end{proof}

\begin{law}\label{law:right-identity}
  (Right identity for $\hsbind$)
  
  Let $X$ be from $\sem{\FF_E(\alpha)}$. Then the following holds:

  $$
  X \hsbind (\lam{x}{\eta(x)}) = X
  $$
\end{law}

\begin{proof}
  By induction on the structure of $X$:
  
  \begin{itemize}
  \item $X = \bot$
    
    \vspace{-0.5cm}
    \begin{align*}
      \bot \hsbind (\lam{x}{\eta(x)})
      &= \bot
    \end{align*}
   
  \item $X = \eta(x)$
    
    \vspace{-0.5cm}
    \begin{align*}
      \eta(x) \hsbind (\lam{x}{\eta(x)})
      &= (\lam{x}{\eta(x)})(x) \\
      &= \eta(x)
    \end{align*}
    
  \item $X = \op{op}(p, c)$

    \vspace{-0.5cm}
    \begin{align*}
      \op{op}(p, c) \hsbind (\lam{x}{\eta(x)})
      &= \op{op}(p, \lam{y}{c(y) \hsbind (\lam{x}{\eta(x)})}) \\
      &= \op{op}(p, \lam{y}{c(y)}) \\
      &= \op{op}(p, c)
    \end{align*}
  \end{itemize}
\end{proof}


\subsection{Functor}
\label{ssec:functor}

We will start by showing what is a functor and in what way do our
computation types form one.

\begin{definition}
A \demph{functor} is a homomorphic mapping from one category to
another. A functor $F$ from a category a $\CC$ to a category $\DD$
consists of:
\begin{itemize}
\item for every object $A$ in $\CC$, an object $F(A)$ in $\DD$
\item for every arrow $f : A \to B$ in $\CC$, an arrow $F(f) : F(A) \to
  F(B)$ in $\DD$
\item the following equations hold:
  \begin{align}
    \label{law:functor-composition}F(f \circ g) &= F(f) \circ F(g) & \text{(Composition)} \\
    \label{law:functor-identity}F(\id_A) &= \id_{F(A)} & \text{(Identity)}
  \end{align}
\end{itemize}
\end{definition}

\begin{definition}
  An \demph{endofunctor} is a functor from some category $\CC$ to the same
  category.
\end{definition}

For every effect signature $E$, we will show that $\FF_E$ is an endofunctor
on the $\banana{\lambda}$ category.
\begin{description}
\item[objects:] for every type $\alpha$, we have a type $\FF_E(\alpha)$
\item[arrows:] for every function $f : \sem{\alpha} \to \sem{\beta}$, \\ we
  have a function
  $\FF_E(f) = \lam{X}{X \hsbind (\lam{x}{\eta(f(x))})} :
  \sem{\FF_E(\alpha)} \to \sem{\FF_E(\beta)}$
\end{description}

We also need to prove that $\FF_E$ satisfies the necesary laws.

Composition~\eqref{law:functor-composition}:

\setcounter{TemporaryCounter}{\value{equation}}
\setcounter{equation}{0}
\NoChapterPrefix
\begin{align}
  \FF_E(f) \circ \FF_E(g)
  &= \lam{X}{\FF_E(f)(\FF_E(g)(X))} \\
  &= \lam{X}{\FF_E(f)((\lam{Z}{Z \hsbind (\lam{x}{\eta(g(x))})})(X))} \\
  &= \lam{X}{\FF_E(f)(X \hsbind (\lam{x}{\eta(g(x))}))} \\
  &= \lam{X}{(\lam{Z}{Z \hsbind (\lam{y}{\eta(f(y))})})(X \hsbind (\lam{x}{\eta(g(x))}))} \\
  &= \lam{X}{(X \hsbind (\lam{x}{\eta(g(x))})) \hsbind (\lam{y}{\eta(f(y))})} \\
  &= \lam{X}{X \hsbind (\lam{z}{(\lam{x}{\eta(g(x))})(z) \hsbind (\lam{y}{\eta(f(y))})})} \\
  &= \lam{X}{X \hsbind (\lam{z}{\eta(g(z)) \hsbind (\lam{y}{\eta(f(y))})})} \\
  &= \lam{X}{X \hsbind (\lam{z}{(\lam{y}{\eta(f(y))})(g(z))})} \\
  &= \lam{X}{X \hsbind (\lam{z}{\eta(f(g(z)))})} \\
  &= \lam{X}{X \hsbind (\lam{z}{\eta((f \circ g)(z))})} \\
  &= \FF_E(f \circ g)
\end{align}
\setcounter{equation}{\value{TemporaryCounter}}
\ChapterPrefix

Throughout most of the proof, we rely only on the definitions of function
composition and the $\FF_E(f)$ function lifter. On Line~6 though, we make
use of the associativity law of $\hsbind$~\eqref{law:associativity}.

Identities~\eqref{law:functor-identity}:

\setcounter{TemporaryCounter}{\value{equation}}
\setcounter{equation}{0}
\NoChapterPrefix
\begin{align}
  \FF_E(\id_\alpha)
  &= \lam{X}{X \hsbind (\lam{x}{\eta(\id_\alpha(x))})} \\
  &= \lam{X}{X \hsbind (\lam{x}{\eta(x)})} \\
  &= \lam{X}{X} \\
  &= \id_{\FF_E(\alpha)}
\end{align}
\setcounter{equation}{\value{TemporaryCounter}}
\ChapterPrefix

Here, we make use of the right identity law of
$\hsbind$~\eqref{law:right-identity} on Line~3.

And so we have a functor $\FF_E$. Its laws let us think of computations of
type $\FF_E(\alpha)$ as containing values of type $\alpha$ over which we
can map functions the same way one would map a function over a list,
satisfying the same basic laws.

We also note that $\banana{\lambda}$ already has syntax for this kind of
mapping: $\FF_E(f)(X) = \sem{x \apr y}([x \mapsto f, y \mapsto X])$ where
$\apr$ is the operator introduced in~\ref{ssec:composing-functions}.


\subsection{Applicative Functor}
\label{ssec:applicative-functor}

The two remaining structures, applicative functors and monads, both have
two popular and slightly different presentations. One is in terms of
natural transformations and is very common in category theory whereas the
other is given in terms of combinators and is preferred in functional
programming. Since we will not be using category theory in the rest of this
thesis and we will work with lots of combinators, we will focus on the
presentation favored in functional programming.

\begin{definition}
  An \emph{applicative functor}~\cite{mcbride2008applicative} is a functor
  $F$ alongside with two combinators, $\pure : \alpha \to F(\alpha)$ and
  $\circledast : F(\alpha \to \beta) \to F(\alpha) \to
  F(\beta)$\footnote{$\circledast$ is an infix operator that associates to
    the left, same as application (which it is based on).}  polymorphic in
  $\alpha$ and $\beta$\footnote{This means that the combinators should not
    have different definitions for different instances of the type
    variables $\alpha$ and $\beta$.}. Furthermore, the following laws must
  hold\footnote{$(\circ)$ is the function composition combinator.}:

  \begin{align}
    \label{law:app-identity}\pure(\id) \circledast u &= u & \text{(Identity)} \\
    \label{law:app-composition}\pure(\circ) \circledast u \circledast v \circledast w &= u \circledast (v \circledast w) & \text{(Composition)} \\
    \label{law:app-homomorphism}\pure(f) \circledast \pure(x) &= \pure(f(x)) & \text{(Homomorphism)} \\
    \label{law:app-interchange}u \circledast \pure(x) &= \pure(\lam{f}{f(x)}) \circledast u & \text{(Interchange)}
  \end{align}
\end{definition}

The idea is that the functor $F$ adds some notion of a computational
effect. $F(\alpha)$ is then a type of computations having that effect and
producing a value of type $\alpha$. The $\pure$ combinator injects a value
into the domain of computations without doing anything on the effect
level. The $(\circledast)$ operator is then meant as a sequencing of two
computations: one yielding a function and the other yielding its argument.

The identity law makes sure that $\pure$ is indeed pure and does not add
any meaningful effect: the effect of $\pure$ must in no way tamper with the
effect of $u$. The composition law tells us that the $\circledast$ operator
must be associative: at the level of effects, there is some monoidal
structure, where order matters, but parentheses do not. The homomorphism
law makes sure that $\circledast$ does actually perform
application. Finally, the interchange law guarantees that $\circledast$ is
not one-sided: the effect of $u$ is respected, no matter if it occurs to
the left or to the right of the $\circledast$.

To show that $\FF_E$ is an applicative functor, we will need to define
$\pure$ and $(\circledast)$ and prove the four applicative functor laws.

\begin{align*}
  \pure(x) &= \eta(x) \\
  F \circledast X &= F \hsbind (\lam{f}{X \hsbind (\lam{x}{\eta(f(x))})})
\end{align*}

Now, we prove the laws.

Identity~\eqref{law:app-identity}:

\setcounter{TemporaryCounter}{\value{equation}}
\setcounter{equation}{0}
\NoChapterPrefix
\begin{align}
  \pure(\id) \circledast u
  &= \eta(\id) \circledast u \\
  &= \eta(\id) \hsbind (\lam{f}{u \hsbind (\lam{x}{\eta(f(x))})}) \\
  &= (\lam{f}{u \hsbind (\lam{x}{\eta(f(x))})})(\id) \\
  &= u \hsbind (\lam{x}{\eta(\id(x))}) \\
  &= u \hsbind (\lam{x}{\eta(x)}) \\
  &= u
\end{align}
\setcounter{equation}{\value{TemporaryCounter}}
\ChapterPrefix

We make use of the left and right identities of $\hsbind$ on Lines~3 and 6,
respectively.

Composition~\eqref{law:app-composition}:

\setcounter{TemporaryCounter}{\value{equation}}
\setcounter{equation}{0}
\NoChapterPrefix
\begin{align}
  \pure(\circ) \circledast u \circledast v \circledast w
  &= \pure(\lam{f g x}{f(g(x))}) \circledast u \circledast v \circledast w \\
  &= \eta(\lam{f g x}{f(g(x))}) \circledast u \circledast v \circledast w \\
  &= (\eta(\lam{f g x}{f(g(x))}) \hsbind (\lam{f}{u \hsbind (\lam{x}{\eta(f(x))})})) \circledast v \circledast w \\
  &= ((\lam{f}{u \hsbind (\lam{u'}{\eta(f(u'))})})(\lam{f g x}{f(g(x))})) \circledast v \circledast w \\
  &= (u \hsbind (\lam{u'}{\eta((\lam{f g x}{f(g(x))})(u'))})) \circledast v \circledast w \\
  &= (u \hsbind (\lam{u'}{\eta(\lam{g x}{u'(g(x))})})) \circledast v \circledast w \\
  &= ((u \hsbind (\lam{u'}{\eta(\lam{g x}{u'(g(x))})})) \hsbind (\lam{f}{v \hsbind (\lam{v'}{\eta(f(v'))})})) \circledast w \\
  &= (u \hsbind (\lam{u'}{\eta(\lam{g x}{u'(g(x))}) \hsbind (\lam{f}{v \hsbind (\lam{v'}{\eta(f(v'))})})})) \circledast w \\
  &= (u \hsbind (\lam{u'}{(\lam{f}{v \hsbind (\lam{v'}{\eta(f(v'))})})(\lam{g x}{u'(g(x))})})) \circledast w \\
  &= (u \hsbind (\lam{u'}{v \hsbind (\lam{v'}{\eta((\lam{g x}{u'(g(x))})(v'))})})) \circledast w \\
  &= (u \hsbind (\lam{u'}{v \hsbind (\lam{v'}{\eta(\lam{x}{u'(v'(x))})})})) \circledast w \\
  &= (u \hsbind (\lam{u'}{v \hsbind (\lam{v'}{\eta(\lam{x}{u'(v'(x))})})})) \hsbind (\lam{f}{w \hsbind (\lam{w'}{\eta(f(w'))})}) \\
  &= u \hsbind (\lam{u'}{v \hsbind (\lam{v'}{\eta(\lam{x}{u'(v'(x))})}) \hsbind (\lam{f}{w \hsbind (\lam{w'}{\eta(f(w'))})})}) \\
  &= u \hsbind (\lam{u'}{v \hsbind (\lam{v'}{\eta(\lam{x}{u'(v'(x))}) \hsbind (\lam{f}{w \hsbind (\lam{w'}{\eta(f(w'))})})})}) \\
  &= u \hsbind (\lam{u'}{v \hsbind (\lam{v'}{(\lam{f}{w \hsbind (\lam{w'}{\eta(f(w'))})})(\lam{x}{u'(v'(x))})})}) \\
  &= u \hsbind (\lam{u'}{v \hsbind (\lam{v'}{w \hsbind (\lam{w'}{\eta((\lam{x}{u'(v'(x))})(w'))})})}) \\
  &= u \hsbind (\lam{u'}{v \hsbind (\lam{v'}{w \hsbind (\lam{w'}{\eta(u'(v'(w')))})})}) \\
  &= u \hsbind (\lam{u'}{v \hsbind (\lam{v'}{w \hsbind (\lam{w'}{(\lam{x}{\eta(u'(x))})(v'(w'))})})}) \\
  &= u \hsbind (\lam{u'}{v \hsbind (\lam{v'}{w \hsbind (\lam{w'}{\eta(v'(w')) \hsbind (\lam{x}{\eta(u'(x))})})})}) \\
  &= u \hsbind (\lam{u'}{v \hsbind (\lam{v'}{(w \hsbind (\lam{w'}{\eta(v'(w'))})) \hsbind (\lam{x}{\eta(u'(x))})})}) \\
  &= u \hsbind (\lam{u'}{(v \hsbind (\lam{v'}{w \hsbind (\lam{w'}{\eta(v'(w'))})})) \hsbind (\lam{x}{\eta(u'(x))})}) \\
  &= u \hsbind (\lam{u'}{(v \circledast w) \hsbind (\lam{x}{\eta(u'(x))})}) \\
  &= u \circledast (v \circledast w)
\end{align}
\setcounter{equation}{\value{TemporaryCounter}}
\ChapterPrefix

This law relies heavily on the associativity of
$\hsbind$~\eqref{law:associativity}. At the beginning, the expression is
associated to the left:
$((\pure(\circ) \circledast u) \circledast v) \circledast w$. And at the
end, it associated to the right: $u \circledast (v \circledast w)$. In the
first part of the proof, we use left identity (Lines~4, 9 and 15) and
associativity (Lines~8 and 13). We reach a normal form on Line~17 and start
expanding the term again. We expand using left identity on Line~19 and then
we reassociate using associativity on Lines~20 and 21. The rest of the
equalities is due to the definitions of $\pure$ and $\circledast$ and
$\beta$ reduction.

Homomorphism~\eqref{law:app-homomorphism}:

\setcounter{TemporaryCounter}{\value{equation}}
\setcounter{equation}{0}
\NoChapterPrefix
\begin{align}
\pure(f) \circledast \pure(x)
&= \eta(f) \circledast \eta(x) \\
&= \eta(f) \hsbind (\lam{f'}{\eta(x) \hsbind (\lam{x'}{\eta(f'(x'))})}) \\
&= (\lam{f'}{\eta(x) \hsbind (\lam{x'}{\eta(f'(x'))})})(f) \\
&= \eta(x) \hsbind (\lam{x'}{\eta(f(x'))}) \\
&= (\lam{x'}{\eta(f(x'))})(x) \\
&= \eta(f(x)) \\
&= \pure(f(x))
\end{align}
\setcounter{equation}{\value{TemporaryCounter}}
\ChapterPrefix

This proof is very direct. We just have to normalize the term using the
left identity of $\hsbind$~\eqref{law:left-identity}.

Interchange~\eqref{law:app-interchange}:

\setcounter{TemporaryCounter}{\value{equation}}
\setcounter{equation}{0}
\NoChapterPrefix
\begin{align}
\pure(\lam{f}{f(x)}) \circledast u
&= \eta(\lam{f}{f(x)}) \circledast u \\
&= \eta(\lam{f}{f(x)}) \hsbind (\lam{f'}{u \hsbind (\lam{u'}{\eta(f'(u'))})}) \\
&= (\lam{f'}{u \hsbind (\lam{u'}{\eta(f'(u'))})})(\lam{f}{f(x)}) \\
&= u \hsbind (\lam{u'}{\eta((\lam{f}{f(x)})(u'))}) \\
&= u \hsbind (\lam{u'}{\eta(u'(x))}) \\
&= u \hsbind (\lam{u'}{(\lam{x'}{\eta(u'(x'))})(x)}) \\
&= u \hsbind (\lam{u'}{\eta(x) \hsbind (\lam{x'}{\eta(u'(x'))})}) \\
&= u \circledast \eta(x) \\
&= u \circledast \pure(x)
\end{align}
\setcounter{equation}{\value{TemporaryCounter}}
\ChapterPrefix

We start with the law's right-hand side and normalize it on Line~5. Then we
do some expansions (left identity on Line~7) to get the desired form.

And there we are, we now have an applicative functor. Applicative functors
are very similar to monads, which we will cover in the next part. The
trade-off between the two is in terms of expressivity vs
composability. When we have two applicative functors, we can compose them
and recover $\pure$ and $\circledast$ such that they both satisfy the
necessary laws. However, the same is as not easy with monads and one has to
go a level higher and compose monad transformers. On the other hand, when
chaining two computations within a monad, we can use an operator which lets
the effects of the second computation depend on the result of the first,
whereas when chaining two computations within an applicative functor, the
effects of both computations must be independent.

Oleg Kiselyov explores the use of applicative functors for natural language
semantics in his recent Applicative Abstract Categorial
Grammars~\cite{kiselyov2015applicative,kiselyov2015swing}. The
composability of applicative functors facilitates the combination, which is
the objective of our method as well. However, partly in order to compensate
for the limited expressivity of applicative functors, several
interpretation passes are required until the logical form of a sentence is
constructed.

The two combinators that make up an applicative functor are accessible in
$\banana{\lambda}$. $\pure$ is of course the function $\eta$ and $\circledast$ is
the combinator $\aplr$ introduced in~\ref{ssec:composing-functions}.


\subsection{Monad}
\label{ssec:monad}

\begin{definition}
  A \demph{monad} is a functor $F$ and two combinators,
  $\eta : \alpha \to F(\alpha)$ and
  $\hsbind : F(\alpha) \to (\alpha \to F(\beta)) \to F(\beta)$, polymorphic
  in $\alpha$ and $\beta$. These objects must also satisfy the following
  laws:

  \begin{align}
    (X \hsbind f) \hsbind g &= X \hsbind (\lam{x}{f(x) \hsbind g}) & \text{(Associativity)} \\
    \eta(x) \hsbind f &= f(x) & \text{(Left identity)} \\
    X \hsbind \eta &= X & \text{(Right identity)}
  \end{align}
\end{definition}

To understand why the laws look the way they do, we will consider functions
of type $\alpha \to F(\beta)$. These are the kinds of functions one might
use to model call-by-value~\cite{moggi1991notions,moggi1990abstract}: we
take a value $\alpha$ and then yield some computation $F(\beta)$. Now
assume we would use this type of functions to model procedures of input
type $\alpha$ and output type $\beta$ and we would want these procedures to
form a category. For every type $\alpha$, we would an identity procedure
with input type and output type $\alpha$, therefore a function of type
$\alpha \to F(\alpha)$. The polymorphic $\eta$ combinator will be this
identity procedure. We would also like to be able to compose a procedure
from $\alpha$ to $\beta$ with a procedure from $\beta$ to $\gamma$, i.e.\
compose functions of types $\alpha \to F(\beta)$ and $\beta \to
F(\gamma)$. When composing $f : \alpha \to F(\beta)$ with
$g : \beta \to F(\gamma)$, we run into the problem of having some
$f(x) : F(\beta)$ and $g : \beta \to F(\gamma)$ that we cannot
compose. This is where $\hsbind$ comes in and composes these two values for
us. Let $f \kleisli g = \lam{x}{f(x) \hsbind g}$ be the resulting
composition operator. In order for this structure to be a category, it
needs to satisfy the following:

\begin{align*}
  (f \kleisli g) \kleisli h &= f \kleisli (g \kleisli h) \\
  \eta \kleisli f &= f \\
  f \kleisli \eta &= f
\end{align*}

By taking $f$ to be the constant function that returns $X$, we end up with
the laws of the monad. Conversely, with the principle of extensionality, we
can derive these laws from the monad laws. Therefore
$\left<F, \eta, \hsbind\right>$ form a monad whenever the derived
$\kleisli$ and $\eta$ form a category. This kind of category is called a
\emph{Kleisli category} and the particular presentation of a monad that we
have given here is known as a \emph{Kleisli triple}.

To prove that $\FF_E$ is a monad will be trivial: we have already done so!
The $\eta$ combinator is of course our $\eta$ and $\hsbind$ is our
$\hsbind$. The three laws that we need to verify are three laws that we
have introduced in~\ref{ssec:three-laws} and have been using throughout
this section.

Monads have been introduced to natural language semantics by Chung-chieh
Shan in 2002~\cite{shan2002monads}. Since then, they have seen occasional
use, mostly to handle dynamics without burdening the semantics with
context/continuation passing~\cite{unger2011dynamic,champollion2015back},
but also other phenomena such as conventional
implicature/opacity\cite{giorgolo2011multidimensional,giorgolo2014monads,giorgolo2012missing}. The
challenge to combining different phenomena which rely on different monads
has been tackled from two angles: using distributive laws for
monads~\cite{giorgolo2015natural} and using monad
transformers~\cite{charlow2014semantics,barker2015monads}.

In $\banana{\lambda}$, the monadic operations $\eta$ and $\hsbind$ are available
as the $\eta$ constructor and the $\hsbind$ combinator introduced
in~\ref{ssec:composing-functions}.

\subsection{Free Monad}
\label{ssec:free-monad}

A free monad is a construction of a monad such that the resulting monad
satisfies the monad laws but does not satisfy anything more than that. This
is similar to the idea of a free monoid generated by some set $A$. If we
have two expressions from a monoid, we know that the operation is
associative and so the grouping does not matter. The only thing that
matters is which elements are multiplied and in which order. We can
therefore thing of the elements of this monoid as lists of values from
$A$. The free monad is a similar construction, but instead of building a
monoid out of a set, it builds a monad out of a functor.

Let $S$ be some functor, we define the monad
$\left<F, \eta, \hsbind\right>$ where:

\begin{itemize}
\item $F(\gamma) = \gamma + S(F(\gamma))$\footnote{The plus is a coproduct,
    which in the case of our category of sets corresponds to disjoint
    union. We will work with coproducts using a similar syntax to the one
    that we have given to sums in~\ref{sec:sums-and-products}.}
\item $\eta(x) = \inl(x)$
\item $X \hsbind f = \casemon{X}{x}{f(x)}{s}{\inr(S(\lam{X'}{X' \hsbind f})(s))}$
\end{itemize}

The functor $S$ correspond to our effect signature. For
$\typedop{op}{\alpha}{\beta}$, we can define a functor
$S_{\op{op}}(\gamma) = \alpha \times \gamma^\beta$. This represents
providing a value of type $\alpha$ and waiting for an answer of type
$\beta$ before continuing with $\gamma$. By taking the free monad of this
functor, we end up with a monad where after each operation, we continue
with a new computation of the same kind until we yield a $\gamma$,
$F(\gamma) = \gamma + \alpha \times F(\gamma)^\beta$.

If we want to offer more operations with different input and output types,
we can take the coproduct of several functors. For an effect signature $E$,
$S_E(\gamma) = \sum_{\op{op} \in E} S_{\op{op}}(\gamma)$.  The resulting
free monad then looks like
$F(\gamma) = \gamma + \sum_{\typedop{op}{\alpha}{\beta} \in E} \alpha
\times F(\gamma)^\beta$. If we replace sums with disjoint unions and types
with their interpretations, you almost get the kind of set in which we
interpret our computations type
in~\ref{ssec:denotational-semantics}. Importantly, the $\eta$ and $\hsbind$
are the same as the ones of the free monad given above. The only difference
between the free monad and the monad used in our interpretation are the
occurrences of $\bot$. The monad that we used is actually a combination of
the $F(X) = X_\bot$ partiality monad and a free monad.

Free monads are another solution to the combination of different effects
within a single calculus, hitherto unexplored in its application to natural
language semantics. A very early appearance of this technique dates back to
1994~\cite{cartwright1994extensible}. It has recently gained prominence
with the work on extensible effects and effect
handlers~\cite{kiselyov2013extensible,bauer2012programming,kammar2013handlers,brady2013programming,plotkin2013handling,pretnar2010logic}.


\section{Confluence}
\label{sec:confluence}

The object of our study during this section will be the proof of the
\emph{confluence property} of $\banana{\lambda}$. Informally, it means that
a single term cannot reduce to two or more different results. Together with
the termination from~\ref{sec:termination}, this will give us the property
that every term yields exactly one result and does so in a finite amount of
steps (a property known as \emph{strong normalization}). Confluence also
gives us a strong tool to prove an inequality on terms. If two terms reduce
to different normal forms, confluence guarantees us that they are not
convertible.

\begin{definition}
  A reduction relution $\to$ on a set $A$ is said to be \demph{confluent}
  whenever for each $a,b,c \in A$ such that $a \to b$ and $a \to c$ there
  is a $d \in A$ such that $b \tto d$ and $c \tto d$.
\end{definition}

Proofs of this property are often mechanical and follow the same
pattern. Our strategy will be to reuse a general result which applies one
such proof for a general class of rewriting systems. Our rewriting system
is a system of reductions on terms and the reductions have side conditions
concerning the binding of free variables. A good fit for this kind of
system are the Combinatory Reduction Systems (CRSs) of
Klop~\cite{klop1993combinatory}.

The main result about CRSs that we will make use of is the following
(Corollary~13.6 in~\cite{klop1993combinatory}).

\begin{theorem}\label{thm:confluence-crs}
  \demph{Confluence of orthogonal CRSs}

  Every orthogonal CRS is confluent.
\end{theorem}

We will model $\calc$ as a CRS. However, $\eta$-reduction will deny us
orthogonality. We will therefore first prove termination of $\calc$ without
$\eta$-reduction and then we will manually show that confluence is
preserved on adding $\eta$-reduction back.

\begin{notation}
  The \demph{intensional $\banana{\lambda}$ calculus $\intcalc$} is the
  $\banana{\lambda}$ calculus without the $\eta$-reduction rule.
\end{notation}

The rest of this section will go like this:

\begin{itemize}
\item CRS: a formalism for higher-order rewriting (\ref{ssec:crs})
\item $\calc$ is a CRS (\ref{ssec:banana-as-crs})
\item Klop et al [93]: Every orthogonal CRS is confluent
  (\ref{ssec:orthogonal-crs})
  \begin{itemize}
  \item $\intcalc$ is an orthogonal CRS $\Rightarrow$ $\intcalc$ is confluent
    (Lemma~\ref{lem:confluence-int})
  \item $\eta$ is an orthogonal CRS $\Rightarrow$ $\eta$ is confluent
    (Lemma~\ref{lem:confluence-eta})
  \end{itemize}
\item $\intcalc + \eta$ is confluent (\ref{ssec:confluence-eta},
  Theorem~\ref{thm:confluence})
  \begin{itemize}
  \item because $\intcalc$ and $\eta$ commute (Lemma~\ref{lem:eta-commutes})
  \end{itemize}
\end{itemize}


\subsection{Combinatory Reduction Systems}
\label{ssec:crs}

A Combinatory Reduction System is defined by an alphabet and a set of
rewriting rules. We will first cover the alphabet.

\begin{definition}
  A \demph{CRS alphabet} consists of:
  \begin{itemize}
  \item a set $\Var$ of \emph{variables} (written lower-case as $x$, $y$,
    $z$,\ldots)
  \item a set $\MVar$ of \emph{metavariables} (written upper-case as $M$,
    $N$, \ldots), each with is own arity
  \item a set of \emph{function symbols}, each with its own arity
  \end{itemize}
\end{definition}

Let us sketch the difference between the variables in $\Var$ and the
metavariables in $\MVar$. The variables in $\Var$ are the variables of the
object-level terms, in our case it will be the variables of
$\banana{\lambda}$. The variables in $\MVar$ are the metavariables that
will occur in our reduction rules and which we will have to instantiate in
order to derive specific application of those rules. In other words, the
variables in $\Var$ are there to express the binding structure within the
terms being reduced and the metavariables in $\MVar$ are there to stand in
for specific terms when applying a reduction rule.

\begin{definition}
  The \demph{metaterms} of a CRS are given inductively:
  \begin{itemize}
  \item variables are metaterms
  \item if $t$ is a metaterm and $x$ a variable, then $[x]t$ is a metaterm
    called \emph{abstraction}
  \item if $F$ is an $n$-ary function symbol and $t_1$,\ldots,$t_n$ are
    metaterms, then $F(t_1,\ldots,t_n)$ is a metaterm
  \item if $M$ is an $n$-ary metavariable and $t_1$,\ldots,$t_n$ are
    metaterms, then $M(t_1,\ldots,t_n)$ is a metaterm
  \end{itemize}
\end{definition}

\begin{definition}
  The \demph{terms} of a CRS are its metaterms which do not contain any
  metavariables.
\end{definition}

To finish the formal introduction of CRSs, we give the definition of a CRS
reduction rule.

\begin{definition}
  A \demph{CRS reduction rule} is a pair of metaterms $s \to t$ such that:
  \begin{itemize}
  \item $s$ and $t$ are both closed, i.e.\ all variables are bound using
    the $[\_]\_$ binder
  \item $s$ is of the form $F(t_1,\ldots,t_n)$
  \item all the metavariables that occur in $t$ also occur in $s$
  \item any metavariable $M$ that occurs in $s$ only occurs in the form
    $M(x_1,\ldots,x_k)$, where $x_i$ are pairwise distinct variables
  \end{itemize}
\end{definition}

\begin{definition}
  A \demph{Combinatory Reduction System (CRS)} is a pair of a CRS alphabet
  and a set of CRS reduction rules.
\end{definition}

We will only sketch the way that a CRS gives rise to a reduction relation
and we will direct curious readers to Sections~11 and 12 of
$\cite{klop1993combinatory}$.

When we instantiate the metavariables in a CRS rule, we use a
\emph{valuation} that assigns to every $n$-ary metavariable a term with
holes labelled from 1 to $n$. The instantiation of $M(t_1,\ldots,t_n)$ then
replaces the metavariable $M$ by the term with holes and fills the holes
labelled $1,\ldots,n$ with the terms $t_1,\ldots,t_n$ respectively.

The crucial detail is that in a particular context, a metavariable can only
be instantiated with terms $M$ that do not contain any free variables bound
in that context. This means that for the instantiation of $M$ to contain a
variable bound in the context, $M$ must explicitly take that variable as an
argument. All other variables not explicitly declared can therefore be
safely assumed to not occur freely within.

Consider the following examples of $\beta$ and $\eta$ reduction.

\begin{align*}
  \ap{(\lam{x}{M(x)})}{N} & \to M(N) \\
  \lam{x}{\ap{N}{x}} & \to N
\end{align*}

More formally written as:

\begin{align*}
  @(\lambda([x]M(x)),N) & \to M(N) \\
  \lambda([x]@(N,x)) & \to N
\end{align*}

where $\lambda$ is a unary function symbol and $@$ is a binary function
symbol. In both of the versions, $M$ is a unary metavariable and $N$ is a
nullary metavariable. In the rule for $\beta$-reduction, we can observe how
the idea of instantiating metavariables by terms with holes lets us express
the same idea for which we had to introduce the meta-level operation of
substitution. In the rule for $\eta$-reduction, we see that $N$ appears in
a context where $x$ is bound but it does not have $x$ as one of its
arguments. Therefore, it will be impossible to instantiate $N$ in such a
way that it contains a free occurrence of $x$. In both of those rules, we
were able to get rid of meta-level operations (substitution) and conditions
($x \notin FV(N)$) and have them both implemented by the formalism itself.


\subsection{$\banana{\lambda}$ as a CRS}
\label{ssec:banana-as-crs}

We will now see how to rephrase the reduction rules of $\banana{\lambda}$ in
order to fit in to the CRS framework. We have already seen how to translate
the $\beta$ and $\eta$ rules in the previous subsection. The next
rules to address are the rules defining the semantics of the $\banana{}$
handlers.

We will repeat the rules for handlers to make the issue at hand clear.

\begin{tabular}{lr}
  $\ap{\cibanana}{(\ap{\eta}{N})} \to$ & rule $\banana{\eta}$ \\
  $\ap{M_\eta}{N}$ & \\
  \\
  $\ap{\cibanana}{(\ap{\ap{\op{op}_j}{N_{\mathrm{p}}}}{(\lam{x}{N_{\mathrm{c}}})})} \to$ & rule $\banana{\op{op}}$ \\
  $\ap{M_j}{\ap{N_{\mathrm{p}}}{(\lam{x}{\ap{\cibanana}{N_{\mathrm{c}}}})}}$
  & where $j \in I$ \\
  & and $x \notin \FV((M_i)_{i \in I}, M_\eta)$ \\
  \\
  $\ap{\cibanana}{(\ap{\ap{\op{op}_j}{N_{\mathrm{p}}}}{(\lam{x}{N_{\mathrm{c}}})})} \to$ & rule $\banana{\op{op}'}$ \\
  $\ap{\op{op}_j}{\ap{N_{\mathrm{p}}}{(\lam{x}{\ap{\cibanana}{N_{\mathrm{c}}}})}}$
  & where $j \notin I$ \\
  & and $x \notin \FV((M_i)_{i \in I}, M_\eta)$
\end{tabular}

The syntax of CRSs does not allow us to use the $(\onto{\op{op}_i}{M_i})_{i
  \in I}$ notation nor capture the $j \in I$ or $j \notin I$ conditions.
The symbols $\op{op}_i$ are problematic as well, since technically, they
are not pure $\banana{\lambda}$ syntax but metavariables standing in for
operation symbols.

We do away with all of the above problems by expanding these meta-notations
and adding a separate rule for every possible instantiation of the
schema. This means that for each sequence of distinct operation symbols
$\op{op}_1$,\ldots,$\op{op}_n$, we end up with:
\begin{itemize}
\item a special rewriting rule
  $\ap{\banana{\onto{\op{op}_1}{M_1},\ldots,\onto{\op{op}_n}{M_n},\ 
    \onto{\eta}{M_\eta}}}{(\etaE{N})}
  \to \ap{M_\eta}{N}$
\item for every $1 \le i \le n$, a special rewriting rule \\
  $\ap{\banana{\onto{\op{op}_1}{M_1},\ldots,\onto{\op{op}_n}{M_n},\ 
    \onto{\eta}{M_\eta}}}{(\app{\op{op}_i}{N_{\mathrm{p}}}{(\lam{x}{N_{\mathrm{c}}(x)})})}
  \\ \to
  \app{M_i}{N_{\mathrm{p}}}{(\lam{x}{\ap{\banana{\onto{\op{op}_1}{M_1},\ldots,\onto{\op{op}_n}{M_n},\ \onto{\eta}{M_\eta}}}{N_{\mathrm{c}}(x)}})}$
\item for every $\op{op}' \in \EE \setminus \{\op{op}_i \| 1 \le i \le n\}$, a special
  rewriting rule \\
  $\ap{\banana{\onto{\op{op}_1}{M_1},\ldots,\onto{\op{op}_n}{M_n},\ 
    \onto{\eta}{M_\eta}}}{(\app{\op{op}'}{N_{\mathrm{p}}}{(\lam{x}{N_{\mathrm{c}}(x)})})}
  \\ \to
  \app{\op{op}'}{N_{\mathrm{p}}}{(\lam{x}{\ap{\banana{\onto{\op{op}_1}{M_1},\ldots,\onto{\op{op}_n}{M_n},\ \onto{\eta}{M_\eta}}}{N_{\mathrm{c}}(x)}})}$
\end{itemize}

The rule for the cherry $\cherry$ extraction operator is already in CRS
form, so all we have to do is address the rules for the $\CC$ operator. We
present them side-by-side in their original form and in CRS-style.

Original:
\begin{align*}
  \ap{\CC}{(\lam{x}{\ap{\eta}{M}})} & \to \ap{\eta}{(\lam{x}{M})} \\
  \ap{\CC}{(\lam{x}{\ap{\ap{\op{op}}{M_{\mathrm{p}}}}{(\lam{y}{M_{\mathrm{c}}})}})}
  & \to
  \ap{\ap{\op{op}}{M_{\mathrm{p}}}}{(\lam{y}{\ap{\CC}{(\lam{x}{M_{\mathrm{c}}})}})} \\
  & \mathrm{where\ } x \notin \FV(M_{\mathrm{p}})
\end{align*}

CRS-style:
\begin{align*}
  \ap{\CC}{(\lam{x}{\ap{\eta}{(M(x))}})} & \to \ap{\eta}{(\lam{x}{M(x)})} \\
  \ap{\CC}{(\lam{x}{\ap{\ap{\op{op}}{M_{\mathrm{p}}}}{(\lam{y}{M_{\mathrm{c}}(x,y)})}})}
  & \to \ap{\ap{\op{op}}{M_{\mathrm{p}}}}{(\lam{y}{\ap{\CC}{(\lam{x}{M_{\mathrm{c}}(x,y)})}})}
\end{align*}

We can see that the only difference is to replace ``simple'' metavariables
$M$, $M_{\mathrm{p}}$ and $M_{\mathrm{c}}$ with their higher-order
versions: the unary $M$, nullary $M_{\mathrm{p}}$ and binary
$M_{\mathrm{c}}$. We see that every CRS metavariable is applied to the
variables in scope, except for $M_{\mathrm{p}}$, which thus loses access to
the variable $x$. This way, the condition that $x$ must not appear free in
$M_{\mathrm{p}}$ is now encoded directly in the reduction rule itself.

In~\ref{ssec:crs}, we have said that a CRS is formed by a set of reduction
rules and by an alphabet. We have already seen all of the rules of our CRS
($\beta$ and $\eta$ were given at the end of~\ref{ssec:crs} and the
$\cherry$ rule is the same as the original one in~\ref{sec:reductions}). In
order to have a clear definition, all that remains is to identify the
alphabet.

The set of variables $Var$ is exactly the set of variables $\XX$ used in
the definition of $\banana{\lambda}$. The set of metavariables $MVar$
consists of the unary $M$, nullary $N$, nullary $N_{\mathrm{p}}$, unary
$N_{\mathrm{c}}$, nullary $M_{\mathrm{p}}$ and binary $M_{\mathrm{c}}$. The
set of function symbols is composed of the following:

\begin{itemize}
\item the binary symbol $@$ for function application
\item the unary symbol $\lambda$ for function abstraction
\item a nullary symbol for every constant in the signature $\Sigma$
\item the unary symbol $\eta$ for the injection operator
\item a binary symbol $\op{op}$ for every $\op{op} \in \EE$
\item a $(n+2)$-ary symbol
  $(\ap{\banana{\onto{\op{op}_1}{\_},\ \ldots,\ \onto{\op{op}_n}{\_},\ \onto{\eta}{\_}}}{\_})$
  for every sequence $\op{op}_1,\ldots,\op{op}_n$ of distinct symbols from
  $\EE$ of length $n$
\item the unary symbol $\cherry$ for the extraction operator
\item the unary symbol $\CC$ for the $\CC$ operator
\end{itemize}

In giving the CRS-style reduction rules above, we have used the ``native''
syntax of $\banana{\lambda}$ instead of writing out everything in terms of
function symbols. For clarity, we give the rules governing the relationship
of the two. We write:

\begin{itemize}
\item $@(t,u)$ as $\ap{t}{u}$
\item $\lambda([x]t)$ as $\lam{x}{t}$
\item $\eta(t)$ as $\etaE{t}$
\item $\op{op}(t_{\mathrm{p}},[x]t_{\mathrm{c}})$ as
  $\app{\op{op}}{t_{\mathrm{p}}}{(\lam{x}{t_{\mathrm{c}}})}$\footnote{Note
    that with this translation,
    $\app{\op{op}}{t_{\mathrm{p}}}{(\lam{x}{t_{\mathrm{c}}})}$ does not
    contain $\lam{x}{t_{\mathrm{c}}}$ as a subterm. This is the same as in
    $\banana{\lambda}$, where the notion of evaluation context
    (see~\ref{sec:reductions}) does not identify $\lam{x}{t_{\mathrm{c}}}$,
    but rather $t_{\mathrm{c}}$, as a subterm of
    $\app{\op{op}}{t_{\mathrm{p}}}{(\lam{x}{t_{\mathrm{c}}})}$. This
    becomes important in our discussion of confluence since it makes it
    impossible to make the $\lambda$ disappear by something like
    $\eta$-reduction.}
\item
  $(\ap{\banana{\onto{\op{op}_1}{\_},\ \ldots,\ \onto{\op{op}_n}{\_},\ \onto{\eta}{\_}}}{\_})(t_1,\ldots,t_n,t_\eta,u)$
  as $\ap{\banana{\onto{\op{op}_1}{t_1},\ \ldots,\ \onto{\op{op}_n}{t_n},\ \onto{\eta}{t_\eta}}}{u}$
\item $\cherry(t)$ as $\ap{\cherry}{t}$
\item $\CC(t)$ as $\ap{\CC}{t}$
\end{itemize}

We have connected the terms of $\banana{\lambda}$ with CRS terms and we
have also expressed all of our reduction rules in terms of CRS reduction
rules. As in $\banana{\lambda}$, CRS then proceeds to take a context
closure of this redex-contractum relation. Our translation from
$\banana{\lambda}$ to a CRS also preserves subterms\footnote{More
  precisely, if $a$ is a subterm of $b$ in $\banana{\lambda}$ then the CRS
  version of $a$ is a subterm of the CRS version of $b$. In the other
  direction, whenever $a$ is a variable or a function-headed term which is
  a subterm of $b$ in the CRS version of $\banana{\lambda}$, then the
  corresponding $a$ in $\banana{\lambda}$ is a subterm of the corresponding
  $b$.}  and so we end up constructing the same reduction relation.


\subsection{Orthogonal CRSs}
\label{ssec:orthogonal-crs}

In order to use Theorem~\ref{thm:confluence-crs}, we need to show that our
CRS is orthogonal, so let us start us by looking at what ``orthogonal''
means in the context of CRSs.

\begin{definition}
  A CRS is \demph{orthogonal} if it is non-overlapping and left-linear.
\end{definition}

We will need to satisfy two criteria: no overlaps and left linearity. We
will start with the latter.

\begin{definition}
  A CRS is \demph{left-linear} if the left-hand sides of all its reduction
  rules are linear. A CRS metaterm is \demph{linear} if no metavariable
  occurs twice within it.
\end{definition}

By going through the rules we have given in~\ref{ssec:banana-as-crs}, we
can see at a glance that no rule uses the same metavariable twice in its
left-hand side and so our CRS is indeed left-linear.

\begin{definition}
  A CRS is \demph{non-overlapping} if:
  \begin{itemize}
    \item Let $r = s \to t$ be some reduction rule of the CRS and let
      $M_1$,\ldots,$M_n$ be all the metavariables occurring in the
      left-hand side $s$. Whenever we can instantiate the metavariables in
      $s$ such that the resulting term contains a redex for some other rule
      $r'$, then said redex must be contained in the instantiation of one
      of the metavariables $M_i$.
    \item Similarly, whenever we can instantiate the metavariables in $s$
      such that the resulting term \emph{properly contains} a redex
      \emph{for the same rule $r$}, then that redex as well must be
      contained in the instantiation of one of the metavariables $M_i$.
  \end{itemize}
\end{definition}

In simpler words, no left-hand side of any rule can contain bits which look
like the top of the left-hand side of some other rule. Let us try and
verify this property in $\banana{\lambda}$:
\begin{itemize}
\item The $\banana{}$ rules have no overlaps with any of the other
  rules. Their left-hand sides are constructed only of the $\banana{}$
  symbols and the $\op{op}$ and $\eta$ constructors. Since there is no
  reduction rule headed by $\op{op}$ and $\eta$, they have no overlap with
  any of the other rules. Furthermore, the three $\banana{}$ rules are
  mutually exclusive, so there is no overlap between themselves.
\item The $\cherry$ rule does not overlap with any of the other neither,
  since the left-hand side contains only $\cherry$ and $\eta$, and there is
  no reduction rule headed by $\eta$.
\item The $\CC$ rules are both mutually exclusives, so there is no overlap
  between the two. However, their left-hand sides are built out of not only
  $\CC$, $\op{op}$ and $\eta$, but also $\lambda$, for which there is the
  $\eta$ reduction rule. Fortunately in this case, the $\CC$ rules only
  apply when the $\lambda$-abstraction's body is an $\eta$ expression or an
  $\op{op}$ expression, whereas the $\eta$ rule applies only when the
  body is an application expression\footnote{This is not so much a
    fortunate conincidence but rather a deliberate choice in the design of
    the calculus.}. Therefore, there is no overlap.
\end{itemize}

We have established that all the reduction rules in our system are pairwise
non-overlapping \emph{except} for $\beta$ and $\eta$. However,
these two are notoriously overlapping.

We can instantiate the metavariables in the left-hand side of the
$\beta$ rule to get a term which contains a $\eta$-redex which shares
the $\lambda$-abstraction with the $\beta$-redex.

$$
\ap{(\lam{x}{\ap{y}{x}})}{z}
$$

We can also instantiate the metavariables in the left-hand side of the
$\eta$ rule to create a $\beta$-redex which shares the application with
the $\eta$-redex.

$$
\lam{x}{\ap{(\lam{z}{z})}{x}}
$$

Our CRS is therefore \emph{not} orthogonal. However, we can still make good
use of Theorem~\ref{thm:confluence-crs}.

\begin{lemma}\label{lem:confluence-int}
  \demph{Confluence of $\intcalc$}

  The $\banana{\lambda}$ reduction system without the $\eta$ rule is
  confluent.
\end{lemma}

\begin{proof}
  If we exclude the $\eta$ rule, we have a CRS which is left-linear and
  also non-overlapping\footnote{We know that $\beta$ does not overlap
    any of the other rules. Neither does it overlap itself since its
    left-hand side does not have an application subexpression.}. Therefore,
  it is orthogonal and thanks to Theorem~\ref{thm:confluence-crs}, also
  confluent.
\end{proof}

\begin{lemma}\label{lem:confluence-eta}
  \demph{Confluence of $\eta$-reduction}

  The reduction system on $\banana{\lambda}$ terms containing only the
  $\eta$ reduction rule is confluent\footnote{This also holds for
    $\banana{\lambda}$ with sums and products since their rules are
    left-linear and do not overlap with the $\banana{\lambda}$ rules.}.
\end{lemma}

\begin{proof}
  We have seen that $\eta$ is a valid left-linear CRS rule. It also
  does not overlap itself since its left-hand side does not contain any
  $\lambda$ subexpression. The CRS consisting of just the $\eta$ rule
  is therefore orthogonal and confluent.
\end{proof}


\subsection{Putting $\eta$ Back in $\banana{\lambda}$}
\label{ssec:confluence-eta}

We have shown that both $\banana{\lambda}$ without $\eta$ and
$\eta$ by itself are confluent. The reduction relation of the complete
$\banana{\lambda}$ calculus is the union of these two reduction
relations. Using the Lemma of Hindley-Rosen (Point~2 in Exercises~1.0.8
in~\cite{klop1992term}), we can show that this union is confluent by
showing that the two reduction relations commute together.

We will not even need to know the definition of commuting reductions, since
we will base our proof on an other result due to Hindley (Point~3 in
Exercises~1.0.8 in~\cite{klop1992term}).

\begin{lemma}\label{lem:commutativity}
  Let $\to_1$ and $\to_2$ be two reduction relations on the same set of
  terms $A$. Suppose that whenever there are $a,b,c \in A$ such that
  $a \to_1 b$ and $a \to_2 c$, there is also some $d \in A$ such that
  $b \tto_2 d$ and $c \to_1^= d$ (meaning $c \to_1 d$ or $c = d$). In that
  case, $\to_1$ commutes with $\to_2$.
\end{lemma}

We can use this to prove that $\banana{\lambda}_{-\eta}$ commutes with the
$\eta$ reduction rule.

\begin{lemma}\label{lem:eta-commutes}
  \demph{Commutativity of $\eta$ and $\banana{\lambda}_{-\eta}$}

  The reduction relations induced by $\eta$ and by the rest of the
  $\banana{\lambda}$ rules commute.
\end{lemma}

\begin{proof}
  We will prove this lemma by an appeal to
  Lemma~\ref{lem:commutativity}. Let $\to_\eta$ be the reduction relation
  induced by the rule $\eta$ and $\to_{\intcalc}$ the reduction
  relation induced by all the other reduction rules in
  $\banana{\lambda}$. We need to prove that for all terms $a$, $b$ and $c$
  where $a \to_{\intcalc} b$ and $a \to_\eta c$, we have a term $d$ such that
  $b \tto_\eta d$ and $c \to_{\intcalc}^= d$.

  This will turn out to be a routine proof by induction on the structure of
  the term $a$. The base cases are trivial since terms without any proper
  subterms happen to have no redexes in $\banana{\lambda}$ and therefore
  trivially satisfy the criterion. In the inductive step, we will proceed
  by analyzing the relative positions of the redexes which led to the
  reductions $a \to_{\intcalc} b$ and $a \to_\eta c$.
  \begin{itemize}
  \item If both reductions occurred within a common subterm of $a$, i.e.\
    $a = C[a']$, $b = C[b']$ and $c = C[c']$ while at the same time
    $a' \to_{\intcalc} b'$ and $a' \to_\eta c'$: We can use the induction
    hypothesis for $a'$. This gives us a $d'$ such that $b' \tto_\eta d'$
    and $c' \to_{\intcalc}^= d'$ and therefore we also have $d = C[d']$ with
    $b \tto_\eta d$ and $c \to_{\intcalc}^= d$.
  \item If both reductions occurred within non-overlapping subterms of $a$,
    i.e.\ $a = C[a_1, a_2]$, $b = C[b', a_2]$ and $c = C[a_1, c']$ with
    $a \to_{\intcalc} b$ and $a \to_\eta c$: We can take $d = C[b', c']$ since
    we have $b \tto_\eta d$ in one step and $c \to_{\intcalc}^= d$ in one step
    too.
  \item If the redex in $a \to_{\intcalc} b$ is the entire term $a$, but the
    redex in $a \to_\eta c$ is a proper subterm of $a$: We will solve this
    by case analysis on the form of $a$:
    \begin{itemize}
    \item If $a$ is an application: Since $a$ is an application and also a
      $\intcalc$-redex, it must match the left-hand side of the $\beta$
      rule, $\ap{(\lam{x}{M(x)})}{N}$, and $b$ must be $M(N)$.
      \begin{itemize}
      \item We will first deal with the case when the $\eta$-redex which
        lead to $c$ originated in $M(x)$. In that case
        $M(x) \to_\eta M'(x)$ and $c = \ap{(\lam{x}{M'(x)})}{N}$. Our
        sought-after $d$ is then $M'(N)$, since $c \to_{\intcalc}^= d$ via
        $\beta$ in one step and $b = M(N) \tto_\eta d = M'(N)$.
      \item Now we get to one of the two interesting cases which
        necessitated this whole lemma: the overlap between $\beta$ and
        $\eta$, with $\beta$ on the top. If the $\eta$-redex did not
        originate in $M(x)$, then the $\eta$-redex must be
        $\lam{x}{M(x)}$. Therefore, $M = \ap{T}{x}$ and
        $a = \ap{(\lam{x}{\ap{T}{x}})}{N}$. Performing the $\eta$-reduction
        yields $c = \ap{T}{N}$. In this case, both $b$ and $c$ are equal to
        $\ap{T}{N}$ and so we can choose $\ap{T}{N}$ as our $d$.
      \end{itemize}
    \item If $a$ is any other kind of term: Let $l \to r$ be the rule used
      in $a \to_{\intcalc} b$. Not counting $\beta$, which only acts on
      applications and which we dealt with just above, the rules of
      $\intcalc$ do not overlap with the $\eta$ rule. This means the
      $\eta$-redex which led to $c$ must lie entirely inside a part the
      part of $l$ which corresponds to a metavariable. Let $M$ be that
      metavariable, then we will decompose $l$ into $L(M)$ and $r$ into
      $R(M)$. We have $a = L(a')$ for some $a'$, $b = R(a')$ and
      $c = L(a'')$\footnote{Since our rules are left-linear, $M$ is
        guaranteed to appear in $L(M)$ at most once. Therefore, if
        $a' \to_\eta a''$ in one step, then also $L(a') \to_\eta L(a'')$ in
        one step as well.}. Our $d$ will be $R(a'')$ and we have
      $b = R(a') \tto_\eta d = R(a'')$ in several steps\footnote{$a'$ can
        occur multiple times in $R(a')$ when the rule $l \to r$ is
        duplicating (which is actually the case for the $\banana{\op{op}}$
        rules). However, we are able to go from $R(a')$ to $R(a'')$ in
        multiple steps. NB: This is why we use
        Lemma~\ref{lem:commutativity} instead of trying to prove
        commutativity directly.} and
      $c = L(a'') \to_{\intcalc}^= d = R(a'')$ in one step of $l \to r$.
    \end{itemize}
  \item If the redex in $a \to_\eta c$ is the entire term $a$, but the
    redex in $a \to_{\intcalc} b$ is a proper subterm of $a$: In this case,
    $a$ must be an abstraction that matches the left-hand side of the
    $\eta$ rule, i.e.\ $a = \lam{x}{\ap{N}{x}}$. Also, we have $c = N$.
    \begin{itemize}
    \item As before, we will first deal with the case when the
      $\intcalc$-redex is contained completely within $N$. Then
      $N \to_{\intcalc} N'$ and $b = \lam{x}{\ap{N'}{x}}$. The common
      reduct $d$ is $N'$ since $b \tto_\eta d$ in one step and
      $c = N \to_{\intcalc}^= d = N'$ as established before.
    \item Now this is where we deal with the second overlap between $\beta$
      and $\eta$ in our reduction system, the one with $\eta$ on top. Let
      us assume that the $\intcalc$-redex in $a$ is actually
      $\ap{N}{x}$. Since this is an application, the only admissible
      reduction is with $\beta$. In that case, $N = \lam{y}{T(y)}$ and
      $a = \lam{x}{\ap{(\lam{y}{T(y)})}{x}}$. Performing the
      $\beta$-reduction gives us $b = \lam{x}{T(x)}$ which is however equal
      to $c = N = \lam{y}{T(y)}$. So we can choose $d = b$ and be done.
    \end{itemize}
  \item If $a$ is the redex for both reductions $a \to_{\intcalc} b$ and
    $a \to_\eta c$, then $a$ must match the left-hand side of two reduction
    rules. However, that is impossible in $\intcalc$ and so $a$ must have
    matched the same rule twice and therefore $b = c$. Then, we have a
    trivial $d = b$.
  \end{itemize}
\end{proof}

Equipped with this lemma, we can go on to prove our main result,
Theorem~\ref{thm:confluence}, the confluence of $\banana{\lambda}$.

\begin{theorem}\label{thm:confluence}
  \demph{Confluence of $\banana{\lambda}$}
  
  The reduction relation $\to$, defined by the reduction rules
  in~\ref{sec:reductions}, on the set of $\banana{\lambda}$ terms is
  confluent.
\end{theorem}

\begin{proof}
  From Lemma~\ref{lem:confluence-int}, we know that the
  $\banana{\lambda}_{-\eta}$ system is confluent and from
  Lemma~\ref{lem:confluence-eta}, we know that the $\eta$ reduction rule is
  confluent as well. Lemma~\ref{lem:eta-commutes} tells us that these two
  reduction systems commute and therefore, by the Lemma of Hindley-Rosen,
  their union, which is the $\banana{\lambda}$ reduction system, commutes
  as well.
\end{proof}


\section{Termination}
\label{sec:termination}

\begin{definition}
  A reduction relation is \demph{terminating} if there is no infinite chain
  $M_1 \to M_2 \to \ldots$.
\end{definition}

In this section, we will prove termination with a similar strategy as the
one we employed for confluence. $\banana{\lambda}$ is an extension of the
$\lambda$-calculus with computation types and some operations on
computations. Our computations can be thought of as algebraic expressions,
i.e.\ they have a tree-like inductive structure. The reason that all
computations in $\banana{\lambda}$ terminate is that the operations defined on
computations rely on well-founded recursion. However, it is quite tricky to
go from this intuition to a formal proof of termination. Fortunately, we
can rely on existing results.

Blanqui, Jounnaud and Okada have introduced Inductive Data Type Systems
(IDTSs)~\cite{blanqui2002inductive,blanqui2000termination}. Similar to the
CRSs, IDTSs are a class of rewriting systems for which we can prove certain
interesting general results. In this section, we will start by examining
the definition of an IDTS and fitting $\banana{\lambda}$ into that
definition. The theory of IDTSs comes with a sufficient condition for
termination known as the General Schema. $\banana{\lambda}$ will not
satisfy this condition and so we will first transform it using Hamana's
technique of higher-order semantic labelling~\cite{hamana2007higher}. As
with our proof of confluence, we will first consider the case of
$\banana{\lambda}$ without $\eta$ reduction and then add $\eta$ manually
while preserving termination.

The plan will look like this:

\begin{itemize}
\item IDTS = Typed CRS (\ref{ssec:idts})
\item The $\idts$ IDTS (\ref{ssec:banana-idts})
  \begin{itemize}
  \item if $\idts$ terminates, then $\intcalc$ terminates
    (Lemma~\ref{lem:banana-tau-termination})
  \end{itemize}
\item Blanqui[00]: General Schema $\Rightarrow$ termination
  (\ref{ssec:termination-for-idts})
\item Hamana[07]: IDTS $R$ terminates iff the labelled IDTS $\overline{R}$
  terminates (\ref{ssec:semantic-labelling})
  \begin{itemize}
  \item Theorem~\ref{thm:labidts-termination}: $\labidts$ terminates (via
    Blanqui[00])
  \item Corollary~\ref{cor:idts-termination}: $\idts$ terminates (via Hamana[07])
  \item Corollary~\ref{cor:intcalc-termination}: $\intcalc$ terminates (via
    Lemma~\ref{lem:banana-tau-termination})
  \end{itemize}
\item $\intcalc + \eta$ terminates (\ref{ssec:termination-eta},
  Theorem~\ref{thm:termination})
  \begin{itemize}
  \item because $\intcalc$ and $\eta$ are exchangeable
    (Lemma~\ref{lem:eta-exchange})
  \item and therefore $\calc$ is strongly normalizing
    (Theorem\ref{thm:strong-normalization})
  \end{itemize}
\end{itemize}


\subsection{Inductive Data Type Systems}
\label{ssec:idts}

We will go by the revised definition of Inductive Data Type Systems that
figures in~\cite{blanqui2000termination} and~\cite{hamana2007higher}. This
formulation extends IDTSs to higher-order rewriting and does so using the
CRS formalism that we introduced earlier.

\begin{definition}
  An \demph{Inductive Data Type System (IDTS)} is a pair of an IDTS alphabet
  and a set of IDTS rewrite rules.
\end{definition}

Just like a CRS, an IDTS is an alphabet coupled with some rewrite
rules. Let us first look at the alphabet and the rules for building terms
out of the elements of the alphabet; the rewrite rules will follow.

\begin{definition}
  The set of types $T(\BB)$ contains:
  \begin{itemize}
  \item all the types from $\BB$
  \item a type $\alpha \To \beta$ for every $\alpha$ and $\beta$ in $T(\BB)$
  \end{itemize}
\end{definition}

\begin{definition}
  An \demph{IDTS alphabet} consists of:
  \begin{itemize}
  \item $\BB$, a set of \emph{base types}
  \item $\XX$, a family $(X_\tau)_{\tau \in T(\BB)}$ of sets of \emph{variables}
  \item $\FF$, a family ${(F_{\alpha_1,\ldots,\alpha_n,\beta})}_{\alpha_1,\ldots,\alpha_n,\beta \in T(\BB)}$ of sets of \emph{function symbols}
  \item $\ZZ$, a family ${(Z_{\alpha_1,\ldots,\alpha_n,\beta})}_{\alpha_1,\ldots,\alpha_n,\beta \in T(\BB)}$ of sets of
    \emph{metavariables}
  \end{itemize}
\end{definition}

The distinction between a CRS-alphabet and an IDTS alphabet is that the
IDTS alphabet comes equipped with a set of types. Furthermore, all the
other symbols in the alphabet are indexed by types, so we end up with typed
variables, typed function symbols and typed metavariables.

When we consider IDTS metaterms, we admit only well-typed terms. The below
definition of IDTS metaterms refines the definition of CRS metaterms by
restraining term formation in accordance with the types.

\begin{definition}
  The \demph{typed metaterms} of an IDTS are given inductively:
  \begin{itemize}
  \item variables from $X_\tau$ are metaterms of type $\tau$
  \item if $t$ is a metaterm of type $\beta$ and $x$ a variable from
    $X_\alpha$, then $[x]t$ is a metaterm of type $\alpha \To \beta$ called
    \emph{abstraction}
  \item if $F$ is an function symbol from
    $F_{\alpha_1,\ldots,\alpha_n,\beta}$ and $t_1$,\ldots,$t_n$ are
    metaterms of types $\alpha_1,\ldots,\alpha_n$, respectively, then
    $F(t_1,\ldots,t_n)$ is a metaterm of type $\beta$
  \item if $M$ is a metavariable from $Z_{\alpha_1,\ldots,\alpha_n,\beta}$
    and $t_1$,\ldots,$t_n$ are metaterms of types
    $\alpha_1,\ldots,\alpha_n$, respectively, then $M(t_1,\ldots,t_n)$ is a
    metaterm of type $\beta$
  \end{itemize}
\end{definition}

\begin{definition}
  The \demph{terms} of an IDTS are its metaterms which do not contain any
  metavariables.
\end{definition}

The definition of an IDTS rewrite rule is almost identical to the one for
CRS reduction rules. The only difference is the extra condition stating
that the redex and contractum must have identical types.

\begin{definition}
  An \demph{IDTS rewrite rule} is a pair of metaterms $s \to t$ such that:
  \begin{itemize}
  \item $s$ and $t$ are both closed, i.e.\ all variables are bound using
    the $[\_]\_$ binder
  \item $s$ is of the form $F(t_1,\ldots,t_n)$
  \item all the metavariables that occur in $t$ also occur in $s$
  \item any metavariable $M$ that occurs in $s$ only occurs in the form
    $M(x_1,\ldots,x_k)$, where $x_i$ are pairwise distinct variables
  \item $s$ and $t$ are both of the same type
  \end{itemize}
\end{definition}

As stated above, an IDTS is just an alphabet along with a set of rewrite
rules. An IDTS induces a rewriting relation in exactly the same way as a
CRS does, see~\cite{blanqui2000termination} for more details.


\subsection{$\banana{\lambda}$ as an IDTS}
\label{ssec:banana-idts}

Now we will try to link $\banana{\lambda}$ to the IDTS framework in order
to benefit from its general termination results. The biggest obstacle will
be that IDTS assigns a fixed type to every symbol. In $\banana{\lambda}$,
symbols are polymorphic: the $\eta$ constructor can produce expressions
like $\etaE{\star} : \FF_E(1)$ or
$\etaE{(\lam{x}{x})} : \FF_E(\alpha \to \alpha)$ and that for any choice of
$E$. We would therefore like to replace function symbols such as $\eta$
with specialized symbols $\eta_{\FF_E(\alpha)}$. For a given type $\alpha$
and effect signature $E$, the symbol $\eta_{\FF_E(\alpha)}$ would have the
type $\alpha \to \FF_E(\alpha)$, i.e.\ it would belong to
$F_{\alpha,\FF_E(\alpha)}$.

We will call this calculus with specialized symbols
$\banana{\lambda}_\tau$. There will not be a bijection between
$\banana{\lambda}$ and $\banana{\lambda}_\tau$ since a single term in
$\banana{\lambda}$ will generally correspond to a multitude of specialized
versions in $\banana{\lambda}_\tau$ (think of $\lam{x}{x}$ in
$\banana{\lambda}$ versus $\lam{x_\iota}{x_\iota}$, $\lam{x_o}{x_o}$\ldots
in $\banana{\lambda}_\tau$). Therefore, the results we prove for
$\banana{\lambda}_\tau$ will not automatically transfer to
$\banana{\lambda}$. In the rest of this subsection, we will elaborate the
definition of $\banana{\lambda}_\tau$ and show why termination carries over
from $\banana{\lambda}_\tau$ to $\banana{\lambda}_{-\eta}$\footnote{In the
  sequel, we will ignore the $\eta$ reduction and use IDTSs to prove the
  termination of $\banana{\lambda}$ without $\eta$ reduction,
  $\banana{\lambda}_{-\eta}$.}.


\subsubsection{Defining $\banana{\lambda}_\tau$}
\label{sssec:banana-tau}

$\banana{\lambda}_\tau$ will be defined as an IDTS. This means we need to
first identify the alphabet. The base types $\BB$ of
$\banana{\lambda}_\tau$ will be the set of types of $\banana{\lambda}$
(i.e.\ all types except for function types)\footnote{Note that throughout
  this section, we will make a distinction between \emph{base} types and
  \emph{atomic} types. Base types are a notion from IDTS and in our
  scenario they correspond to the set of types of
  $\banana{\lambda}$. Atomic types is a notion from $\banana{\lambda}$,
  where it essentially means a ``basic type'' like truth values,
  individuals, natural numbers\ldots.}. Note that both $\banana{\lambda}$
and IDTS have a notion of function type, but the notation is
different. Contrary to common practice, in our exposition of IDTS we use
$\alpha \To \beta$ for the IDTS function type. This allows us to keep using
the $\alpha \to \beta$ notation for $\banana{\lambda}$ types, as we do in
the rest of the thesis.

Next, we will introduce function symbols for all the syntactic
constructions of $\banana{\lambda}$, except for abstraction, which is
handled by the $[\_]\_$ binder construct already found in IDTSs:

\begin{itemize}
\item $\aps_{\alpha, \beta} \in F_{\alpha \to \beta, \alpha, \beta}$
  (i.e.\ for every pair of types $\alpha$ and $\beta$, there will be a
  function symbol $\aps_{\alpha,\beta}$ of type $(\alpha \to \beta) \To
  \alpha \To \beta$ in our alphabet)
\item $\lambda_{\alpha, \beta} \in F_{\alpha \To \beta, \alpha \to \beta}$
\item $c \in F_{\alpha}$ for any constant $c : \alpha \in \Sigma$
\item $\eta_{\alpha, E} \in F_{\alpha, \FF_E(\alpha)}$
\item $\op{op}_{\gamma, E} \in F_{\alpha, \beta \To \FF_E(\gamma),
  \FF_E(\gamma)}$ for any operation symbol $\op{op}$ from $\EE$ and any $E$
  such that $\typedop{op}{\alpha}{\beta} \in E$
\item $\cherry_\alpha \in F_{\FF_\emptyset(\alpha), \alpha}$
\item $\banana{}_{\op{op}_1, \ldots, \op{op}_n, \gamma, \delta, E, E'} \in F_{\alpha_1 \to (\beta_1 \to \FF_{E'}(\delta)), \ldots,
  \alpha_n \to (\beta_n \to \FF_{E'}(\delta)), \gamma \to \FF_{E'}(\delta),
  \FF_E(\gamma), \FF_{E'}(\delta)}$ where:
  \begin{itemize}
  \item $\op{op}_1 : \alpha_1 \rightarrowtail \beta_1 \in E$, \ldots,
    $\op{op}_n : \alpha_n \rightarrowtail \beta_n \in E$
  \item $E \setminus \{\op{op}_1, \ldots, \op{op}_n\} \subseteq E'$
  \end{itemize}
\item $\CC_{\alpha,\beta,E} \in F_{\alpha \to \FF_E(\beta),\FF_E(\alpha \to
  \beta)}$
\end{itemize}

The list above is based on the typing rules of $\banana{\lambda}$ found on
Figure~\ref{fig:types}. We convert the typing rules of $\banana{\lambda}$
into the typed function symbols of $\banana{\lambda}_\tau$ with the
following process:

\begin{itemize}
\item We take a typing rule of $\banana{\lambda}$, other than [var] (since
  variables are already present in the language of IDTS terms).
\item We identify all the type-level metavariables. That is, metavariables
  $\alpha$, $\beta$, $\gamma$ \ldots ranging over types, metavariables $E$,
  $E'$ \ldots ranging over effect signatures and metavariables $\op{op}$
  ranging over operation symbols.
\item We strip these metavariables down to a minimal non-redundant set
  (e.g.\ in the $[\op{op}]$ rule, we have that
  $\typedop{op}{\alpha}{\beta} \in E$, therefore $E$ and $\op{op}$
  determine $\alpha$ and $\beta$ and therefore $\alpha$ and $\beta$
  redundant)
\item We introduce a family of symbols: for every possible instantiation of
  the metavariables mentioned above, we will have a different symbol. The
  arity of the symbol will correspond to the number of typing judgments
  that serve as hypotheses to the typing rule. The types of the arguments
  and of the result will be derived from the types of the judgments of the
  hypotheses and the conclusion, respectively. If a variable of type
  $\alpha$ is bound in a premise of type
  $\beta$, then that will correspond to the IDTS function type $\alpha \To
  \beta$.
  \begin{itemize}
  \item Example: In the $[\eta]$ rule, we have two metavariables: $\alpha$
    standing in for a type and $E$ standing in for an effect signature. The
    rule has one typing judgment hypothesis. For every type $\alpha$ and
    every effect signature $E$, we will therefore have a unary symbol
    $\eta_{\alpha, E}$ of type $\alpha \to \FF_E(\alpha)$ (i.e.\ belonging
    to $F_{\alpha, \FF_E(\alpha)}$).
  \end{itemize}
\end{itemize}

A specifically-typed symbol in
$\banana{\lambda}_\tau$ then corresponds to an instantiation of the type
metavariables in a
$\banana{\lambda}$ typing rule. We can follow this correspondence further
and see that
$\banana{\lambda}_\tau$ IDTS terms, written using the above function
symbols, correspond to typing derivations in $\banana{\lambda}$.

Our alphabet now has types and function symbols. We also need to specify
the sets of variables and metavariables and so we will take some arbitrary
sets with $x_\tau$, $y_\tau$, \ldots $\in X_\tau$ and
$M_{\alpha_1,\ldots,\alpha_n,\beta}$, $N_{\alpha_1,\ldots,\alpha_n,\beta}$,
\ldots $\in Z_{\alpha_1,\ldots,\alpha_n,\beta}$.

\begin{sidewaysfigure}
  \centering
  \begin{tabular}{lr}
  $\aps(\lambda([x]M(x)), N) \to$ & rules $\beta_{\alpha,\gamma}$ \\
  $M (N)$ & \\
  \multicolumn{2}{l}{$\aps_{\typehint{\alpha \to \gamma, \alpha, \gamma}}(\lambda_{\typehint{\alpha \To \gamma, \alpha \to \gamma}}([x_{\typehint\alpha}]M_{\typehint{\alpha, \gamma}}(x_{\typehint\alpha})), N_{\typehint\alpha}) \to$} \\
  \multicolumn{2}{l}{$M_{\typehint{\alpha, \gamma}}(N_{\typehint\alpha})$} \\
  \\
  let $\banana{}^{(\op{op}_i)_{i \in
    I}}_{\typehint{\FF_E(\gamma),\FF_{E'}(\delta)}}(N_{\typehint{\FF_E(\gamma)}})$ & \\
  \multicolumn{2}{l}{$ = \banana{}^{(\op{op}_i)_{i \in I}}_{\typehint{(\alpha_i \to (\beta_i \to \FF_{E'}(\delta)) \to
  \FF_{E'}(\delta))_{i \in I}, \gamma \to \FF_{E'}(\delta), \FF_E(\gamma),
  \FF_{E'}(\delta)}} ((M^i_{\typehint{\alpha_i \to (\beta_i \to
    \FF_{E'}(\delta)) \to \FF_{E'}(\delta)}})_{i \in I},
    M^\eta_{\typehint{\gamma \to \FF_{E'}(\delta)}}, N_{\typehint{\FF_E(\gamma)}})$} \\
  \\
  $\banana{}^{(\op{op}_i)_{i \in I}} (\eta (N)) \to$ & rules $\banana{\eta}^{(\op{op}_i)_{i \in I}}_{\FF_E(\gamma),\FF_{E'}(\delta)}$ \\
  $\aps(M^\eta, N)$ & \\
  \multicolumn{2}{l}{$\banana{}^{(\op{op}_i)_{i \in I}}_{\typehint{\FF_E(\gamma), \FF_{E'}(\delta)}} (\eta_{\typehint{\gamma, \FF_E(\gamma)}} (N_{\typehint{\gamma}})) \to$} \\
  \multicolumn{2}{l}{$\aps_{\typehint{\gamma \to \FF_{E'}(\delta), \gamma,
  \FF_{E'}(\delta)}} (M^\eta_{\typehint{\gamma \to \FF_{E'}(\delta)}}, N_{\typehint{\gamma}})$} \\
  \\
  $\banana{}^{(\op{op}_i)_{i \in I}} (\op{op}_j (N^{\mathrm{p}}, [y] N^{\mathrm{c}}(y))) \to$ & rules $\banana{\op{op}}^{(\op{op}_i)_{i \in I}}_{\FF_E(\gamma),\FF_{E'}(\delta)}$ \\
  $\aps(\aps(M^j, N^{\mathrm{p}}), \lambda([y] \banana{}^{(\op{op}_i)_{i \in I}} (N^{\mathrm{c}}(y))))$ & where $j \in I$ \\
  \multicolumn{2}{l}{$\banana{}^{(\op{op}_i)_{i \in I}}_{\typehint{\FF_E(\gamma), \FF_{E'}(\delta)}} (\op{op}_{j \typehint{\alpha, \beta \To \FF_E(\gamma), \FF_E(\gamma)}} (N^{\mathrm{p}}_{\typehint{\alpha}}, [y_{\typehint{\beta}}] N^{\mathrm{c}}_{\typehint{\beta, \FF_E(\gamma)}}(y_{\typehint{\beta}}))) \to$} \\
  \multicolumn{2}{l}{$\aps_{\typehint{(\beta \to  \FF_{E'}(\delta)) \to \FF_{E'}(\delta), \beta \to \FF_{E'}(\delta), \FF_{E'}(\delta)}} (\aps_{\typehint{\alpha \to (\beta \to
    \FF_{E'}(\delta)) \to \FF_{E'}(\delta), \alpha, (\beta \to
    \FF_{E'}(\delta)) \to \FF_{E'}(\delta)}} (M^j_{\typehint{\alpha \to (\beta \to
    \FF_{E'}(\delta)) \to \FF_{E'}(\delta)}},
    N^{\mathrm{p}}_{\typehint{\alpha}}), \lambda_{\typehint{\beta \To
    \FF_{E'}(\delta), \beta \to \FF_{E'}(\delta)}}([y_{\typehint{\beta}}] \banana{}^{(\op{op}_i)_{i \in I}}_{\typehint{\FF_E(\gamma), \FF_{E'}(\delta)}} (N^{\mathrm{c}}_{\typehint{\beta, \FF_E(\gamma)}}(y_{\typehint{\beta}}))))$} \\
  \\
  $\banana{}^{(\op{op}_i)_{i \in I}} (\op{op}_j (N^{\mathrm{p}}, [y] N^{\mathrm{c}}(y))) \to$ & rules $\banana{\op{op}'}^{(\op{op}_i)_{i \in I}}_{\FF_E(\gamma),\FF_{E'}(\delta)}$ \\
  $\op{op}_j (N^{\mathrm{p}}, [y] \banana{}^{(\op{op}_i)_{i \in I}} (N^{\mathrm{c}}(y)))$ & where $j \notin I$ \\
  \multicolumn{2}{l}{$\banana{}^{(\op{op}_i)_{i \in I}}_{\typehint{\FF_E(\gamma), \FF_{E'}(\delta)}} (\op{op}_{j \typehint{\alpha, \beta \To \FF_E(\gamma), \FF_E(\gamma)}} (N^{\mathrm{p}}_{\typehint{\alpha}}, [y_{\typehint{\beta}}] N^{\mathrm{c}}_{\typehint{\beta, \FF_E(\gamma)}}(y_{\typehint{\beta}}))) \to$} \\
  \multicolumn{2}{l}{$\op{op}_{j \typehint{\alpha, \beta \To \FF_{E'}(\delta), \FF_{E'}(\delta)}} (N^{\mathrm{p}}_{\typehint{\alpha}}, [y_{\typehint{\beta}}] \banana{}^{(\op{op}_i)_{i \in I}}_{\typehint{\FF_E(\gamma), \FF_{E'}(\delta)}} (N^{\mathrm{c}}_{\typehint{\beta, \FF_E(\gamma)}}(y_{\typehint{\beta}})))$} \\
  \\
  $\cherry (\eta (N)) \to$ & rules $\cherry_\alpha$ \\
  $N$ & \\
  \multicolumn{2}{l}{$\cherry_{\typehint{\FF_\emptyset(\alpha), \alpha}} (\eta_{\typehint{\alpha, \FF_\emptyset(\alpha)}} (N_{\typehint\alpha})) \to$} \\
  \multicolumn{2}{l}{$N_{\typehint\alpha}$} \\
  \\
  $\CC (\lambda([x]\eta (M(x)))) \to$ & rules $\CC^\eta_{\alpha, \beta, E}$ \\
  $\eta (\lambda([x] M(x)))$ & \\
  \multicolumn{2}{l}{$\CC_{\typehint{\alpha \to \FF_E(\beta), \FF_E(\alpha \to \beta)}} (\lambda_{\typehint{\alpha \To \FF_E(\beta), \alpha \to \FF_E(\beta)}}([x_{\typehint\alpha}]\eta_{\typehint{\beta, \FF_E(\beta)}} (M_{\typehint{\alpha, \beta}}(x_{\typehint\alpha})))) \to$} \\
  \multicolumn{2}{l}{$\eta_{\typehint{(\alpha \to \beta), \FF_E(\alpha \to
    \beta)}} (\lambda_{\typehint{\alpha \To \beta, \alpha \to \beta}}([x_{\typehint\alpha}] M_{\typehint{\alpha, \beta}}(x_{\typehint\alpha})))$} \\
  \\
  $\CC (\lambda([x] \op{op} (M^p, [y]M^c(x, y)))) \to$ & rules $\CC^{\op{op}}_{\alpha, \beta, E}$ \\
  $\op{op} (M^p, [y] \CC (\lambda([x] M^c(x, y))))$ & \\
  \multicolumn{2}{l}{$\CC_{\typehint{\alpha \to \FF_E(\beta), \FF_E(\alpha \to \beta)}} (\lambda_{\typehint{\alpha \To \FF_E(\beta), \alpha \to \FF_E(\beta)}}([x_{\typehint\alpha}] \op{op}_{\typehint{\gamma, \delta \To \FF_E(\beta), \FF_E(\beta)}} (M^p_{\typehint\gamma}, [y_{\typehint\delta}]M^c_{\typehint{\alpha, \delta, \FF_E(\beta)}}(x_{\typehint\alpha}, y_{\typehint\delta})))) \to$} \\
  \multicolumn{2}{l}{$\op{op}_{\typehint{\gamma, \delta \To \FF_E(\alpha \to \beta), \FF_E(\alpha \to \beta)}} (M^p_{\typehint\gamma}, [y_{\typehint\delta}] \CC_{\typehint{\alpha \to \FF_E(\beta), \FF_E(\alpha \to \beta)}} (\lambda_{\typehint{\alpha \To \FF_E(\beta), \alpha \to \FF_E(\beta)}}([x_{\typehint\alpha}] M^c_{\typehint{\alpha, \delta, \FF_E(\beta)}}(x_{\typehint\alpha}, y_{\typehint\delta}))))$}
  \end{tabular}
  
  \caption{\label{fig:tau-types} IDTS rewrite rules for
    $\banana{\lambda}_\tau$, shown in parallel with the CRS rules for
    $\banana{\lambda}$.}
  
\end{sidewaysfigure}

To complete our IDTS, we have to give the rewrite rules. The rules for
$\banana{\lambda}_\tau$ are given in Figure~\ref{fig:tau-types}. An
important property of an IDTS rewrite rule is that both its left-hand and
right-hand side are well-typed and that they have the same type. In order
to facilitate the reader's verification that this is indeed the case, we
have used a different labelling scheme for function symbols. When we write
$f_{\alpha_1,\ldots,\alpha_n,\beta}$, we are referring to the instance of
symbol $f$ which has the type $\alpha_1 \to \ldots \to \alpha_n \to \beta$
(i.e.\ belongs to $F_{\alpha_1,\ldots,\alpha_n,\beta}$). This way, instead
of using a symbol name like $\eta_{\alpha,E}$, forcing you to look up its
type $\alpha \to \FF_E(\alpha)$, we will refer to this symbol directly as
$\eta_{\alpha,\FF_E(\alpha)}$.

In Figure~\ref{fig:tau-types}, you will also find the rewrite rules with
all the subscripts removed. This allows you to get a high-level look at the
term without any of the type annotation noise. By removing the typed
indices from the $\banana{\lambda}_\tau$ IDTS rewrite rules, we get the
$\banana{\lambda}$ CRS-reduction rules of Section~\ref{sec:confluence}
(modulo the renaming of $@$ to $\aps$).

When describing the rewrite rules for handlers, the $\banana{}$ symbol
applied to all of its clauses and annotated with all of the intervening
types ends up taking lots of space. Since this expression stays the same
from redex to contractum, from rule to rule, we introduce a shortcut
$\banana{}^{(\op{op}_i)_{i \in
    I}}_{\typehint{\FF_E(\gamma),\FF_{E'}(\delta)}}(N_{\typehint{\FF_E(\gamma)}})$
that we use throughout all of the handler rules.

\subsubsection{Connecting $\banana{\lambda}_\tau$ to $\banana{\lambda}$}
\label{sssec:connecting-bananas}

We have given a complete formal definition of $\banana{\lambda}_\tau$. This
will let us find a proof of termination for $\banana{\lambda}_\tau$ using
the theory of IDTSs. However, in order to carry over this result to our
calculus $\banana{\lambda}$, we will need to formalize relationship between
the two.

\begin{definition}
  \demph{Term} is a (partial) function from $\banana{\lambda}_\tau$ terms
  to $\banana{\lambda}$ terms which removes any type annotations (the
  subscripts on function symbols, variables and metavariables) and
  translates $\banana{\lambda}_\tau$ syntax to $\banana{\lambda}$ syntax
  using the following equations:
  
  \begin{align*}
    & \Term(x) &&= x \\
    & \Term(\lambda([x] M)) &&= \lam{x}{\Term(M)} \\
    & \Term(\aps(M, N)) &&= \ap{(\Term(M))}{(\Term(N))} \\
    & \Term(c) &&= c \\
    & \Term(\eta(M)) &&= \etaE{(\Term(M))} \\
    & \Term(\op{op}(M^{\mathrm{p}}, [x] M^{\mathrm{c}})) &&= \app{\op{op}}{(\Term(M^{\mathrm{p}}))}{(\lam{x}{\Term(M^{\mathrm{c}})})} \\
    & \Term(\cherry(M)) &&= \ap{\cherry}{(\Term(M))} \\
    & \Term(\banana{}_{\op{op}_1, \ldots, \op{op}_n}(M_1, \ldots, M_n, M_\eta, N)) &&= \ap{\banana{\onto{\op{op}_1}{\Term(M_1)},\ \onto{\op{op}_n}{\Term(M_n)},\ \onto{\eta}{\Term(M_\eta)}}}{(\Term(N))} \\
    & \Term(\CC(M)) &&= \ap{\CC}{(\Term(M))}
  \end{align*}
\end{definition}

\begin{definition}
  \demph{Types} is a function from $\banana{\lambda}$ terms to sets of
  $\banana{\lambda}_\tau$ terms, defined by the equation below.
  
  $$
  \Types(M) = \{ m \mid \Term(m) = M \}
  $$
\end{definition}

\begin{lemma}
  \label{lem:infinite-chains}
  Let $M$ and $N$ be $\banana{\lambda}$ terms. Then,

  $$
  M \to_{\intcalc} N \quad \Rightarrow \quad
  \forall m \in \Types(M).\ \exists n \in \Types(N).\ m \to n
  $$
  
  In the above, upper-case letters stand for $\banana{\lambda}$ terms,
  while lower-case letters stand for $\banana{\lambda}_\tau$ terms.
\end{lemma}

\begin{proof}
  This property is essentially a stronger kind of subject reduction for
  $\intcalc$. In proofs of subject reduction, we examine
  every reduction rule and we show how a typing derivation of the redex can
  be transformed into a typing derivation of the contractum. We can think
  of $\banana{\lambda}_\tau$ terms as $\banana{\lambda}$ typing
  derivations. The reduction rules in Figure~\ref{fig:tau-types} are the
  rules which tell us how to take a typing of the redex and transform it
  into a typing of the contractum.
  
  In order to prove this property, we will need to check the following:
  \begin{itemize}
  \item The redexes and contracta in Figure~\ref{fig:tau-types} are
    well-formed (i.e.\ well-typed). For that reason, we have included the
    type of every variable, metavariable and function symbol as a
    subscript.
  \item Applying $\Term$ to the type-annotated $\banana{\lambda}_\tau$
    redexes and contracta yields the redexes and contracta of $\intcalc$
    (and therefore the $\banana{\lambda}_\tau$ redexes and contracta belong
    to the $\Types$ image of the $\intcalc$ redexes and contracta). Since
    in Figure~\ref{fig:tau-types}, we have included the terms with their
    type annotations removed, we can see at a glance that the stripped
    rules align with the CRS formulation of $\banana{\lambda}$.
  \item Finally, we have to check whether the rewriting rules in
    Figure~\ref{fig:tau-types} actually apply to \emph{all} the
    $m \in \Types(M)$. In other words, we need to check whether the type
    annotation scheme used for the redexes is the most general and covers
    all possible typings of the redex. In our case, we have followed the
    typing rule constraints and given the most general type annotations.
  \end{itemize}
  
  Given a reduction in $\intcalc$ from $M$ to $N$, we can find the untyped
  reduction rule used in Figure~\ref{fig:tau-types}. We know that if
  $m \in \Types(M)$, then $m$ then matches the redex of the corresponding
  typed rule. We also know that the contractum of the typed rule belongs to
  $\Types(N)$ and therefore, the property holds. Furthermore, if we were to
  formalize the correspondence between $\banana{\lambda}$ typing
  derivations and $\banana{\lambda}_\tau$ terms, we would get another proof
  of subject reduction for $\intcalc$.
\end{proof}

\begin{lemma}\label{lem:banana-tau-termination}
  If the reduction relation of $\banana{\lambda}_\tau$ is terminating, then
  so is the $\intcalc$ reduction relation on well-typed terms.
\end{lemma}

\begin{proof}
  Consider the contrapositive: if there exists an infinite chain of
  well-typed $\banana{\lambda}$ terms, then there must also be an infinite
  chain of $\banana{\lambda}_\tau$ terms. Using
  Lemma~\ref{lem:infinite-chains}, we can take the $\banana{\lambda}$ chain
  and translate it, link by link, to a $\banana{\lambda}_\tau$ chain.
\end{proof}


\subsection{Termination for IDTSs}
\label{ssec:termination-for-idts}

So far, we have introduced an IDTS and have shown that if this IDTS is
terminating, then so is $\banana{\lambda}$. We will now look at a general result
for IDTSs that we will make use of.

\begin{theorem}
  \label{thm:idts-normalization}
  \demph{(Strong normalization)}~\cite{blanqui2000termination} Let
  $\II = (\AAA, \RR)$ be a $\beta$-IDTS satisfying the assumptions (A). If
  all the rules of $\RR$ satisfy the General Schema, then $\to_\II$ is
  strongly normalizing.
\end{theorem}

Strong normalization is confluence and termination and so by showing
$\banana{\lambda}_\tau$ strongly normalizing, we also prove it
terminating. The theorem was lifted verbatim
from~\cite{blanqui2000termination} and parts of it deserve explaining:

\begin{itemize}
\item What is a $\beta$-IDTS?
\item What are the assumptions (A)?
\item What is the General Schema?
\end{itemize}

We will deal with these in order.

A $\beta$-IDTS is just an IDTS which for every two types $\alpha$ and
$\beta$ has a function symbol
$@_{\alpha,\beta} \in F_{\alpha \To \beta,\alpha,\beta}$ and a rule
$@_{\alpha,\beta}([x_\alpha] M_{\alpha, \beta}(x_\alpha), N_\alpha) \to
M_{\alpha,\beta}(N_\alpha)$. Furthermore, there must be no other rules
whose left-hand side is headed by $@$. We can turn our IDTS
from~\ref{ssec:banana-idts} into a $\beta$-IDTS by extending it with these
function symbols and reduction rules\footnote{These $\beta$ rules and
  application operators are different from the ones already in our
  IDTS. $\aps$ is defined for the $\alpha \to \beta$ function type from
  $\banana{\lambda}$ whereas $@$ serves the $\alpha \To \beta$ type of
  IDTS.}. Termination in a larger system will still imply termination in
our system.

\subsubsection{Checking Off the Assumptions}

Next, we will deal with the assumptions (A).

\begin{definition}
  The \demph{Assumptions (A)} are defined as the following four conditions:
  \begin{enumerate}
  \item every constructor is positive
  \item no left-hand side of rule is headed by a constructor
  \item both $>_\BB$ and $>_\FF$ are well-founded
  \item $stat_f = stat_g$ whenever $f =_\FF g$
  \end{enumerate}
\end{definition}

For these to make sense to us, we will need to identify some more structure
on top of our IDTS: the notion of a constructor and the $>_\BB$ and $>_\FF$
relations.

We will need to designate for every base type $\gamma$ a set
$C_\gamma \subseteq \cup_{p \ge 0, \alpha_1, \ldots, \alpha_p \in T(\BB)}
F_{\alpha_1, \ldots, \alpha_p, \gamma}$ (i.e.\ a set of function symbols
with result type $\gamma$). We will then call the elements of these sets
\emph{constructors} of $\gamma$.

The base types of our IDTS consist of atomic types, function types and
computation types. We will have no constructors for atomic types. On the
other hand, every function type $\alpha \to \beta$ will have a constructor
$\lambda_{\alpha, \beta}$ ($\in F_{\alpha \To \beta, \alpha \to \beta}$)
and every computation type $\FF_E(\gamma)$ will have constructors
$\eta_{\gamma,E}$ ($\in F_{\gamma,\FF_E(\gamma)}$) and $\op{op}_{\gamma,E}$
($\in F_{\alpha,\beta \to \FF_E(\gamma),\FF_E(\gamma)}$) for every
$\typedop{op}{\alpha}{\beta} \in E$.

We can now check assumption (A.2). Since the only constructors in our IDTS
are $\eta$, $\op{op}$ and $\lambda$, we validate this
assumption\footnote{This is why we have to prove termination with $\eta$
  reduction separately}.

Our choice of constructors induces a binary relation on the base types.

\begin{definition}
  $\beta$ \emph{depends on} $\alpha$ if there is a constructor
  $c \in C_\beta$ such that $\alpha$ occurs in the type of one of the
  arguments of $c$.
  
  We will use $\ge_\BB$ to mean the reflexive-transitive closure of this
  relation between $\alpha$ and $\beta$. Furthermore, we will use $=_\BB$
  and $>_\BB$ to mean the associated equivalence and strict ordering,
  respectively.
\end{definition}

\begin{observation}\label{obs:base-type-depends}
  If $\tau_2$ depends on $\tau_1$, then either:

  \begin{itemize}
  \item $\tau_1$ is a subterm of $\tau_2$ or
  \item $\tau_1 = \beta \to \FF_E(\gamma)$ and $\tau_2 = \FF_E(\gamma)$ for
    some $\typedop{op}{\alpha}{\beta} \in E$.
  \end{itemize}
\end{observation}
\begin{proof}
  If $\tau_2$ is an atomic type, then $\tau_2$ has no constructors, so it
  does not depend on any type.

  If $\tau_2$ is the function type $\alpha \to \beta$, then it depends on
  $\alpha$ and $\beta$ due to the constructor $\lambda_{\alpha, \beta}$
  whose argument has type $\alpha \To \beta$. Both $\alpha$ and $\beta$ are
  subterms of $\alpha \to \beta$.
  
  If $\tau_2$ is the computation type $\FF_E(\gamma)$, then we will have
  several constructors. We have $\eta_{\gamma,E}$ with a single argument of
  type $\gamma$. We thus know that $\FF_E(\gamma)$ depends $\gamma$. For
  every $\typedop{op}{\alpha}{\beta} \in E$, we have a constructor
  $\op{op}_{\gamma,E}$ with arguments of types $\alpha$ and
  $\beta \to \FF_E(\gamma)$. This tells us that $\FF_E(\gamma)$ also
  depends on $\alpha$ and $\beta \to \FF_E(\gamma)$\footnote{Note that
    $\FF_E(\gamma)$ does not depend on $\beta$. From the point of view of
    IDTS and the definition of ``depends'', $\beta \to \FF_E(\gamma)$ is an
    opaque base type. Therefore, on the IDTS side, $\beta$ does not occur
    in $\beta \to \FF_E(\gamma)$, though it would occur in
    $\beta \To \FF_E(\gamma).$}. $\alpha$ and $\gamma$ are both subterms of
  $\FF_E(\gamma)$ ($\alpha$ occurs in $E$).  $\beta \to \FF_E(\gamma)$
  falls into the second case, when $\tau_1$ is not a subterm of $\tau_2$.
\end{proof}

\begin{corollary}\label{cor:base-type-le}
  If $\tau_1 \le_\BB \tau_2$, then either:

  \begin{itemize}
  \item $\tau_1$ is a subterm of $\tau_2$ or
  \item $\tau_1 = \beta \to \FF_E(\gamma)$ and $\tau_2 = \FF_E(\gamma)$ for
    some $\typedop{op}{\alpha}{\beta} \in E$.
  \end{itemize}
\end{corollary}

\begin{proof}
  Let us first ignore the second case of
  Observation~\ref{obs:base-type-depends} where $\tau_1$ is not a subterm
  of $\tau_2$. Then we have that the ``$b$ depends on $a$'' relation is
  included in the ``$a$ is a subterm of $b$'' relation. The subterm
  relation is a preorder (reflexive, transitive). Since the
  reflexive-transitive closure is monotone and idempotent, we have that the
  reflexive-transitive closure of ``$b$ depends on $a$'', $\le_\BB$, is
  included in the subterm relation.

  If we now admit the second case, when $\tau_1 = \beta \to \FF_E(\gamma)$
  and $\tau_2 = \FF_E(\gamma)$, we can show that the only new pairs that we
  add into the reflexive-transitive closure will be the
  $\beta \to \FF_E(\gamma) \le_\BB \FF_E(\gamma)$ pairs. For any
  $x \le_\BB \beta \to \FF_E(\gamma)$, the transitive closure will force us
  to add $x \le_\BB \FF_E(\gamma)$. However, $\beta \to \FF_E(\gamma)$
  depends only on $\beta$ and $\FF_E(\gamma)$, which are both already
  subterms of $\FF_E(\gamma)$.
\end{proof}

\begin{corollary}\label{cor:base-type-eq}
  $\tau_1 =_\BB \tau_2$ if and only if either:

  \begin{itemize}
  \item $\tau_1 = \tau_2$ or
  \item $\tau_1 = \beta \to \FF_E(\gamma)$ and $\tau_2 = \FF_E(\gamma)$ for
    some $\typedop{op}{\alpha}{\beta} \in E$.
  \end{itemize}
\end{corollary}

\begin{corollary}\label{cor:base-type-lt}
  If $\tau_1 <_\BB \tau_2$, then $\tau_1$ is a proper subterm of $\tau_2$.
\end{corollary}

We can now check the first half of assumption (A.3). Since the proper
subterm relation is well-founded (i.e.\ has no infinite descending chains)
and $>_\BB$ is a subset of the proper subterm relation, then $>_\BB$ must
be well-founded as well.

We can also check assumption (A.1) once we explain what is a positive
constructor.

\begin{definition}
  A constructor $c \in C_\beta$ is \demph{positive} if every base type
  $\alpha =_\BB \beta$ occurs only at positive positions in the types of
  the arguments of $c$.
\end{definition}

\begin{definition}
  The base types occurring in \demph{positive positions} $(\Pos)$ and the
  base types occurring in \demph{negative positions} $(\Neg)$ within a type
  are defined by the following mutually recursive equations:

  \begin{align*}
    \Pos(\alpha \to \beta) &= \Neg(\alpha) \cup \Pos(\beta) \\
    \Neg(\alpha \to \beta) &= \Pos(\alpha) \cup \Neg(\beta) \\
    \Pos(\nu) &= \{ \nu \} \text{\quad with $\nu$ an atomic type} \\
    \Neg(\nu) &= \emptyset \text{\quad with $\nu$ an atomic type}
  \end{align*}
\end{definition}

In our IDTS, the only constructors are $\lambda$, $\eta$ and
$\op{op}$.
\begin{itemize}
\item $\lambda_{\tau_1, \tau_2}$ is a constructor for the type
  $\tau_1 \to \tau_2$; it has one argument of type $\tau_1 \To
  \tau_2$. From Corollary~\ref{cor:base-type-eq}, we know that if
  $\tau_1 \to \tau_2 =_\BB \tau$, then either $\tau = \tau_1 \to \tau_2$ or
  $\tau = \tau_2$ (the case when $\tau_2 = \FF_E(\gamma)$).
  $\tau_1 \to \tau_2$ does not occur in $\tau_1 \To \tau_2$ at all and
  $\tau_2$ occurs there only positively.
\item $\eta_{\gamma, E}$ is a constructor for the type $\FF_E(\gamma)$; it
  has one argument of (base) type $\gamma$. With the same reasoning as
  above, the only types $=_\BB$-equivalent to $\FF_E(\gamma)$ are
  $\FF_E(\gamma)$ and $\beta \to \FF_E(\gamma)$, neither of which occur in
  the base type $\gamma$.
\item For every $\typedop{op}{\alpha}{\beta} \in E$, we have a constructor
  $\op{op}_{\gamma, E}$ for the type $\FF_E(\gamma)$. It has two arguments,
  one of (base) type $\alpha$ and one of type $\beta \to
  \FF_E(\gamma)$. $\FF_E(\gamma)$ is $=_\BB$-equivalent to $\FF_E(\gamma)$
  (which does not occur in the type of any of the arguments) and to
  $\beta \to \FF_E(\gamma)$, which only occurs positively in
  $\beta \to \FF_E(\gamma)$.
\end{itemize}

This means that we validate assumption (A.1).

To validate the second half of (A.3), we will need to introduce the $>_\FF$
relation. As $>_\BB$ was induced by the structure of constructors, $>_\FF$
will be induced by the structure of the rewriting rules $\RR$ of our IDTS.

\begin{definition}
  A function symbol $g$ \demph{depends on} a function symbol $f$ if there
  is a rule defining $g$ (i.e.\ whose left-hand side is headed by $g$) and
  in the right-hand side of which $f$ occurs.

  We will use $\le_\FF$ as the name for the reflexive-transitive closure of
  this relation between $f$ and $g$. We will also write $=_\FF$ and $>_\FF$
  for the associated equivalence and strict ordering, respectively.
\end{definition}

If we scan the rules of $\banana{\lambda}$, we will see that the
$\banana{}$ symbols depend on $\op{op}$ (for when there is no handler and
the $\op{op}$ is copied), $\aps$ (for applying the handler clauses to their
arguments) and on $\banana{}$ (for recursion). The $\CC$ symbols depend on
$\op{op}$ (when passing the $\lambda$ through an $\op{op}$), $\eta$ (when
switching the $\lambda$ with the $\eta$) and $\CC$ (for recursion). There
is no other dependency in our IDTS.\@ This means we can check off the
second part of assumption (A.3) since $>_\FF$ is well-founded (it contains
only $\banana{} >_\FF \op{op}$, $\banana{} >_\FF \aps$, $\CC >_\FF \op{op}$
and $\CC >_\FF \eta$).

Assumption (A.4) is trivial in our case, since within our IDTS $f =_\FF g$
only when $f = g$. This assumption only comes into play in the general
theory of IDTSs when one exploits mutual recursion with functions of
multiple arguments. The $stat_f$ values mentioned in the assumption (A.4)
describe the way in which a function's arguments should be ordered to
guarantee that recursive calls are always made to smaller arguments. In the
case of mutual recursion, both functions must agree on the order according
to which they will decrease their arguments. Since we do not deal with
mutual recursion in $\banana{\lambda}$, we will not go into any more detail
into this.


\subsubsection{General Schema}

There is one last obstacle in our way towards proving termination of
$\banana{\lambda}_\tau$. We will need to verify that the rewrite rules that
we given in Figure~\ref{fig:tau-types} satisfy the General Schema.

\begin{definition}
  A rewrite rule $f(l_1, \ldots, l_n) \to r$ follows the \demph{General
    Schema} if $r \in \CC\CC_f(l_1, \ldots, l_n)$.
\end{definition}

$\CC\CC_f(l_1, \ldots, l_n)$ refers to the so-called \emph{computable
  closure} of the left-hand side $f(l_1, \ldots, l_n)$. The idea behind the
computable closure is that the left-hand side of a rewrite rule can tell us
what are all the possible right-hand sides that still lead to a correct
proof of termination\footnote{Theorem~\ref{thm:idts-normalization} is
  proven using Tait's method of computability predicates
  \cite{tait1967intensional}. The term computable closure comes from the
  fact that the admissible right-hand sides are the metavariables of the
  left-hand side closed on operations that preserve computability.}. A
formal definition of computable closure is given
in~\cite[p. 8]{blanqui2000termination}.

Informally, $r \in \CC\CC_f(l_1, \ldots, l_n)$ if:
\begin{itemize}
\item Every metavariable used in $r$ is accessible in one of $l_1$, \ldots,
  $l_n$.
\item Recursive function calls (i.e.\ uses of function symbols $g =_\FF f$)
  are made to arguments smaller than the arguments $l_1$, \ldots, $l_n$.
\end{itemize}

A metavariable is \demph{accessible} in a term if it appears at the top of
the term or under abstractions or constructors. If a metavariable occurs
inside an argument of a function symbol which is not a constructor, then
there are some technical constraints on whether it is accessible. However,
in every rewrite rule of our IDTS, the arguments of the function symbol
being defined contain only constructors as function symbols.

Finally, we will need to show that the arguments being recursively passed
to $\banana{}$ and $\CC$ are smaller than the original arguments and
therefore the recursion is well-founded and terminating. However, the
General Schema presented in~\cite{blanqui2000termination} uses a notion of
``smaller than'' which is not sufficient to capture the decrease of our
arguments. On the other hand, when we were defining a denotational
semantics for $\banana{\lambda}$, we gave a well-founded ordering showing
that the successive arguments to these operations are in fact
decreasing. We will therefore make use of a technique which will allows us
to incorporate this semantic insight into the IDTS so that the General
Schema will be able to recognize the decreasing nature of the arguments.


\subsection{Higher-Order Semantic Labelling}
\label{ssec:semantic-labelling}

We will make us of the higher-order semantic labelling technique presented
by Makoto Hamana in~\cite{hamana2007higher}. The idea behind the semantic
labelling technique is to label function symbols with the denotations of
their arguments. Whereas before a function symbol was rewritten to the same
function symbol on a smaller argument, in the labelled IDTS, a labelled
symbol will be rewritten to a different \emph{smaller} symbol (i.e.\ with a
smaller label).

The theory in~\cite{hamana2007higher} is expressed in terms of category
theory. This results in a very elegant and concise formulation of the
theorems and their proofs. In our thesis, we only care about the
applications of the theory and so we will be try to introduce the technique
without presupposing the reader's familiarity with category theory.


\subsubsection{Presheafs and Binding Algebras}
\label{sssec:presheafs-binding-algebras}

We will nevertheless introduce a few terms from category theory.

When dealing with binding and types, it is usually not so useful to
consider a mixed set of terms or denotations of different types. It is much
more pertinent to speak of families of terms having the same type in the
same typing context, i.e.\
$T_\tau(\Gamma) = \{ t \mid \Gamma \vdash t : \tau \}$. In this example,
$T$ is a family of sets, indexed first by type and second by context. We
can therefore say that $T \in (\SetC^{\ContextC})^{\BB}$, where $\BB$ is
the set of base types of our IDTS (i.e.\ the set of $\banana{\lambda}$
types) and $\ContextC$ is the set of $\banana{\lambda}$ typing contexts
(functions from finite sets to $\BB$).

The category-theoretical presentation of abstract syntax and binding
originating in~\cite{fiore2003abstract} relies on a similar notion known as
\emph{presheaf}. Presheaf can be seen as a synonym for functor
(see~\ref{ssec:functor}), usually going from some kind of ``index
category'' to some other category. In the above example, $\BB$, $\ContextC$
and $\SetC$ can be seen as categories:

\begin{itemize}
\item $\BB$ has base types as objects and no arrows besides the mandatory
  identities
\item $\ContextC$ has typing contexts as objects and renamings of contexts
  (exchanges, weakenings, contractions) as arrows
\item $\SetC$ is the standard category with sets as objects and functions
  as arrows
\end{itemize}

$\SetC^\ContextC$ is the category of functors from $\ContextC$ to
$\SetC$. The object component of such a functor maps contexts to sets
(usually sets of objects having some type within the given context). The
arrow component translates the renamings of contexts into renamings of
variables in these objects. The functors in the category
$(\SetC^\ContextC)^\BB$ map types to the object of $\SetC^\ContextC$; their
arrow component is trivial since $\BB$ has only trivial arrows.

We will call the object of $(\SetC^\ContextC)^\BB$ presheafs (sometimes, we
will also call objects in $\SetC^\ContextC$ presheafs). In our
presentation, we will care only about the object level, meaning we will
identify a presheaf with a family of sets. We will now consider some
presheaf that will come into play:

\begin{itemize}
\item The presheaf that we will care the most about will be the presheaf
  $T$ of $\banana{\lambda}$ terms,
  $T_{\tau,\Gamma} = \{ M \mid \Gamma \vdash M : \tau \}$. Every element of
  $T_{\tau,\Gamma}$ is a well-typed $\banana{\lambda}$ term.
\item Another useful presheaf is the presheaf $V$ of variables where
  $V_{\tau,\Gamma} = \{x \mid x : \tau \in \Gamma \}$.
\item $Z$ is the presheaf of the IDTS metavariables from $\ZZ$,
  $Z_{\tau, (x_1 : \alpha_1,\ldots,x_n : \alpha_n)} = \{ M \mid M \in
  Z_{\alpha_1,\ldots,\alpha_n,\tau} \}$.
\item $T_\Sigma V$ is the presheaf of IDTS terms with alphabet $\Sigma$.
\item $M_\Sigma
  Z$ is the presheaf of IDTS metaterms with alphabet
  $\Sigma$ and typed metavariables $Z$.
\end{itemize}

Now we will define some endofunctors on the category of presheaves. As
before, we will ignore the arrow component and give only a mapping from one
family to another.

\begin{itemize}
\item First, we introduce an endofunctor on the category of presheafs in
  $\SetC^\ContextC$. For every base type $\tau$, we have a functor
  $\delta_\tau : \SetC^\ContextC \to \SetC^\ContextC$. For
  $A \in \SetC^\ContextC$, we define
  $(\delta_\tau A)(\Gamma) = A(\Gamma + \tau)$ where $\Gamma + \tau$ is the
  extension of context $\Gamma$ by a variable of type $\tau$\footnote{When
    we extend a context, we usually extend it with a pair of a variable
    name and a type, e.g.\ $\Gamma, x : \tau$. However, in this section we
    will be using de Bruijn levels~\cite{de1972lambda}, where the names of
    variables in a context are always integers from 1 to some
    $n$. Extending a context $x_1 : \alpha_1, \ldots, x_n : \alpha_n$ with
    a type $\tau$ then yields a context
    $x_1 : \alpha_1, \ldots, x_n : \alpha_n, x_{n+1} : \tau$.}. The idea
  behind this operation is to model binders, i.e.\ the arrow type $\To$ of
  IDTS.\@ If the presheaf $A_\beta \in \SetC^\ContextC$ models the type
  $\beta$, then the presheaf $\delta_\alpha A_\beta$ models the type
  $\alpha \To \beta$.

\item The alphabet of our IDTS, $\Sigma$, induces an endofunctor on the
  category $(\SetC^\ContextC)^\BB$ mapping presheafs $A$ to presheafs
  $\Sigma A$.

  $$
  (\Sigma A)_\gamma = \coprod_{f \in F_{\vec{\alpha_1} \To \beta_1, \ldots, \vec{\alpha_l} \To \beta_l, \gamma}} \prod_{1 \le i \le l} \delta_{\vec{\alpha_i}} A_{\beta_i}
  $$

  In the above, we use the vector notation $\vec{\alpha} \To \beta$ for
  $\alpha_1 \To \ldots \To \alpha_n \To \beta$ and $\delta_{\vec{\alpha}}$
  for $\delta_{\alpha_1} \circ \ldots \circ \delta_{\alpha_n}$. Note that
  the above definition assumes that $\vec{\alpha_i}$, $\beta_i$ and
  $\gamma$ are all base types. Since in our encoding of $\banana{\lambda}$,
  we use a function constructor $\to$ on the level of base types, this is
  the case.
\end{itemize}

We are now ready to define the notion of a $\Sigma$-binding algebra.

\begin{definition}
  A \demph{$\Sigma$-(binding) algebra} $\AAA$ is a pair of a presheaf $A$
  and a natural transformation\footnote{Natural transformation is the name
    for an arrow between two functors (presheafs). In our particular
    setting, naturality boils down to $A_\gamma$ being a function of
    $(\Sigma A)_\gamma$.} $\alpha : \Sigma A \to A$. The presheaf is the
  \demph{carrier} and the natural transformation interprets the
  \demph{operations}. Since $\Sigma A$ is a coproduct over all the
  $f \in \FF$, we can also see $\alpha$ as the copair
  $[f^\AAA]_{f \in \FF}$, where $f^\AAA$ is the interpretation in algebra
  $\AAA$ of operation $f$.
\end{definition}

We will need to construct a $(V+\Sigma)$-algebra in order to proceed, where
$(V+\Sigma)(A) = V + \Sigma(A)$. Our algebra will be a term algebra, the
carrier will be the presheaf $T$. Now we need to give an interpretation to
variables and to every function symbol defined in the alphabet
$\Sigma$. This interpretation must be given as an
$\alpha : V + \Sigma T \to T$, meaning that the interpretation of every
function symbol must be compositional. Every value from
$(\Sigma T)_{\gamma,\Gamma}$ is some function symbol of result type
$\gamma$ together with the interpretation of all of the symbol's
arguments. These interpretations will be $\banana{\lambda}$ terms typable
with type $\beta_i$ under the context $\Gamma + \vec{\alpha_i}$ where
$\beta_i$ is the type of the $i$-th argument of the function symbol and
$\vec{\alpha_i}$ are the types of variables that the function symbol binds
in the $i$-th argument (the names of the bound variables will be
$x_{n+1}$,\ldots,$x_{n+k_i}$ where $n = |\Gamma|$ and $k_i$ is the number
of variables bound in the $i$-th argument by the function symbol).

The translation $\Term$ from $\banana{\lambda}_\tau$ terms to
$\banana{\lambda}$ terms that we have given in~\ref{ssec:banana-idts} is
exactly of this form. For example, the line defining the translation of the
expression $\op{op}(M^\petitp, [x] M^\petitc)$ can be transformed into an
interpretation for the function symbol $\op{op}$ the following way:

\begin{align*}
  & \Term(\op{op}(M^\petitp, [x] M^\petitc)) =
    \app{\op{op}}{(\Term(M^\petitp))}{(\lam{x}{\Term(M^\petitc)})} \\
  & \op{op}_\Gamma(M^\petitp, M^\petitc) =
    \app{\op{op}}{(\Term(M^\petitp))}{(\lam{x_{n+1}}{\Term(M^\petitc)})} \\
\end{align*}

where $n = |\Gamma|$.

Therefore, the $\Term$ translation function from~\ref{ssec:banana-idts}
gives us a $(V+\Sigma)$-algebra $\TT$ with carrier $T$.

% Another example of a $(V+\Sigma)$-algebra is the algebra of denotations
% $\DD$ whose carrier is the presheaf of denotations $D$ and where the
% operations are interpreted with the compositional rules of
% $\banana{\lambda}$ denotational semantics given
% in~\ref{ssec:denotational-semantics}.


\subsubsection{Building a Quasi-Model}
\label{sssec:quasi-model}

We will now deal with presheafs equipped with partial orders.

\begin{definition}
  A \demph{presheaf equipped with a partial order} is a pair of a presheaf
  $A$ and a family of partial orders $\ge_A$ such that
  $\ge_{A_{\tau,\Gamma}}$ is a partial order on the set $A_{\tau,\Gamma}$.
\end{definition}

\begin{definition}
  An arrow $f : A^1 \times \cdots \times A^n \to B$ in $\SetC^\ContextC$ is
  \demph{weakly monotonic} if for all $\Gamma$ and
  $a_1, b_1 \in A^1_\Gamma$, \ldots, $a_n, b_n \in A^n_\Gamma$ with
  $a_k \ge_{A_{k,\Gamma}} b_k$ for some $k$ and $a_j = b_j$ for all
  $j \neq k$, we have that
  $f(\Gamma)(a_1, \ldots, a_n) \ge_{B_\Gamma} f(\Gamma)(b_1, \ldots,
  b_n)$.
\end{definition}

\begin{definition}
  A \demph{weakly monotonic $V+\Sigma$-algebra} is a $V+\Sigma$-algebra
  $\AAA$ whose carrier $A$ is equipped with a partial order $\ge_A$ such
  that every operation of $\AAA$ is weakly monotonic.
\end{definition}

We will equip our ($V+\Sigma$)-algebra $\TT$ with the partial order
$\to^*$. Because the reduction relation $\to$ of $\banana{\lambda}$ is
closed on contexts, the operations of $\TT$ are weakly monotonic: if we
replace one of the arguments $M_i$ in $f(M_1,\ldots,M_n)$ with an $M'_i$
such that $M_i \to^* M_i'$, then we will also have
$f(M_1,\ldots,M_n) \to^* f(M_1,\ldots,M'_i,\ldots,M_n)$. Therefore, we have
a weakly monotonic ($V+\Sigma$)-algebra $\TT$.

\begin{definition}
  For a given ($V+\Sigma$)-algebra $\AAA$, a \demph{term-generated
    assignment} $\phi$ is an arrow in $(\SetC^\ContextC)^\BB$ from the
  presheaf $Z$ to the presheaf $A$ such that $\phi = \bangop \circ \theta$,
  where:

  \begin{itemize}
  \item $\theta$ is an IDTS valuation\footnote{Same as the CRS valuations
      introduced in~\ref{ssec:crs}, but typed.}, i.e.\ an arrow from $Z$ to
    $T_\Sigma V$.
  \item $\bangop$ is the unique homomorphism from the initial
    ($V+\Sigma$)-algebra $T_\Sigma V$ to $A$\footnote{Homomorphisms between
      $\Sigma$-algebras are defined in the same way as homomorphisms for
      first-order algebras. The term algebra $T_\Sigma V$ is called an
      initial algebra because we can find a (unique) homomorphism from
      $T_\Sigma V$ to any other algebra $\AAA$ that works by interpreting
      terms from $T_\Sigma V$ using the operations of $\AAA$.}.
  \end{itemize}
\end{definition}

To clarify the nomenclature: valuations replace metavariables with terms,
assignments replace metavariables with interpretations in some algebra and
term-generated assignments are assignments that can only assign an
interpretation $x$ if $x$ can be computed as the interpretation of some
term.

\begin{definition}
  A weakly monotonic ($V+\Sigma$)-algebra $(\AAA, \ge_A)$ \demph{satisfies
    an IDTS rewrite rule} $l \to r$, with $l$ and $r$ of type $\tau$, if
  for all term-generated assignments $\phi$ of the free metavariables $Z$
  in $l$ and $r$, we have:

  $$
  \bangop \theta^*_{\tau,\Gamma}(l) \ge_{A_{\tau,\Gamma}} \bangop \theta^*_{\tau,\Gamma}(r)
  $$

  where $\phi = \bangop \circ \theta$, $\theta^*$ is the extension of the
  valuation $\theta$ to meta-terms and $\Gamma$ is the context regrouping
  all the free variables exposed by $\theta$.
\end{definition}

\begin{definition}
  A weakly monotonic ($V+\Sigma$)-algebra $(\AAA, \ge_A)$ is a quasi-model
  for the IDTS $(\Sigma, \RR)$ if $(\AAA, \ge_A)$ satisfies every rule in
  $\RR$.
\end{definition}

Our weakly monotonic algebra $(\TT, \to^*)$ is a quasi-model for the IDTS
$\banana{\lambda}_\tau$. It satisfies every rule, because if we substitute
for the metavariables $M$, $N$, \ldots in a $\banana{\lambda}_\tau$ rule
$l[M,N] \to r[M,N]$ and translate it to $\banana{\lambda}$ syntax, we still
have a $\banana{\lambda}$ reduction $\Term(l[M',N']) \to \Term(r[M',N'])$.


\subsubsection{Labelling Our System}

We will now decide how to label the $\banana{}$ and $\CC$ symbols. The
labels we will choose will be the $\banana{\lambda}$ denotations introduced
in~\ref{ssec:denotational-semantics}. We will build up some orders on the
denotations that will come in hand later.

\begin{definition}
  For each $\banana{\lambda}$ type $\tau$, we define a well-founded strict
  partial order $>_{\sem{\tau}}$ by induction on $\tau$.

  \begin{itemize}
  \item $\tau$ is an atomic type

    Then $>_{\sem{\tau}}$ is the empty relation.

  \item $\tau = \alpha \to \beta$

    $f >_{\sem{\tau}} g$ if and only if $f$ and $g$ are both functions
    (i.e.\ not $\bot$) and
    $\forall x \in \sem{\alpha}.\ f(x) >_{\sem{\beta}} g(x)$. The new order
    is well-founded: any hypothetical descending chain $f_1$, $f_2$, \ldots
    in $>_{\sem{\tau}}$ would be projected to a descending chain $f_1(x)$,
    $f_2(x)$, \ldots in $>_{\sem{\beta}}$, which is well-founded by
    induction hypothesis.

  \item $\tau = \FF_E(\gamma)$

    Let $E = \{\typedopg{\op{op}_i}{\alpha_i}{\beta_i}\}_{i \in I}$. The
    order $>_{\sem{\tau}}$ is the smallest transitive relation satisfying
    the following:
    \begin{itemize}
    \item
      $\forall i \in I,\ \forall p \in \sem{\alpha_i},\ \forall c \in
      \sem{\FF_E(\gamma)}^{\sem{\beta_i}},\ \forall x \in \sem{\beta_i}.\
      \op{op}_i(p, c) >_{\sem{\tau}} c(x)$
    \end{itemize}
    
    The proof of the well-foundedness of this relation was given in the
    definition of the interpretation of a handler
    in~\ref{ssec:denotational-semantics}. It relies on the fact that
    $\sem{\FF_E(\gamma)}$ is defined as a union of an increasing sequence
    of sets where $c(x)$ always belongs to a set preceding the one in which
    $\op{op}_i(p, c)$ appears for the first time.
  \end{itemize}
\end{definition}

As our labels, we will use denotations of (possibly open)
$\banana{\lambda}$ terms. These objects are functions from $\sem{\Gamma}$
to $\sem{\tau}$ for some typing context $\Gamma$ and type $\tau$. We will
want to be able to compare denotations of two objects having the same type
but not necessarily occurring in the same typing context. We introduce some
notation to deal with context and valuation extensions.

\begin{notation}
  Let $\Gamma$ and $\Delta$ be typing contexts. The typing context $\Gamma,
  \Delta$, the \demph{extension of $\Gamma$ with $\Delta$}, is defined by:

  $$
  (\Gamma,\Delta)(x) = \begin{cases}
    \Delta(x), & \text{if $\Delta(x)$ is defined} \\
    \Gamma(x), & \text{otherwise}
  \end{cases}
  $$
\end{notation}

\begin{notation}
  Let $e$ and $d$ be valuations\footnote{Not IDTS valuations, but the
    valuations used by the denotational semantics
    in~\ref{ssec:denotational-semantics}.} for the typing contexts $\Gamma$
  and $\Delta$, respectively. The valuation $e + d$ for the context
  $\Gamma, \Delta$, called the \demph{extension of $e$ with $d$}, is
  defined by:

  $$
  (e + d)(x) = \begin{cases}
    d(x), & \text{if $x \in \dom(d)$} \\
    e(x), & \text{otherwise}
  \end{cases}
  $$
\end{notation}

\begin{notation}
  We will use the term $D(\tau)$ for the set
  $\biguplus_\Gamma \sem{\tau}^{\sem{\Gamma}}$, the set of \demph{possible
    denotations} of $\tau$-typed $\banana{\lambda}$ terms.
\end{notation}

\begin{definition}
  Let $\tau$ be a $\banana{\lambda}$ type. The well-founded strict partial
  order $>_{D(\tau)}$ on the set $D(\tau)$ is defined by:

  \begin{itemize}
  \item $f >_{D(\tau)} g$ if and only if:
    \begin{itemize}
    \item $f : \sem{\Gamma} \to \sem{\tau}$
    \item $g : \sem{\Gamma,\Delta} \to \sem{\tau}$
    \item $\forall e \in \sem{\Gamma},\ \forall d \in \sem{\Delta}.\ f(e)
      >_{\sem{\tau}} g(e + d)$
    \end{itemize}
  \end{itemize}
  
  We will use the notation $\ge_{D(\tau)}$ for the associated well-founded
  partial order (the reflexive closure of $>_{D(\tau)}$).
\end{definition}

For every symbol $f$ to label, we will now choose a non-empty well-founded
poset $(S_f, \ge_{S_f})$, called the \emph{semantic label set}. In our
application of the technique, we will always choose the set of possible
denotations of the argument that is being recursively decreased by the
function. For the symbols that we do care to label, we will assume that
their semantic label set is the single-element set $1$.

\begin{itemize}
\item For
  $\banana{}_{\op{op}_1, \ldots, \op{op}_n, \gamma, \delta, E, E'} \in
  F_{\alpha_1 \to (\beta_1 \to \FF_{E'}(\delta)), \ldots, \alpha_n \to
    (\beta_n \to \FF_{E'}(\delta)), \gamma \to \FF_{E'}(\delta),
    \FF_E(\gamma), \FF_{E'}(\delta)}$, we take as the semantic label set
  the poset $D(\FF_E(\gamma))$ ordered by $\ge_{D(\FF_E(\gamma))}$.
\item For
  $\CC_{\alpha,\beta,E} \in F_{\alpha \to \FF_E(\beta),\FF_E(\alpha \to
    \beta)}$, we take as the semantic label set the poset
  $D(\alpha \to \FF_E(\beta))$ ordered by
  $\ge_{D(\alpha \to \FF_E(\beta))}$.
\end{itemize}

Having fixed the semantic label sets, we will now choose the \emph{semantic
  label maps}. For each symbol
$f \in F_{\vec{\alpha_1} \To \beta_1, \ldots, \vec{\alpha_n} \To \beta_n,
  \gamma}$ to be labelled, we define a weakly monotonic arrow
$\angles{-}^f$ in $\SetC^\ContextC$:

$$
\angles{-}^f : \delta_{\vec{\alpha_1}} T_{\beta_1} \times \cdots \times
\delta_{\vec{\alpha_n}} T_{\beta_n} \longrightarrow K_{S_f}
$$

where $K_A$ is the constant presheaf $K_A(\Gamma) = A$. This semantic label
map has access to the interpretations of all of the function symbol's
arguments and needs to map them to an element of the semantic label set. In
our model, the carrier containing the interpretations is the presheaf $T$.

This means that for every
$\banana{}_{\op{op}_1, \ldots, \op{op}_n, \gamma, \delta, E, E'} \in
F_{\alpha_1 \to (\beta_1 \to \FF_{E'}(\delta)), \ldots, \alpha_n \to
  (\beta_n \to \FF_{E'}(\delta)), \gamma \to \FF_{E'}(\delta),
  \FF_E(\gamma), \FF_{E'}(\delta)}$, we need to give:

$$
\angles{-}^{\banana{}} : T_{\alpha_1 \to (\beta_1 \to
  \FF_{E'}(\delta))} \times \cdots \times T_{\alpha_n \to (\beta_n \to
  \FF_{E'}(\delta))} \times T_{\gamma \to \FF_{E'}(\delta)} \times
T_{\FF_E(\gamma)} \longrightarrow K_{D(\FF_E(\gamma))}
$$

We do so by projecting the last argument, which is a $\banana{\lambda}$
term of type $\FF_E(\gamma)$ in the context $\Gamma$, and finding its
denotation using $\sem{-}$.

$$
\angles{M_1, \cdots, M_n, M_\eta, N}^{\banana{}}_\Gamma = \sem{N}
$$

We will do the same for the $\CC$ symbols. For every
$\CC_{\alpha,\beta,E} \in F_{\alpha \to \FF_E(\beta),\FF_E(\alpha \to
  \beta)}$, we give a:

$$
\angles{-}^\CC : T_{\alpha \to \FF_E(\beta)} \to K_{D(\alpha \to \FF_E(\beta))}
$$

by:

$$
\angles{M}^\CC_\Gamma = \sem{M}
$$

The semantic label maps must be weakly monotonic. That is a condition that
our maps satisfy: whenever we have $M \to^* N$, then
by~\ref{obs:denotation-soundness} the denotations $\sem{M}$ and $\sem{N}$
will be equal, therefore $\sem{M} \ge \sem{N}$.

We have now built up enough structure to correctly label our IDTS with
denotations. Let us start with the alphabet.

\begin{definition}
  Let $\Sigma = (\BB, \XX, \FF, \ZZ)$ be the alphabet of an IDTS
  $(\Sigma, \RR)$, $M$ a ($V+\Sigma$)-algebra and $S_f$ the chosen semantic
  label sets. The \demph{alphabet of the labelled IDTS}
  $(\overline{\Sigma}, \overline{\RR})$ is the IDTS alphabet
  $\overline{\Sigma} = (\BB, \XX, \overline{\FF}, \ZZ)$ where:

  \begin{itemize}
  \item For every symbol $f \in \FF_{\alpha_1,\ldots,\alpha_n,\beta}$ and
    for every label $p$ in $S_f$, we will have
    $f^p \in \overline{\FF}_{\alpha_1,\ldots,\alpha_n,\beta}$.
  \end{itemize}
\end{definition}

To complete our new IDTS, we will also have to transform the rules, so we
will need a way to label metaterms.

\begin{definition}
  Let $\phi : Z \to T$ be a term-generated assignment with
  $\phi = \bangop \circ \theta$. The \demph{labelling map}
  $\phi^\Label : M_\Sigma Z \to M_{\overline{\Sigma}} Z$ is the arrow in
  $(\SetC^\ContextC)^\BB$ defined by:
  
  \begin{align*}
    \phi^\Label_{\tau,\Gamma}(x) &= x \\
    \phi^\Label_{\tau,\Gamma}(Z_{\alpha_1,\ldots,\alpha_n,\beta}(t_1, \ldots, t_n))
    &= Z(\phi^\Label_{\alpha_1,\Gamma}(t_1), \ldots, \phi^\Label_{\alpha_n,\Gamma}(t_n)) \\
    \phi^\Label_{\tau,\Gamma}(f([\vec{x_1}] t_1, \ldots, [\vec{x_n} t_n]))
    &= f^{\angles{\bangop\theta^*(t_1), \ldots, \bangop\theta^*(t_n)}^f_\Gamma}([\vec{x_1}] \phi^\Label_{\beta_i,(\Gamma,\vec{x_1} :
      \vec{\alpha_1})}(t_1), \ldots,
      [\vec{x_n}] \phi^\Label_{\beta_n,(\Gamma,\vec{x_n} : \vec{\alpha_n})}(t_n))
  \end{align*}

  where
  $f \in F_{\vec{\alpha_1} \To \beta_1, \ldots, \vec{\alpha_n} \To \beta_n,
    \tau}$.
\end{definition}

The labelling map traverses an IDTS metaterm and replaces unlabelled
function symbols from $\FF$ with labelled ones from $\overline{\FF}$.  Note
that the term-generated assignment is not used to rewrite the
metavariables: the assignment has values in the carrier presheaf of our
($V+\Sigma$)-algebra and it can therefore be something completely different
than an IDTS term. The term-generated assignment
$\phi = \bangop \circ \theta$ is only used when labelling a function
symbol. The IDTS valuation $\theta$ is used to replace the metavariables in
all of the arguments with some specific terms and the resulting IDTS terms
are then interpreted in our algebra $\TT$ using $\bangop$ (which simply
turns them into $\banana{\lambda}$ terms). These interpretations are then
given as arguments to the semantic label map $\angles{-}^f$ which chooses a
label from the label set. Note also that there is no case for bare
abstraction ($[x] t$). In the theory of higher-order semantic labelling
presented in~\cite{hamana2007higher}, the IDTS is assumed to not contain
any bare abstractions: abstractions should always be arguments to function
symbols. This is the case in our IDTS $\banana{\lambda}_\tau$.

Knowing how to label metaterms, we can now label the rules of an
IDTS.

\begin{definition}
  Given an IDTS $(\Sigma, \RR)$, a $(V+\Sigma)$-algebra $M$ and a choice of
  semantic label sets $S_f$ and maps $\angles{-}^f$, we define the
  \demph{rules of the labelled IDTS} $(\overline{\Sigma}, \overline{\RR})$
  with:

  \begin{itemize}
  \item
    $\overline{\RR} = \{ \phi^\Label_{\tau,\emptyset}(l) \to
    \phi^\Label_{\tau,\emptyset}\mid l \to r : \tau \in \RR,
    \text{term-generated assignment } \phi : Z \to M \}$
  \end{itemize}
\end{definition}

The labelled IDTS will multiply the number of rules. For every possible
IDTS valuation of the free metavariables of a rule, there will be a new
rule in which the function symbols have been labelled using the
interpretations of their arguments. As we have done
in~\ref{ssec:banana-idts}, we will have to show that termination of this
new labelled system gives us termination of the unlabelled one. This is the
object of the principal result in~\cite{hamana2007higher} (Theorem~3.7):

\begin{theorem}\label{thm:semantic-labelling}
  (\demph{Higher-order semantic labelling})

  Let $M$ be a quasi-model for an IDTS $(\Sigma, \RR)$ and
  $(\overline{\Sigma}, \overline{\RR})$ the labelled IDTS with respect to
  $M$. Then $(\Sigma, \RR)$ is terminating if and only if
  $(\overline{\Sigma}, \overline{\RR} \cup \Decr)$ is terminating.
\end{theorem}

\begin{definition}
  Given a labelled IDTS alphabet $\overline{\Sigma}$ with semantic label
  sets $S_f$, the rules of the IDTS $(\overline{\Sigma}, \Decr)$ (called
  \demph{decreasing rules}) consist of:

  $$
  f^p([\vec{x_1}] t_1, \ldots, [\vec{x_n}] t_n) \longrightarrow f^q([\vec{x_1}] t_1, \ldots, [\vec{x_n}] t_n)
  $$

  where
  $f \in F_{\vec{\alpha_1} \To \beta_1, \ldots, \vec{\alpha_n} \To \beta_n,
    \gamma}$ and $p >_{S_f} q$.
\end{definition}

The decreasing rules allow us to freely adjust the labels on function
symbols to fit rewrite rules as long as we do not increase them.


\subsubsection{Verifying the General Schema}
\label{sssec:general-schema-2}

Now we will retrace the steps we have carried out
in~\ref{ssec:termination-for-idts}, this time with our semantically
labelled system $\labidts$.

\begin{enumerate}
  \item every constructor is positive
  \item no left-hand side of rule is headed by a constructor
  \item both $>_\BB$ and $>_\FF$ are well-founded
  \item $stat_f = stat_g$ whenever $f =_\FF g$
\end{enumerate}

First we have to check off the assumptions (A.1) through (A.4), repeated
above. The constructors of $\labidts$ are the same as the ones in
$\idts$. This means that the induced ordering $>_\BB$ is the same as before
and it is therefore still well-founded, so we have the first half of (A.3).
Since $>_\BB$ is still the same, then so is $=_\BB$, which is used in the
definition of positive constructors. The constructors are therefore still
positive as well and we get (A.1). The labelling of the function symbols
never did not turn any non-constructor into a constructor and so (A.2)
still holds as well.

To verify the second half of (A.3) and (A.4), we will need to investigate
the ordering on function symbols $>_\FF$ and it is here that we will reap
the benefits of our labelling. We need to give a well-founded partial order
$\ge_\FF$ on the function symbols such that whenever we have a rule
$f(\vec{l}) \to r$, then $f \ge_\FF g$ for all function symbols $g$
occurring in $r$. We propose the following relation:

\begin{itemize}
\item $\banana{}^p_{\op{op}_1, \ldots, \op{op}_n, \gamma, \delta, E, E'}
  >_\FF \banana{}^q_{\op{op}_1, \ldots, \op{op}_n, \gamma, \delta, E, E'}$
  if $p >_{S_{\banana{}}} q$
\item $\banana{}_{\op{op}_1, \ldots, \op{op}_n} > \op{op}_i$
\item $\banana{} > \aps$
\item $\banana{} > \lambda$
\item $\CC^p_{\alpha,\beta,E} >_\FF \CC^q_{\alpha,\beta,E}$ if
  $p >_{S_\CC} q$
\item $\CC > \op{op}$
\item $\CC > \eta$
\item $\CC > \lambda$
\end{itemize}

Whenever we elide indices in the above (for labels, types or the operations
in a handler), we assume that they are universally quantified over. This
relation is indeed a well-founded strict partial order: $\aps$, $\op{op}$,
$\eta$ and $\cherry$ are minimal elements and decreasing chains of
$\banana{}$ or $\CC$ symbols are all finite since the underlying semantic
label set orderings $>_{S_f}$ are well-founded.

As last time, we validate (A.4) because $f =_\FF g$ only if $f = g$. To
show that our well-founded ordering is the actual ordering from (A.3), we
need to check that for each rule $f(\vec{l}) \to r$, $f \ge_\FF g$ for all
function symbols $g$ occurring in $r$. We will go a step further and prove
that in our labelled IDTS, $f >_\FF g$.

We first check the rules in $\Decr$. These work out because $>_\FF$
contains the label ordering for both labelled function symbols, $\banana{}$
and $\CC$. Then we check the rules that correspond to reductions in
$\banana{\lambda}$, looking at either the original formulation on
Figure~\ref{fig:reductions} or the CRS/IDTS versions on
Figure~\ref{fig:tau-types}. For most of the rules, it is just a matter of
checking that only certain symbols appear in the right-hand sides of
certain rules. However, in rules $\banana{\op{op}}$, $\banana{\op{op}'}$
and $C_{\op{op}}$, we have the same (unlabelled) symbol on both the
left-hand side and the right-hand side of the rule. In all of these cases,
we will need to prove that the label on the left-hand side occurrence is
greater than the label on the right-hand side occurrence.

We will start with the rules $\banana{\op{op}}$ and $\banana{\op{op}'}$.

\begin{align*}
  \ap{\cibanana^p}{(\ap{\ap{\op{op}_j}{N_{\mathrm{p}}}}{(\lam{x}{N_{\mathrm{c}}})})}
  & \to \ap{M_j}{\ap{N_{\mathrm{p}}}{(\lam{x}{\ap{\cibanana^q}{N_{\mathrm{c}}}})}}
  & \text{ where $j \in I$} \\
  \ap{\cibanana^p}{(\ap{\ap{\op{op}_j}{N_{\mathrm{p}}}}{(\lam{x}{N_{\mathrm{c}}})})}
  &\to \ap{\op{op}_j}{\ap{N_{\mathrm{p}}}{(\lam{x}{\ap{\cibanana^q}{N_{\mathrm{c}}}})}}
  & \text{ where $j \notin I$}
\end{align*}

In both cases, the $\banana{}$ on the left-hand side is applied to
$\Gamma \vdash \app{\op{op}_j}{N_\petitp}{(\lam{x}{N_\petitc})} :
\FF_E(\gamma)$ whereas the $\banana{}$ on the right-hand side is applied to
$\Gamma, x : \beta_j \vdash N_\petitc : \FF_E(\gamma)$ where
$\typedopg{\op{op}_j}{\alpha_j}{\beta_j} \in E$. The label $p$ of the left
$\banana{}$ will be the denotation
$\sem{\app{\op{op}_j}{N_\petitp}{(\lam{x}{N_\petitc})}}$ whereas the label
$q$ of the right $\banana{}$ will be the denotation $\sem{N_\petitc}$.

The ordering on these labels is the $>_{D(\FF_E(\gamma))}$ ordering. For
the first to be greater than the second, we will need to prove for all
$e \in \sem{\Gamma}$ and all $d \in \sem{\beta_j}$ that
$\sem{\app{\op{op}_j}{N_\petitp}{(\lam{x}{N_\petitc})}}(e)
>_{\sem{\FF_E(\gamma)}} \sem{N_\petitc}(\subst{e}{x}{d})$.

$$
\sem{\app{\op{op}_j}{N_\petitp}{(\lam{x}{N_\petitc})}}(e) =
\op{op}_j(\sem{N_\petitp}(e), \lam{X}({\sem{N_\petitc}}(\subst{e}{x}{X})))
$$

From the definition of $>_{\sem{\FF_E(\gamma)}}$, we know that for all
$d \in \sem{\beta_j}$,
$\op{op}_j(\sem{N_\petitp}(e), \lam{X}({\sem{N_\petitc}}(\subst{e}{x}{X})))
>_{\sem{\FF_E(\gamma)}} \sem{N_\petitc}(\subst{e}{x}{d})$ which is exactly
what we wanted to show.

Now we look at the $C_{\op{op}}$ rule.

$$
\ap{\CC^p}{(\lam{x}{\app{\op{op}}{M_\petitp}{(\lam{y}{M_\petitc})}})}
\to \app{\op{op}}{M_\petitp}{(\lam{y}{\ap{\CC^q}{(\lam{x}{M_\petitc})}})}
$$

On the left-hand side, $\CC$ is applied to
$\Gamma \vdash \lam{x}{\app{\op{op}}{M_\petitp}{(\lam{y}{M_\petitc})}} :
\gamma \to \FF_E(\delta)$, and on the right-hand side, it is applied to
$\Gamma, y : \beta \vdash \lam{x}{M_\petitc} : \gamma \to \FF_E(\delta)$
where $\typedop{op}{\alpha}{\beta} \in E$. The label $p$ of the left $\CC$
is the denotation
$\sem{\lam{x}{\app{\op{op}}{M_\petitp}{(\lam{y}{M_\petitc})}}}$ while the
label $q$ of the right-hand side $\CC$ is $\sem{\lam{x}{M_\petitc}}$.

These labels are ordered by the $>_{D(\gamma \to \FF_E(\delta))}$ ordering
under which $p > q$ if for all $e \in \sem{\Gamma}$ and all
$d \in \sem{\beta}$, we have
$p(e) >_{\sem{\gamma \to \FF_E(\delta)}} q(\subst{e}{y}{d})$. Then to show
that $p(e) >_{\sem{\gamma \to \FF_E(\delta)}} q(\subst{e}{y}{d})$, we will
need to show that they are both functions and that for all
$c \in \sem{\gamma}$, we have
$p(e)(c) >_{\FF_E(\delta)} q(\subst{e}{y}{d})(c)$.

\begin{align*}
  \sem{\lam{x}{\app{\op{op}}{M_\petitp}{(\lam{y}{M_\petitc})}}}(e)(c)
  &= (\lam{X}{(\sem{\app{\op{op}}{M_\petitp}{(\lam{y}{M_\petitc})}}(\subst{e}{x}{X}))})(c) \\
  &= \sem{\app{\op{op}}{M_\petitp}{(\lam{y}{M_\petitc})}}(\subst{e}{x}{c}) \\
  &= \op{op}(\sem{M_\petitp}(\subst{e}{x}{c}), \lam{Y}{(\sem{M_\petitc}(\substt{e}{x}{c}{y}{Y}))}) \\
  \sem{\lam{x}{M_\petitc}}(\subst{e}{y}{d})(c)
  &= (\lam{X}{(\sem{M_\petitc}(\substt{e}{y}{d}{x}{X}))})(c) \\
  &= \sem{M_\petitc}(\substt{e}{y}{d}{x}{c}) \\
  &= \sem{M_\petitc}(\substt{e}{x}{c}{y}{d})
\end{align*}

We elaborate both of the expressions. The last step in rewriting
$\sem{\lam{x}{M_\petitc}}(\subst{e}{y}{d})(c)$ is due to
$\substt{e}{x}{X}{y}{Y} = \substt{e}{y}{Y}{x}{X}$ for distinct variables
$x$ and $y$. From the definition of $>_{\FF_E(\delta)}$, we get that for
all $d \in \sem{\beta}$,
$\op{op}(\sem{M_\petitp}(\subst{e}{x}{c}),
\lam{Y}{(\sem{M_\petitc}(\substt{e}{x}{c}{y}{Y}))}) >
(\sem{M_\petitc})(\substt{e}{x}{c}{y}{d})$, which is exactly what we need.

With this, we have validated the second half of (A.3) and therefore checked
all of the assumptions. We now need to check the schema itself, which
demands that the right-hand side of any rule is included in the computable
closure of the left-hand side. As we have remarked previously, this can be
simplified into saying that the metavariables appearing in the right-hand
side must be accessible in the left-hand side and that all recursive calls
from a symbol $f$ to a symbol $g$ with $f =_\FF g$ must be made to smaller
arguments. We have already verified the accessibility condition for the
unlabelled system $\idts$ and the labelling does not affect it. When it
comes to comparing the size of arguments in recursive calls, this was the
critical point in~\ref{ssec:termination-for-idts} that forced us to use
semantic labelling. However, now this step is trivial because in
$\labidts$, there is no rule $f(\vec{l}) \to r$ such that some $g =_\FF f$
occurs in $r$. We have already paid the burden of proof for this in giving
the semantic labelling and proving that the induced $>_\FF$ ordering is
well-founded.

\begin{theorem}\label{thm:labidts-termination}
  (\demph{Termination of $\labidts$})

  The reduction relation induced by the labelled IDTS $\labidts$ is
  terminating\footnote{This result can be extended to $\banana{\lambda}$
    with sums and products. The pair construction $\left<-,-\right>$ and
    the injections $\inl$ and $\inr$ will be the constructors for
    $\alpha \times \beta$ and $\alpha + \beta$, respectively, with
    $\alpha <_\BB \alpha \times \beta$, $\beta <_\BB \alpha \times \beta$,
    $\alpha <_\BB \alpha + \beta$ and $\beta <_\BB \alpha + \beta$. All of
    the rules defining case analysis and projections $\pi_1$ and $\pi_2$
    satisfy the General Schema.}.
\end{theorem}

\begin{proof}
  Proof given above by the application of the General Schema presented
  in~\cite{blanqui2000termination}.
\end{proof}

\begin{corollary}\label{cor:idts-termination}
  (\demph{Termination of $\idts$})

  The reduction relation induced by the IDTS $\idts$ is terminating.
\end{corollary}

\begin{proof}
  By Theorem~\ref{thm:labidts-termination} and
  Theorem~\ref{thm:semantic-labelling}.
\end{proof}

\begin{corollary}\label{cor:intcalc-termination}
  (\demph{Termination of $\intcalc$})
  
  The reduction relation of $\banana{\lambda}$ without $\eta$-reduction is
  terminating.
\end{corollary}

\begin{proof}
  By Corollary~\ref{cor:idts-termination} and
  Lemma~\ref{lem:banana-tau-termination}.
\end{proof}


\subsection{Putting $\eta$ Back in $\banana{\lambda}$}
\label{ssec:termination-eta}

We have shown termination for $\intcalc$. We know that the $\eta$-reduction
on $\calc$ is terminating: it decreases the number of $\lambda$
abstractions in the term by one in each step. We would now like to show
that the combination of $\intcalc$ and $\eta$ is terminating as well.

Note that we could not have used the General Schema to prove that $\calc$
with $\eta$ is terminating. The General Schema does not admit
$\eta$-reduction. The left-hand side of every rule needs to be headed by a
function symbol which is not a contructor. If we tried declaring that
$\lambda$ is not a constructor, we would run into problems with the notion
of accessibility. When accessing the metavariables of the left-hand side of
a rule, we can access all of the arguments of a constructor but we can only
access the arguments of a non-constructor symbol that have a basic
type. The type of the argument of $\lambda_{\alpha,\beta}$ is
$\alpha \To \beta$ and so we could not access the arguments of $\lambda$ in
our rules (which would break the $\beta$ rule, $\eta$ rule and the $\CC$
rules).

Termination is generally not a modular property of higher-order rewriting
systems~\cite{appel2010higher}. Our plan will be to show that
$\eta$-reduction does not interfere with the rewrite rules of
$\intcalc$. Then we will be able to take any reduction chain in $\calc$ and
pull out from it a chain which only uses rules from $\intcalc$. Since this
chain must be finite due to the termination of $\intcalc$, we will have a
proof of finiteness for the reduction chain in $\calc$.

\begin{definition}
  An \demph{n-ary evaluation context $C^n$} is a $\banana{\lambda}$ term
  in which $n$ disjoint subterms have been replaced with the symbol
  $[]$. We write $C^n[M]$ for the term in which all of the occurrences of
  the symbol $[]$ have been replaced with $M$.
\end{definition}

\begin{lemma}\label{lem:eta-exchange}
  (\demph{Exchanging $\eta$ with $\intcalc$})

  For every well-typed reduction chain $s \to_\eta t \to_\intcalc u$, there
  exists a well-typed reduction chain $s \to^+_\intcalc t' \to^*_\eta u$.
\end{lemma}

\begin{proof}
  We will consider all the possible relative positions of the contractum of
  the first reduction and the redex for the second reduction within $t$.
  
  \begin{itemize}
  \item Assume the two are disjoint, i.e.\ $s = C[M,N]$, $t = C[M',N]$ with
    $M \to_\eta M'$ and $u = C[M',N']$ with $N \to_\intcalc N'$. Then we
    can easily reorder the two reductions, producing the chain
    $C[M,N] \to_\intcalc C[M,N'] \to_\eta C[M',N']$.
  \item Assume that the contractum of the first reduction contains the
    redex for the second reduction, i.e.\ $s = C[M]$, $t = C[D[N]]$ with
    $M \to_\eta D[N]$ and $u = C[D[N']]$ with $N \to_\intcalc N'$. Since
    $M$ is an $\eta$-redex, $M = \lam{x}{\ap{D[N]}{x}}$. We can now build
    the chain
    $C[\lam{x}{\ap{D[N]}{x}}] \to_\intcalc C[\lam{x}{\ap{D[N']}{x}}]
    \to_\eta C[D[N']]$.
  \item Assume that the redex for the second reduction contains the
    contractum of the first reduction, i.e.\ $s = C[D[M]]$, $t = C[D[M']]$
    with $M \to_\eta M'$ and $u = C[N']$ with $D[M'] \to_\intcalc N'$. Let
    $R$ be the rule used in $D[M'] \to_\intcalc N$. We will now distinguish
    two scenarios:

    \begin{itemize}
    \item The occurrence of $M'$ in $D[M']$ is matched by a metavariable in
      the left-hand side of rule $R$.
      
      The $R$-redex $N'$ of $D[M']$ will be a term $E^n[M',\ldots,M']$
      where $E^n$ is an $n$-ary context for some $n$ which depends on the
      rule $R$ and the metavariable that was matched\footnote{Rules like
        $\banana{\eta}$ can delete metavariables ($n = 0$ for the
        metavariable $M_\eta$), while others, like $\banana{\op}$, can copy
        them ($n = 2$ for the variable $M_j$)}. Furthermore, we can replace
      $M'$ with any other term of the same type and the reduction will
      still go through, e.g.\ notably $D[M] \to_R E^n[M,\ldots,M]$. We can
      now build our chain
      $C[D[M]] \to_\intcalc C[E^n[M,\ldots,M]] \to^*_\eta
      C[E^n[M',\ldots,M']] = C[N']$.
      
    \item The occurrence of $M'$ in $D[M']$ is not matched by a
      metavariable.
      
      $M'$ is an $\eta$-contractum and must therefore have a function
      type. If we investigate the left-hand sides of all the rewriting
      rules in $\intcalc$ and search for terms that have a function type,
      we end up with\footnote{The case of $D = []$ is not considered,
        because it is covered by the case where the contractum of the first
        reduction containts the redex of the second reduction.}:

      \begin{itemize}
      \item $D = \ap{[]}{N}$ and $R = \beta$
      \item $D = \ap{\CC}{[]}$ and $R = \CC_{\op{op}}$ or $R = \CC_\eta$
      \end{itemize}
      
      We note that in all of these rules, the symbol which replaces $[]$
      must be a $\lambda$-abstraction. Therefore, if $D[M'] \to_R N$, then
      $M' = \lam{x}{M''}$. From $M \to_\eta M'$, we also know that
      $M = \lam{x}{\ap{M'}{x}}$. Since we were $\eta$-expanding a
      $\lambda$-abstraction, we can replace this step by a
      $\beta$-reduction:
      $M = \lam{x}{\ap{(\lam{x}{M''})}{x}} \to_\beta \lam{x}{M''} =
      M'$. The $\beta$ rule is a part of $\intcalc$ and so we can now build
      the chain $C[D[M]] \to_\intcalc C[D[M']] \to_\intcalc C[N']$.
    \end{itemize}
  \end{itemize}
\end{proof}

\begin{lemma}\label{lem:pulling-links}
  (\demph{Pulling an $\intcalc$ link from a $\calc$ chain})
  
  Let $t_1 \to t_2 \to \ldots$ be an infinite reduction chain in
  $\calc$. Then there exists another infinite reduction chain
  $u_1 \to u_2 \to \ldots$ in $\calc$ and $t_1 \to_\intcalc u_1$.
\end{lemma}

\begin{proof}
  The goal of this lemma is to show that we can find an $\intcalc$ link in
  every infinite $\calc$ and move it to the beginning of the chain.

  An infinite chain in $\calc$ must use a rule from $\intcalc$, otherwise
  it would be an $\eta$ chain and those cannot be infinite since $\eta$ is
  terminating.
  
  Let $t_k \to t_{k+1}$ be the first link in the chain that uses a rule
  from $\intcalc$. We will prove this lemma by induction on $k$.
  
  If $k = 1$, then we give the chain $t_2 \to t_3 \to \ldots$ which also
  uses rules from $\intcalc$ infinitely often and which satisfies
  $t_1 \to_\intcalc t_2$.
  
  If $k > 1$, then we replace the segment
  $t_{k-1} \to_\eta t_k \to_\intcalc t_{k+1}$ with the segment
  $t_{k-1} \to^+_\intcalc t_k \to^*_\eta t_{k+1}$ using
  Lemma~\ref{lem:eta-exchange}. By induction hypothesis, the chain
  $t_1 \to \ldots \to t_{k-1} \to^+_\intcalc t_k \to^*_\eta t_{k+1} \to
  t_{k+2} \to \ldots$ gives us the necessary chain $u_1 \to u_2 \to \ldots$
  with $t_1 \to_\intcalc u_1$.
\end{proof}

\begin{theorem}\label{thm:termination}
  (\demph{Termination of $\banana{\lambda}$})
  
  The reduction relation $\to$ on $\banana{\lambda}$ terms given by the
  rules in Figure~\ref{fig:reductions} is terminating.
\end{theorem}

\begin{proof}
  We will prove this theorem by contradiction. Let $t_1 \to t_2 \to \ldots$
  be an infinite reduction chain in $\calc$. Since we have an infinite
  chain in $\calc$, we can iterate Lemma~\ref{lem:pulling-links} to get an
  infinite sequence of chains such that the first element of every chain
  reduces via $\intcalc$ to the first element of the next chain in the
  sequence. The first elements of these chains form an infinite reduction
  chain $\intcalc$, which is in contradiction with the termination of
  $\intcalc$.
\end{proof}

\begin{theorem}\label{thm:strong-normalization}
  (\demph{Strong normalization of $\calc$})
  
  There are no infinite reduction chains in $\calc$ and all maximal
  reduction chains originating in a $\calc$ term $M$ terminate in the same
  term, the normal form of $M$.
\end{theorem}

\begin{proof}
  The lack of infinite reduction chains is due to termination of $\calc$
  (Theorem~\ref{thm:termination}) and the fact that all maximal reduction
  chains lead to the same term is entailed by confluence of $\calc$
  (Theorem~\ref{thm:confluence}).
\end{proof}
