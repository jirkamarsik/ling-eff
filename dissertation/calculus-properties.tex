\chapter{Properties}
\label{chap:properties}


\section{Algebraic Properties}
\label{sec:algebraic-properties}


\section{Subject Reduction}


\section{Confluence}
\label{sec:confluence}

The object of our study during this section will be the proof of the
\emph{confluence property} of $\banana{\lambda}$.

\begin{definition}
  A reduction relution $\to$ on a set $A$ is said to be \demph{confluent}
  whenever for each $a,b,c \in A$ such that $a \to b$ and $a \to c$ there
  is a $d \in A$ such that $b \tto d$ and $c \tto d$.
\end{definition}

\begin{theorem}\label{thm:confluence}
  \demph{Confluence of $\banana{\lambda}$}
  
  The reduction relation $\to$, defined by the reduction rules
  in~\ref{sec:reductions}, on the set of $\banana{\lambda}$ terms is
  confluent.
\end{theorem}

Proofs of this property are often mechanical and follow the same
pattern. Our strategy will be to reuse a general result which applies one
such proof for a general class of rewriting systems. Our rewriting system
is a system of reductions on terms and the reductions have side conditions
concerning the binding of free variables. A good fit for this kind of
system are the Combinatory Reduction Systems (CRSs) of
Klop~\cite{klop1993combinatory}.

The main result about CRSs that we will make use of is the following
(Corollary~13.6 in~\cite{klop1993combinatory}).

\begin{theorem}\label{thm:confluence-crs}
  \demph{Confluence of orthogonal CRSs}

  All orthogonal CRSs are confluent.
\end{theorem}

The rest of this section will go like this:
\begin{itemize}
\item First, we define Combinatory Reduction Systems.
\item Next, we show that our reduction relation can be coded as a CRS.
\item Afterwards, we explain the orthogonality condition.
\item Finally, we verify whether orthogonality holds for our CRS.
\end{itemize}


\subsection{Combinatory Reduction Systems}
\label{ssec:crs}

A Combinatory Reduction System is defined by an alphabet and a set of
rewriting rules. We will first cover the alphabet.

\begin{definition}
  A \demph{CRS-alphabet} consists of:
  \begin{itemize}
  \item a set $\Var$ of \emph{variables} (written lower-case as $x$, $y$,
    $z$,\ldots)
  \item a set $\MVar$ of \emph{metavariables} (written upper-case as $M$,
    $N$, \ldots), each with is own arity
  \item a set of \emph{function symbols}, each with its own arity
  \end{itemize}
\end{definition}

Let us sketch the difference between the variables in $\Var$ and the
metavariables in $\MVar$. The variables in $\Var$ are the variables of the
object-level terms, in our case it will be the variables of
$\banana{\lambda}$. The variables in $\MVar$ are the metavariables that
will occur in our reduction rules and which we will have to instantiate in
order to derive specific application of those rules. In other words, the
variables in $\Var$ are there to express the binding structure within the
terms being reduced and the metavariables in $\MVar$ are there to stand in
for specific terms when applying a reduction rule.

\begin{definition}
  The \demph{metaterms} of a CRS are given inductively:
  \begin{itemize}
  \item variables are metaterms
  \item if $t$ is a metaterm and $x$ a variable, then $[x]t$ is a metaterm
    called \emph{abstraction}
  \item if $F$ is an $n$-ary function symbol and $t_1$,\ldots,$t_n$ are
    metaterms, then $F(t_1,\ldots,t_n)$ is a metaterm
  \item if $M$ is an $n$-ary metavariable and $t_1$,\ldots,$t_n$ are
    metaterms, then $M(t_1,\ldots,t_n)$ is a metaterm
  \end{itemize}
\end{definition}

\begin{definition}
  The \demph{terms} of a CRS are its metaterms which do not contain any
  metavariables.
\end{definition}

To finish the formal introduction of CRSs, we give the definition of a CRS
reduction rule.

\begin{definition}
  A \demph{CRS-reduction rule} is a pair of metaterms $s \to t$ such that:
  \begin{itemize}
  \item $s$ and $t$ are both closed, i.e.\ all variables are bound using
    the $[\_]\_$ binder
  \item $s$ is of the form $F(t_1,\ldots,t_n)$
  \item all the metavariables that occur in $t$ also occur in $s$
  \item any metavariable $M$ that occurs in $s$ only occurs in the form
    $M(x_1,\ldots,x_k)$, where $x_i$ are pairwise distinct variables
  \end{itemize}
\end{definition}

\begin{definition}
  A \demph{Combinatory Reduction System (CRS)} is a pair of a CRS-alphabet
  and a set of CRS-reduction rules.
\end{definition}

We will only sketch the way that a CRS gives rise to a reduction relation
and we will direct curious readers to Sections~11 and 12 of
$\cite{klop1993combinatory}$.

When we instantiate the metavariables in a CRS rule, we use a
\emph{valuation} that assigns to every $n$-ary metavariable a term with
holes labelled from 1 to $n$. The instantiation of $M(t_1,\ldots,t_n)$ then
replaces the metavariable $M$ by the term with holes and fills the holes
labelled $1,\ldots,n$ with the terms $t_1,\ldots,t_n$ respectively.

The crucial detail is that in a particular context, a metavariable can only
be instantiated with terms $M$ that do not contain any free variables bound
in that context. This means that for the instantiation of $M$ to contain a
variable bound in the context, $M$ must explicitly take that variable as an
argument. All other variables not explicitly declared can therefore be
safely assumed to not occur freely within.

Consider the following examples of $\beta$ and $\eta$ reduction.

\begin{align*}
  \ap{(\lam{x}{M(x)})}{N} & \to M(N) \\
  \lam{x}{\ap{N}{x}} & \to N
\end{align*}

More formally written as:

\begin{align*}
  @(\lambda([x]M(x)),N) & \to M(N) \\
  \lambda([x]@(N,x)) & \to N
\end{align*}

where $\lambda$ is a unary function symbol and $@$ is a binary function
symbol. In both of the versions, $M$ is a unary metavariable and $N$ is a
nullary metavariable. In the rule for $\beta$-reduction, we can observe how
the idea of instantiating metavariables by terms with holes lets us express
the same idea for which we had to introduce the meta-level operation of
substitution. In the rule for $\eta$-reduction, we see that $N$ appears in
a context where $x$ is bound but it does not have $x$ as one of its
arguments. Therefore, it will be impossible to instantiate $N$ in such a
way that it contains a free occurrence of $x$. In both of those rules, we
were able to get rid of meta-level operations (substitution) and conditions
($x \notin FV(N)$) and have them both implemented by the formalism itself.


\subsection{$\banana{\lambda}$ as a CRS}
\label{ssec:banana-as-crs}

We will now see how to rephrase the reduction rules of our calculus in
order to fit in to the CRS framework. We have already seen how to translate
the $\beta.\to$ and $\eta.\to$ rules in the previous subsection. The next
rules to address are the rules defining the semantics of the $\banana{}$
handlers.

We will repeat the rules for handlers to make the issue at hand clear.

\begin{tabular}{lr}
  $\ap{\cibanana}{(\ap{\eta}{N})} \to$ & rule $\banana{\eta}$ \\
  $\ap{M_\eta}{N}$ & \\
  \\
  $\ap{\cibanana}{(\ap{\ap{\op{op}_j}{N_{\mathrm{p}}}}{(\lam{x}{N_{\mathrm{c}}})})} \to$ & rule $\banana{\op{op}}$ \\
  $\ap{M_j}{\ap{N_{\mathrm{p}}}{(\lam{x}{\ap{\cibanana}{N_{\mathrm{c}}}})}}$
  & where $j \in I$ \\
  & and $x \notin \FV((M_i)_{i \in I}, M_\eta)$ \\
  \\
  $\ap{\cibanana}{(\ap{\ap{\op{op}_j}{N_{\mathrm{p}}}}{(\lam{x}{N_{\mathrm{c}}})})} \to$ & rule $\banana{\op{op}'}$ \\
  $\ap{\op{op}_j}{\ap{N_{\mathrm{p}}}{(\lam{x}{\ap{\cibanana}{N_{\mathrm{c}}}})}}$
  & where $j \notin I$ \\
  & and $x \notin \FV((M_i)_{i \in I}, M_\eta)$
\end{tabular}

\TODO{Make sure later that the form of these rules in the Definitions
  chapter is the same as the one above.}

The syntax of CRSs does not allow us to use the $(\onto{\op{op}_i}{M_i})_{i
  \in I}$ notation nor capture the $j \in I$ or $j \notin I$ conditions.
The symbols $\op{op}_i$ are problematic as well, since technically, they
are not pure $\banana{\lambda}$ syntax but metavariables standing in for
operation symbols.

We do away with all of the above problems by expanding these meta-notations
and adding a separate rule for every possible instantiation of the
schema. This means that for each sequence of distinct operation symbols
$\op{op}_1$,\ldots,$\op{op}_n$, we end up with:
\begin{itemize}
\item a special rewriting rule
  $\ap{\banana{\onto{\op{op}_1}{M_1},\ldots,\onto{\op{op}_n}{M_n},\ 
    \onto{\eta}{M_\eta}}}{(\etaE{N})}
  \to \ap{M_\eta}{N}$
\item for every $1 \le i \le n$, a special rewriting rule \\
  $\ap{\banana{\onto{\op{op}_1}{M_1},\ldots,\onto{\op{op}_n}{M_n},\ 
    \onto{\eta}{M_\eta}}}{(\app{\op{op}_i}{N_{\mathrm{p}}}{(\lam{x}{N_{\mathrm{c}}(x)})})}
  \\ \to
  \app{M_i}{N_{\mathrm{p}}}{(\lam{x}{\ap{\banana{\onto{\op{op}_1}{M_1},\ldots,\onto{\op{op}_n}{M_n},\ \onto{\eta}{M_\eta}}}{N_{\mathrm{c}}(x)}})}$
\item for every $\op{op}' \in \EE \setminus \{\op{op}_i \| 1 \le i \le n\}$, a special
  rewriting rule \\
  $\ap{\banana{\onto{\op{op}_1}{M_1},\ldots,\onto{\op{op}_n}{M_n},\ 
    \onto{\eta}{M_\eta}}}{(\app{\op{op}'}{N_{\mathrm{p}}}{(\lam{x}{N_{\mathrm{c}}(x)})})}
  \\ \to
  \app{\op{op}'}{N_{\mathrm{p}}}{(\lam{x}{\ap{\banana{\onto{\op{op}_1}{M_1},\ldots,\onto{\op{op}_n}{M_n},\ \onto{\eta}{M_\eta}}}{N_{\mathrm{c}}(x)}})}$
\end{itemize}

The rule for the cherry $\cherry$ extraction operator is already in CRS
form, so all we have to do is address the rules for the $\CC$ operator. We
present them side-by-side in their original form and in CRS-style.

Original:
\begin{align*}
  \ap{\CC}{(\lam{x}{\ap{\eta}{M}})} & \to \ap{\eta}{(\lam{x}{M})} \\
  \ap{\CC}{(\lam{x}{\ap{\ap{\op{op}}{M_{\mathrm{p}}}}{(\lam{y}{M_{\mathrm{c}}})}})}
  & \to
  \ap{\ap{\op{op}}{M_{\mathrm{p}}}}{(\lam{y}{\ap{\CC}{(\lam{x}{M_{\mathrm{c}}})}})} \\
  & \mathrm{where\ } x \notin \FV(M_{\mathrm{p}})
\end{align*}

CRS-style:
\begin{align*}
  \ap{\CC}{(\lam{x}{\ap{\eta}{(M(x))}})} & \to \ap{\eta}{(\lam{x}{M(x)})} \\
  \ap{\CC}{(\lam{x}{\ap{\ap{\op{op}}{M_{\mathrm{p}}}}{(\lam{y}{M_{\mathrm{c}}(x,y)})}})}
  & \to \ap{\ap{\op{op}}{M_{\mathrm{p}}}}{(\lam{y}{\ap{\CC}{(\lam{x}{M_{\mathrm{c}}(x,y)})}})}
\end{align*}

We can see that the only difference is to replace ``simple'' metavariables
$M$, $M_{\mathrm{p}}$ and $M_{\mathrm{c}}$ with their higher-order
versions: the unary $M$, nullary $M_{\mathrm{p}}$ and binary
$M_{\mathrm{c}}$. We see that every CRS metavariable is applied to the
variables in scope, except for $M_{\mathrm{p}}$, which thus loses access to
the variable $x$. This way, the condition that $x$ must not appear free in
$M_{\mathrm{p}}$ is now encoded directly in the reduction rule itself.

In~\ref{ssec:crs}, we have said that a CRS is formed by a set of reduction
rules and by an alphabet. We have already seen all of the rules of our CRS
($\beta.\to$ and $\eta.\to$ were given at the end of~\ref{ssec:crs} and the
$\cherry$ rule is the same as the original one in~\ref{sec:reductions}). In
order to have a clear definition, all that remains is to identify the
alphabet.

The set of variables $Var$ is exactly the set of variables $\XX$ used in
the definition of $\banana{\lambda}$. The set of metavariables $MVar$
consists of the unary $M$, nullary $N$, nullary $N_{\mathrm{p}}$, unary
$N_{\mathrm{c}}$, nullary $M_{\mathrm{p}}$ and binary $M_{\mathrm{c}}$. The
set of function symbols is composed of the following:

\begin{itemize}
\item the binary symbol $@$ for function application
\item the unary symbol $\lambda$ for function abstraction
\item a nullary symbol for every constant in the signature $\Sigma$
\item the unary symbol $\eta$ for the injection operator
\item a binary symbol $\op{op}$ for every $\op{op} \in \EE$
\item a $(n+2)$-ary symbol
  $(\ap{\banana{\onto{\op{op}_1}{\_},\ \ldots,\ \onto{\op{op}_n}{\_},\ \onto{\eta}{\_}}}{\_})$
  for every sequence $\op{op}_1,\ldots,\op{op}_n$ of distinct symbols from
  $\EE$ of length $n$
\item the unary symbol $\cherry$ for the extraction operator
\item the unary symbol $\CC$ for the $\CC$ operator
\end{itemize}

In giving the CRS-style reduction rules above, we have used the ``native''
syntax of our calculus instead of writing out everything in terms of
function symbols. For clarity, we give the rules governing the relationship
of the two. We write:

\begin{itemize}
\item $@(t,u)$ as $\ap{t}{u}$
\item $\lambda([x]t)$ as $\lam{x}{t}$
\item $\eta(t)$ as $\etaE{t}$
\item $\op{op}(t_{\mathrm{p}},[x]t_{\mathrm{c}})$ as
  $\app{\op{op}}{t_{\mathrm{p}}}{(\lam{x}{t_{\mathrm{c}}})}$\footnote{Note
  that with this translation,
  $\app{\op{op}}{t_{\mathrm{p}}}{(\lam{x}{t_{\mathrm{c}}})}$ does not
  contain $\lam{x}{t_{\mathrm{c}}}$ as a subterm. This is the same as in
  our calculus, where the syntactic closure (see~\ref{sec:reductions}) does
  not identify $\lam{x}{t_{\mathrm{c}}}$, but rather $t_{\mathrm{c}}$, as a
  subterm of
  $\app{\op{op}}{t_{\mathrm{p}}}{(\lam{x}{t_{\mathrm{c}}})}$. This becomes
  important in our discussion of confluence since it makes it impossible to
  make the $\lambda$ disappear by something like $\eta$-reduction.}
\item
  $(\ap{\banana{\onto{\op{op}_1}{\_},\ \ldots,\ \onto{\op{op}_n}{\_},\ \onto{\eta}{\_}}}{\_})(t_1,\ldots,t_n,t_\eta,u)$
  as $\ap{\banana{\onto{\op{op}_1}{t_1},\ \ldots,\ \onto{\op{op}_n}{t_n},\ \onto{\eta}{t_\eta}}}{u}$
\item $\cherry(t)$ as $\ap{\cherry}{t}$
\item $\CC(t)$ as $\ap{\CC}{t}$
\end{itemize}

We have connected the terms of $\banana{\lambda}$ with CRS terms and we
have also expressed all of our reduction rules in terms of CRS reduction
rules. As in our calculus, CRS then proceeds to take a syntactic closure of
this redex-contractum relation. Our translation from $\banana{\lambda}$ to
a CRS also preserves subterms\footnote{More precisely, if $a$ is a subterm
  of $b$ in $\banana{\lambda}$ then the CRS version of $a$ is a subterm of
  the CRS version of $b$. In the other direction, whenever $a$ is a
  variable or a function-headed term which is a subterm of $b$ in the CRS
  version of $\banana{\lambda}$, then the corresponding $a$ in
  $\banana{\lambda}$ is a subterm of the corresponding $b$ (according to
  the notion of subterm inherent in the definition of syntactic closure).}
and so we end up constructing the same reduction relation.


\subsection{Orthogonal CRSs}
\label{ssec:orthogonal-crs}

In order to use Theorem~\ref{thm:confluence-crs}, we need to show that our
CRS is orthogonal, so let us start us by looking at what ``orthogonal''
means in the context of CRSs.

\begin{definition}
  A CRS is \demph{orthogonal} if it is non-overlapping and left-linear.
\end{definition}

We will need to satisfy two criteria: no overlaps and left linearity. We
will start with the latter.

\begin{definition}
  A CRS is \demph{left-linear} if the left-hand sides of all its reduction
  rules are linear. A CRS metaterm is \demph{linear} if no metavariable
  occurs twice within it.
\end{definition}

By going through the rules we have given in~\ref{ssec:banana-as-crs}, we
can see at a glance that no rule uses the same metavariable twice in its
left-hand side and so our CRS is indeed left-linear.

\begin{definition}
  A CRS is \demph{non-overlapping} if:
  \begin{itemize}
    \item Let $r = s \to t$ be some reduction rule of the CRS and let
      $M_1$,\ldots,$M_n$ be all the metavariables occurring in the
      left-hand side $s$. Whenever we can instantiate the metavariables in
      $s$ such that the resulting term contains a redex for some other rule
      $r'$, then said redex must be contained in the instantiation of one
      of the metavariables $M_i$.
    \item Similarly, whenever we can instantiate the metavariables in $s$
      such that the resulting term \emph{properly contains} a redex
      \emph{for the same rule $r$}, then that redex as well must be
      contained in the instantiation of one of the metavariables $M_i$.
  \end{itemize}
\end{definition}

In simpler words, no left-hand side of any rule can contain bits which look
like the top of the left-hand side of some other rule. Let us try and
verify this property in our calculus:
\begin{itemize}
\item The $\banana{}$ rules have no overlaps with any of the other
  rules. Their left-hand sides are constructed only of the $\banana{}$
  symbols and the $\op{op}$ and $\eta$ constructors. Since there is no
  reduction rule headed by $\op{op}$ and $\eta$, they have no overlap with
  any of the other rules. Furthermore, the three $\banana{}$ rules are
  mutually exclusive, so there is no overlap between themselves.
\item The $\cherry$ rule does not overlap with any of the other neither,
  since the left-hand side contains only $\cherry$ and $\eta$, and there is
  no reduction rule headed by $\eta$.
\item The $\CC$ rules are both mutually exclusives, so there is no overlap
  between the two. However, their left-hand sides are built out of not only
  $\CC$, $\op{op}$ and $\eta$, but also $\lambda$, for which there is the
  $\eta.\to$ reduction rule. Fortunately in this case, the $\CC$ rules only
  apply when the $\lambda$-abstraction's body is an $\eta$ expression or an
  $\op{op}$ expression, whereas the $\eta.\to$ rule applies only when the
  body is an application expression\footnote{This is not so much a
    fortunate conincidence but rather a deliberate choice in the design of
    the calculus.}. Therefore, there is no overlap.
\end{itemize}

We have established that all the reduction rules in our system are pairwise
non-overlapping \emph{except} for $\beta.\to$ and $\eta.\to$. However,
these two are notoriously overlapping.

We can instantiate the metavariables in the left-hand side of the
$\beta.\to$ rule to get a term which contains a $\eta$-redex which shares
the $\lambda$-abstraction with the $\beta$-redex.

$$
\ap{(\lam{x}{\ap{y}{x}})}{z}
$$

We can also instantiate the metavariables in the left-hand side of the
$\eta.\to$ rule to create a $\beta$-redex which shares the application with
the $\eta$-redex.

$$
\lam{x}{\ap{(\lam{z}{z})}{x}}
$$

Our CRS is therefore \emph{not} orthogonal. However, we can still make good
use of Theorem~\ref{thm:confluence-crs}.

\begin{lemma}\label{lem:confluence-int}
  \demph{Confluence of intensional $\banana{\lambda}$}

  The $\banana{\lambda}$ reduction systems without the $\eta.\to$ rule is
  confluent.
\end{lemma}

\begin{proof}
  If we exclude the $\eta.\to$ rule, we have a CRS which is left-linear and
  also non-overlapping\footnote{We know that $\beta.\to$ does not overlap
    any of the other rules. Neither does it overlap itself since its
    left-hand side does not have an application subexpression.}. Therefore,
  it is orthogonal and thanks to Theorem~\ref{thm:confluence-crs}, also
  confluent.
\end{proof}

\begin{lemma}\label{lem:confluence-eta}
  \demph{Confluence of $\eta$-reduction}

  The reduction system on $\banana{\lambda}$ terms containing only the
  $\eta.\to$ reduction rule is confluent.
\end{lemma}

\begin{proof}
  We have seen that $\eta.\to$ is a valid left-linear CRS rule. It also
  does not overlap itself since its left-hand side does not contain any
  $\lambda$ subexpression. The CRS consisting of just the $\eta.\to$ rule
  is therefore orthogonal and confluent.
\end{proof}


\subsection{Adding $\eta.\to$ Back to $\banana{\lambda}$}

We have shown that both $\banana{\lambda}$ without $\eta.\to$ and
$\eta.\to$ by itself are confluent. The reduction relation of the complete
$\banana{\lambda}$ calculus is the union of these two reduction
relations. Using the Lemma of Hindley-Rosen (Point~2 in Exercises~1.0.8
in~\cite{klop1992term}), we can show that this union is confluent by
showing that the two reduction relations commute together.

We will not even need to know the definition of commuting reductions, since
we will base our proof on an other result due to Hindley (Point~3 in
Exercises~1.0.8 in~\cite{klop1992term}).

\begin{lemma}\label{lem:commutativity}
  Let $\to_1$ and $\to_2$ be two reduction relations on the same set of
  terms $A$. Suppose that whenever there are $a,b,c \in A$ such that
  $a \to_1 b$ and $a \to_2 c$, there is also some $d \in A$ such that
  $b \tto_2 d$ and $c \to_1^= d$ (meaning $c \to_1 d$ or $c = d$). In that
  case, $\to_1$ commutes with $\to_2$.
\end{lemma}

We can use this to prove that $\banana{\lambda}$ commutes with the
$\eta.\to$ reduction rule.

\begin{lemma}\label{lem:eta-commutes}
  \demph{Commutativity of $\eta$ and $\banana{\lambda}_{-\eta}$}

  The reduction relations induced by $\eta$ and by the rest of the
  $\banana{\lambda}$ rules commute.
\end{lemma}

\begin{proof}
  We will prove this lemma by an appeal to
  Lemma~\ref{lem:commutativity}. Let $\to_\eta$ be the reduction relation
  induced by the rule $\eta.\to$ and $\to_{\banana{\lambda}}$ the reduction
  relation induced by all the other reduction rules in
  $\banana{\lambda}$. We need to prove that for all terms $a$, $b$ and $c$
  where $a \to_{\calc} b$ and $a \to_\eta c$, we have a term $d$ such that
  $b \tto_\eta d$ and $c \to_{\calc}^= d$.

  This will turn out to be a routine proof by induction on the structure of
  the term $a$. The base cases are trivial since terms without any proper
  subterms happen to have no redexes in our calculus and therefore
  trivially satisfy the criterion. In the inductive step, we will proceed
  by analyzing the relative positions of the redexes which led to the
  reductions $a \to_{\calc} b$ and $a \to_\eta c$.
  \begin{itemize}
  \item If both reductions occurred within a common subterm of $a$, i.e.\
    $a = C[a']$, $b = C[b']$ and $c = C[c']$ while at the same time
    $a' \to_{\calc} b'$ and $a' \to_\eta c'$: We can use the induction
    hypothesis for $a'$. This gives us a $d'$ such that $b' \tto_\eta d'$
    and $c' \to_{\calc}^= d'$ and therefore we also have $d = C[d']$ with
    $b \tto_\eta d$ and $c \to_{\calc}^= d$.
  \item If both reductions occurred within non-overlapping subterms of $a$,
    i.e.\ $a = C[a_1, a_2]$, $b = C[b', a_2]$ and $c = C[a_1, c']$ with
    $a \to_{\calc} b$ and $a \to_\eta c$: We can take $d = C[b', c']$ since
    we have $b \tto_\eta d$ in one step and $c \to_{\calc}^= d$ in one step
    too.
  \item If the redex in $a \to_{\calc} b$ is the entire term $a$, but the
    redex in $a \to_\eta c$ is a proper subterm of $a$: We will solve this
    by case analysis on the form of $a$:
    \begin{itemize}
    \item If $a$ is an application: Since $a$ is an application and also a
      $\banana{\lambda}$-redex, it must match the left-hand side of the
      $\beta.\to$ rule, $\ap{(\lam{x}{M(x)})}{N}$, and $b$ must be $M(N)$.
      \begin{itemize}
      \item We will first deal with the case when the $\eta$-redex which
        lead to $c$ originated in $M(x)$. In that case
        $M(x) \to_\eta M'(x)$ and $c = \ap{(\lam{x}{M'(x)})}{N}$. Our
        sought-after $d$ is then $M'(N)$, since $c \to_{\calc}^= d$ via
        $\beta.\to$ in one step and $b = M(N) \tto_\eta d = M'(N)$.
      \item Now we get to one of the two interesting cases which
        necessitated this whole lemma: the overlap between $\beta$ and
        $\eta$, with $\beta$ on the top. If the $\eta$-redex did not
        originate in $M(x)$, then the $\eta$-redex must be
        $\lam{x}{M(x)}$. Therefore, $M = \ap{T}{x}$ and
        $a = \ap{(\lam{x}{\ap{T}{x}})}{N}$. Performing the $\eta$-reduction
        yields $c = \ap{T}{N}$. In this case, both $b$ and $c$ are equal to
        $\ap{T}{N}$ and so we can choose $\ap{T}{N}$ as our $d$.
      \end{itemize}
    \item If $a$ is any other kind of term: Let $l \to r$ be the rule used
      in $a \to_{\calc} b$. Not counting $\beta.\to$, which only acts on
      applications and which we dealt with just above, the rules of
      $\banana{\lambda}$ do not overlap with the $\eta.\to$ rule. This
      means the $\eta$-redex which led to $c$ must lie entirely inside a
      part the part of $l$ which corresponds to a metavariable. Let $M$ be
      that metavariable, then we will decompose $l$ into $L(M)$ and $r$
      into $R(M)$. We have $a = L(a')$ for some $a'$, $b = R(a')$ and
      $c = L(a'')$\footnote{Since our rules are left-linear, $M$ is
        guaranteed to appear in $L(M)$ at most once. Therefore, if
        $a' \to_\eta a''$ in one step, then also $L(a') \to_\eta L(a'')$ in
        one step as well.}. Our $d$ will be $R(a'')$ and we have
      $b = R(a') \tto_\eta d = R(a'')$ in several steps\footnote{$a'$ can
        occur multiple times in $R(a')$ when the rule $l \to r$ is
        duplicating (which is actually the case for the $\banana{\op{op}}$
        rules). However, we are able to go from $R(a')$ to $R(a'')$ in
        multiple steps. NB: This is why we use
        Lemma~\ref{lem:commutativity} instead of trying to prove
        commutativity directly.} and $c = L(a'') \to_{\calc}^= d = R(a'')$
      in one step of $l \to r$.
    \end{itemize}
  \item If the redex in $a \to_\eta c$ is the entire term $a$, but the
    redex in $a \to_{\calc} b$ is a proper subterm of $a$: In this case,
    $a$ must be an abstraction that matches the left-hand side of the
    $\eta.\to$ rule, i.e.\ $a = \lam{x}{\ap{N}{x}}$. Also, we have $c = N$.
    \begin{itemize}
    \item As before, we will first deal with the case when the
      $\banana{\lambda}$-redex is contained completely within $N$. Then
      $N \to_{\calc} N'$ and $b = \lam{x}{\ap{N'}{x}}$. The common reduct
      $d$ is $N'$ since $b \tto_\eta d$ in one step and
      $c = N \to_{\calc}^= d = N'$ as established before.
    \item Now this is where we deal with the second overlap between $\beta$
      and $\eta$ in our reduction system, the one with $\eta$ on top. Let
      us assume that the $\banana{\lambda}$-redex in $a$ is actually
      $\ap{N}{x}$. Since this is an application, the only admissible
      reduction is with $\beta.\to$. In that case, $N = \lam{y}{T(y)}$ and
      $a = \lam{x}{\ap{(\lam{y}{T(y)})}{x}}$. Performing the
      $\beta$-reduction gives us $b = \lam{x}{T(x)}$ which is however equal
      to $c = N = \lam{y}{T(y)}$. So we can choose $d = b$ and be done.
    \end{itemize}
  \item If $a$ is the redex for both reductions $a \to_{\calc} b$ and
    $a \to_\eta c$, then $a$ must match the left-hand side of two reduction
    rules. However, that is impossible in our calculus and so $a$ must have
    matched the same rule twice and therefore $b = c$. Then, we have a
    trivial $d = b$.
  \end{itemize}
\end{proof}

Equipped with this lemma, we can go on to prove our main result,
Theorem~\ref{thm:confluence}, the confluence of $\banana{\lambda}$.

\begin{theorem}\label{thm:confluence}
  \demph{Confluence of $\banana{\lambda}$}
  
  The reduction relation $\to$, defined by the reduction rules
  in~\ref{sec:reductions}, on the set of $\banana{\lambda}$ terms is
  confluent.
\end{theorem}

\begin{proof}
  From Lemma~\ref{lem:confluence-int}, we know that the $\banana{\lambda}$
  system without $\eta.\to$ is confluent and from
  Lemma~\ref{lem:confluence-eta}, we know that the $\eta.\to$ reduction
  rule is confluent as well. Lemma~\ref{lem:eta-commutes} tells us that
  these two reduction systems commute and therefore, by the Lemma of
  Hindley-Rosen, their union, which is the $\banana{\lambda}$ reduction
  system, commutes as well.
\end{proof}


\section{Termination}
\label{sec:termination}

\begin{definition}
  A reduction relation is \demph{terminating} if there is no infinite chain
  $M_1 \to M_2 \to \ldots$.
\end{definition}

In this section, we will prove termination with a similar strategy as the
one we employed for confluence. $\banana{\lambda}$ is an extension of the
$\lambda$-calculus with computation types and some operations on
computations. Our computations can be thought of as algebraic expressions,
i.e.\ they have a tree-like inductive structure. The reason that all
computations in our calculus terminate is that the operations defined on
computations rely on well-founded recursion. However, it is quite tricky to
go from this intuition to a formal proof of termination. Fortunately, we
can rely on existing results.

Blanqui, Jounnaud and Okada have introduced Inductive Data Type Systems
(IDTSs)~\cite{blanqui2002inductive,blanqui2000termination}. Similar to the
CRSs, IDTSs are a class of rewriting systems for which we can prove certain
interesting general results. In this section, we will start by examining
the definition of an IDTS and fitting our calculus into that
definition. Then, we will verify that the IDTS version of our calculus
satisfies the sufficient conditions for being a terminating IDTS and thus
end up with a proof of termination for our calculus.

\subsection{Defining Inductive Data Type Systems}
\label{ssec:defining-idtss}

We will go by the revised definition of Inductive Data Type Systems that
figures in~\cite{blanqui2000termination}. This formulation extends IDTSs to
higher-order rewriting and does so using the CRS formalism that we
introduced earlier.

\begin{definition}
  An \demph{Inductive Data Type System (IDTS)} is a pair of an IDTS-alphabet
  and a set of IDTS-rewrite rules.
\end{definition}

Just like a CRS, an IDTS is an alphabet coupled with some rewrite
rules. Let us first look at the alphabet and the rules for building terms
out of the elements of the alphabet; the rewrite rules will follow.

\begin{definition}
  The set of types $T(\BB)$ contains:
  \begin{itemize}
  \item all the types from $\BB$
  \item a type $\alpha \to \beta$ for every $\alpha$ and $\beta$ in $T(\BB)$
  \end{itemize}
\end{definition}

\begin{definition}
  An \demph{IDTS-alphabet} consists of:
  \begin{itemize}
  \item $\BB$, a set of \emph{base types}
  \item $\XX$, a family $(X_\tau)_{\tau \in T(\BB)}$ of sets of \emph{variables}
  \item $\FF$, a family ${(F_{\alpha_1,\ldots,\alpha_n,\beta})}_{\alpha_1,\ldots,\alpha_n,\beta \in T(\BB)}$ of sets of \emph{function symbols}
  \item $\ZZ$, a family ${(Z_{\alpha_1,\ldots,\alpha_n,\beta})}_{\alpha_1,\ldots,\alpha_n,\beta \in T(\BB)}$ of sets of
    \emph{metavariables}
  \end{itemize}
\end{definition}

The distinction between a CRS-alphabet and an IDTS-alphabet is that the
IDTS-alphabet comes equipped with a set of types. Furthermore, all the
other symbols in the alphabet are indexed by types, so we end up with typed
variables, typed function symbols and typed metavariables.

When we consider IDTS metaterms, we admit only well-typed terms. The below
definition of IDTS metaterms refines the definition of CRS metaterms by
restraining term formation in accordance with the types.

\begin{definition}
  The \demph{typed metaterms} of an IDTS are given inductively:
  \begin{itemize}
  \item variables from $X_\tau$ are metaterms of type $\tau$
  \item if $t$ is a metaterm of type $\beta$ and $x$ a variable from
    $X_\alpha$, then $[x]t$ is a metaterm of type $\alpha \to \beta$ called
    \emph{abstraction}
  \item if $F$ is an function symbol from
    $F_{\alpha_1,\ldots,\alpha_n,\beta}$ and $t_1$,\ldots,$t_n$ are
    metaterms of types $\alpha_1,\ldots,\alpha_n$, respectively, then
    $F(t_1,\ldots,t_n)$ is a metaterm of type $\beta$
  \item if $M$ is a metavariable from $Z_{\alpha_1,\ldots,\alpha_n,\beta}$
    and $t_1$,\ldots,$t_n$ are metaterms of types
    $\alpha_1,\ldots,\alpha_n$, respectively, then $M(t_1,\ldots,t_n)$ is a
    metaterm of type $\beta$
  \end{itemize}
\end{definition}

\begin{definition}
  The \demph{terms} of an IDTS are its metaterms which do not contain any
  metavariables.
\end{definition}

The definition of an IDTS rewrite rule is almost identical to the one for
CRS reduction rules. The only difference is the extra condition stating
that the redex and contractum must have identical types.

\begin{definition}
  An \demph{IDTS rewrite rule} is a pair of metaterms $s \to t$ such that:
  \begin{itemize}
  \item $s$ and $t$ are both closed, i.e.\ all variables are bound using
    the $[\_]\_$ binder
  \item $s$ is of the form $F(t_1,\ldots,t_n)$
  \item all the metavariables that occur in $t$ also occur in $s$
  \item any metavariable $M$ that occurs in $s$ only occurs in the form
    $M(x_1,\ldots,x_k)$, where $x_i$ are pairwise distinct variables
  \item $s$ and $t$ are both of the same type
  \end{itemize}
\end{definition}

As stated above, an IDTS is just an alphabet along with a set of rewrite
rules. An IDTS induces a rewriting relation in exactly the same way as a
CRS does, see~\cite{blanqui2000termination} for more details.


\subsection{$\banana{\lambda}$ as an Inductive Data Type System}
\label{ssec:banana-idts}

Now we will try to link our calculus to the IDTS framework in order to
benefit from its general termination results. The biggest obstacle will be
that IDTS assigns a fixed type to every symbol. In our calculus, symbols
are polymorphic: the $\eta$ constructor can produce expressions like
$\etaE{\star} : \FF_E(1)$ or $\etaE{(\lam{x}{x})} : \FF_E(\alpha \to
\alpha)$ and that for any choice of $E$. We would therefore like to replace
function symbols such as $\eta$ with specialized symbols
$\eta_{\FF_E(\alpha)}$. For a given type $\alpha$ and effect signature $E$,
the symbol $\eta_{\FF_E(\alpha)}$ would have the type $\alpha \to
\FF_E(\alpha)$, i.e.\ it would belong to $F_{\alpha,\FF_E(\alpha)}$.

We will call this calculus with specialized symbols
$\banana{\lambda}_\tau$. There will not be a bijection between
$\banana{\lambda}$ and $\banana{\lambda}_\tau$ since a single term in
$\banana{\lambda}$ will generally correspond to a multitude of specialized
versions in $\banana{\lambda}_\tau$ (think of $\lam{x}{x}$ in
$\banana{\lambda}$ versus $\lam{x_\iota}{x_\iota}$, $\lam{x_o}{x_o}$\ldots
in $\banana{\lambda}_\tau$). Therefore, the results we prove for
$\banana{\lambda}_\tau$ will not automatically transfer to
$\banana{\lambda}$. In the rest of this subsection, we will elaborate the
definition of $\banana{\lambda}_\tau$ and show why termination carries over
from $\banana{\lambda}_\tau$ to $\banana{\lambda}$.


\subsubsection{Defining $\banana{\lambda}_\tau$}
\label{sssec:banana-tau}

$\banana{\lambda}_\tau$ will be defined as an IDTS. This means we need to
first identify the alphabet. The base types $\BB$ of
$\banana{\lambda}_\tau$ will be all the atomic types and computation types
of $\banana{\lambda}$ (i.e.\ all types except for function
types).\footnote{Note that throughout this section, we will make a
  distinction between \emph{base} types and \emph{atomic} types. Base types
  are a notion from IDTS and they correspond to everything which is not a
  function type (in our case, these will be computation types and atomic
  types). Atomic types is a notion from $\banana{\lambda}$, where it
  essentially means a ``base type'' like truth values, individuals, natural
  numbers\ldots.} This means that the set of types $T(\BB)$ of
$\banana{\lambda}_\tau$ will be exactly the set of types of
$\banana{\lambda}$.

Next, we will introduce function symbols for all the syntactic
constructions of $\banana{\lambda}$, except for abstraction, which is
handled by the $[\_]\_$ binder construct already found in IDTSs:

\begin{itemize}
\item $@_{\alpha, \beta} \in F_{\alpha \to \beta, \alpha, \beta}$
  (i.e.\ for every pair of types $\alpha$ and $\beta$, there will be a
  function symbol $@_{\alpha,\beta}$ of type $(\alpha \to \beta) \to
  \alpha \to \beta$ in our alphabet)
\item $c \in F_{\alpha}$ for any constant $c : \alpha \in \Sigma$
\item $\eta_{\alpha, E} \in F_{\alpha, \FF_E(\alpha)}$
\item $\op{op}_{\gamma, E} \in F_{\alpha, \beta \to \FF_E(\gamma),
  \FF_E(\gamma)}$ for any operation symbol $\op{op}$ from $\EE$ and any $E$
  such that $\typedop{op}{\alpha}{\beta} \in E$
\item $\cherry_\alpha \in F_{\FF_\emptyset(\alpha), \alpha}$
\item $\banana{}_{\op{op}_1, \ldots, \op{op}_n, \gamma, \delta, E, E'} \in F_{\alpha_1 \to (\beta_1 \to \FF_{E'}(\delta)), \ldots,
  \alpha_n \to (\beta_n \to \FF_{E'}(\delta)), \gamma \to \FF_{E'}(\delta),
  \FF_E(\gamma), \FF_{E'}(\delta)}$ where:
  \begin{itemize}
  \item $\op{op}_1 : \alpha_1 \rightarrowtail \beta_1 \in E$, \ldots,
    $\op{op}_n : \alpha_n \rightarrowtail \beta_n \in E$
  \item $E \setminus \{\op{op}_1, \ldots, \op{op}_n\} \subseteq E'$
  \end{itemize}
\item $\CC_{\alpha,\beta,E} \in F_{\alpha \to \FF_E(\beta),\FF_E(\alpha \to
  \beta)}$
\end{itemize}

The list above is based on the typing rules of our calculus found on
Figure~\ref{fig:types}. We convert the typing rules of $\banana{\lambda}$
into the typed function symbols of $\banana{\lambda}_\tau$ with the
following process:

\begin{itemize}
\item We take a typing rule of $\banana{\lambda}$, other than [abs] or
  [var] (since abstractions and variables are already present in the
  language of IDTS terms).
\item We identify all the type-level metavariables. That is, metavariables
  $\alpha$, $\beta$, $\gamma$ \ldots ranging over types, metavariables $E$,
  $E'$ \ldots ranging over effect signatures and metavariables ranging over
  operation symbols $\op{op}$.
\item We strip these metavariables down to a minimal non-redundant set
  (e.g.\ in the $[\op{op}]$ rule, we have that
  $\typedop{op}{\alpha}{\beta} \in E$, therefore $E$ and $\op{op}$
  determine $\alpha$ and $\beta$ and therefore $\alpha$ and $\beta$
  redundant)
\item We introduce a family of symbols: for every possible instantiation of
  the metavariables mentioned above, we will have a different symbol. The
  arity of the symbol will correspond to the number of typing judgments
  that serve as hypotheses to the typing rule. The types of the arguments
  and of the result will be derived from the types of the judgments of the
  hypotheses and the conclusion, respectively.
  \begin{itemize}
  \item Example: In the $[\eta]$ rule, we have two metavariables: $\alpha$
    standing in for a type and $E$ standing in for an effect signature. The
    rule has one typing judgment hypothesis. For every type $\alpha$ and
    every effect signature $E$, we will therefore have a unary symbol
    $\eta_{\alpha, E}$ of type $\alpha \to \FF_E(\alpha)$ (i.e.\ belonging
    to $F_{\alpha, \FF_E(\alpha)}$).
  \end{itemize}
\end{itemize}

A specifically-typed symbol in
$\banana{\lambda}_\tau$ then corresponds to an instantiation of the type
metavariables in a
$\banana{\lambda}$ typing rule. We can follow this correspondence further
and see that
$\banana{\lambda}_\tau$ IDTS terms, written using the above function
symbols, correspond to typing derivations in $\banana{\lambda}$.

Our alphabet now has types and function symbols. We also need to specify
the sets of variables and metavariables and so we will take some arbitrary
sets with $x_\tau$, $y_\tau$, \ldots $\in X_\tau$ and
$M_{\alpha_1,\ldots,\alpha_n,\beta}$, $N_{\alpha_1,\ldots,\alpha_n,\beta}$,
\ldots $\in Z_{\alpha_1,\ldots,\alpha_n,\beta}$.

\begin{sidewaysfigure}
  \centering
  \begin{tabular}{lr}
  $@([x]M(x), N) \to$ & rules $\beta$ \\
  $M (N)$ & \\
  \multicolumn{2}{l}{$@_{\typehint{\alpha \to \gamma, \alpha, \gamma}}([x_{\typehint\alpha}]M_{\typehint{\alpha, \gamma}}(x_{\typehint\alpha}), N_{\typehint\alpha}) \to$} \\
  \multicolumn{2}{l}{$M_{\typehint{\alpha, \gamma}}(N_{\typehint\alpha})$} \\
  \\
  let $\banana{}^{(\op{op}_i)_{i \in
    I}}_{\typehint{\FF_E(\gamma),\FF_{E'}(\delta)}}(N_{\typehint{\FF_E(\gamma)}})$ & \\
  \multicolumn{2}{l}{$ = \banana{}^{(\op{op}_i)_{i \in I}}_{\typehint{(\alpha_i \to (\beta_i \to \FF_{E'}(\delta)) \to
  \FF_{E'}(\delta))_{i \in I}, \gamma \to \FF_{E'}(\delta), \FF_E(\gamma),
  \FF_{E'}(\delta)}} ((M^i_{\typehint{\alpha_i \to (\beta_i \to
    \FF_{E'}(\delta)) \to \FF_{E'}(\delta)}})_{i \in I},
    M^\eta_{\typehint{\gamma \to \FF_{E'}(\delta)}}, N_{\typehint{\FF_E(\gamma)}})$} \\
  \\
  $\banana{}^{(\op{op}_i)_{i \in I}} (\eta (N)) \to$ & rules $\banana{\eta}^{(\op{op}_i)_{i \in I}}_{\FF_E(\gamma),\FF_{E'}(\delta)}$ \\
  $@(M^\eta, N)$ & \\
  \multicolumn{2}{l}{$\banana{}^{(\op{op}_i)_{i \in I}}_{\typehint{\FF_E(\gamma), \FF_{E'}(\delta)}} (\eta_{\typehint{\gamma, \FF_E(\gamma)}} (N_{\typehint{\gamma}})) \to$} \\
  \multicolumn{2}{l}{$@_{\typehint{\gamma \to \FF_{E'}(\delta), \gamma,
  \FF_{E'}(\delta)}} (M^\eta_{\typehint{\gamma \to \FF_{E'}(\delta)}}, N_{\typehint{\gamma}})$} \\
  \\
  $\banana{}^{(\op{op}_i)_{i \in I}} (\op{op}_j (N^{\mathrm{p}}, [y] N^{\mathrm{c}}(y))) \to$ & rules $\banana{\op{op}}^{(\op{op}_i)_{i \in I}}_{\FF_E(\gamma),\FF_{E'}(\delta)}$ \\
  $@(@(M^j, N^{\mathrm{p}}), [y] \banana{}^{(\op{op}_i)_{i \in I}} (N^{\mathrm{c}}(y)))$ & where $j \in I$ \\
  \multicolumn{2}{l}{$\banana{}^{(\op{op}_i)_{i \in I}}_{\typehint{\FF_E(\gamma), \FF_{E'}(\delta)}} (\op{op}_{j \typehint{\alpha, \beta \to \FF_E(\gamma), \FF_E(\gamma)}} (N^{\mathrm{p}}_{\typehint{\alpha}}, [y_{\typehint{\beta}}] N^{\mathrm{c}}_{\typehint{\beta, \FF_E(\gamma)}}(y_{\typehint{\beta}}))) \to$} \\
  \multicolumn{2}{l}{$@_{\typehint{(\beta \to  \FF_{E'}(\delta)) \to \FF_{E'}(\delta), \beta \to \FF_{E'}(\delta), \FF_{E'}(\delta)}} (@_{\typehint{\alpha \to (\beta \to
    \FF_{E'}(\delta)) \to \FF_{E'}(\delta), \alpha, (\beta \to
    \FF_{E'}(\delta)) \to \FF_{E'}(\delta)}} (M^j_{\typehint{\alpha \to (\beta \to
    \FF_{E'}(\delta)) \to \FF_{E'}(\delta)}}, N^{\mathrm{p}}_{\typehint{\alpha}}), [y_{\typehint{\beta}}] \banana{}^{(\op{op}_i)_{i \in I}}_{\typehint{\FF_E(\gamma), \FF_{E'}(\delta)}} (N^{\mathrm{c}}_{\typehint{\beta, \FF_E(\gamma)}}(y_{\typehint{\beta}})))$} \\
  \\
  $\banana{}^{(\op{op}_i)_{i \in I}} (\op{op}_j (N^{\mathrm{p}}, [y] N^{\mathrm{c}}(y))) \to$ & rules $\banana{\op{op}'}^{(\op{op}_i)_{i \in I}}_{\FF_E(\gamma),\FF_{E'}(\delta)}$ \\
  $\op{op}_j (N^{\mathrm{p}}, [y] \banana{}^{(\op{op}_i)_{i \in I}} (N^{\mathrm{c}}(y)))$ & where $j \notin I$ \\
  \multicolumn{2}{l}{$\banana{}^{(\op{op}_i)_{i \in I}}_{\typehint{\FF_E(\gamma), \FF_{E'}(\delta)}} (\op{op}_{j \typehint{\alpha, \beta \to \FF_E(\gamma), \FF_E(\gamma)}} (N^{\mathrm{p}}_{\typehint{\alpha}}, [y_{\typehint{\beta}}] N^{\mathrm{c}}_{\typehint{\beta, \FF_E(\gamma)}}(y_{\typehint{\beta}}))) \to$} \\
  \multicolumn{2}{l}{$\op{op}_{j \typehint{\alpha, \beta \to \FF_{E'}(\delta), \FF_{E'}(\delta)}} (N^{\mathrm{p}}_{\typehint{\alpha}}, [y_{\typehint{\beta}}] \banana{}^{(\op{op}_i)_{i \in I}}_{\typehint{\FF_E(\gamma), \FF_{E'}(\delta)}} (N^{\mathrm{c}}_{\typehint{\beta, \FF_E(\gamma)}}(y_{\typehint{\beta}})))$} \\
  \\
  $\cherry (\eta (N)) \to$ & rules $\cherry_\alpha$ \\
  $N$ & \\
  \multicolumn{2}{l}{$\cherry_{\typehint{\FF_\emptyset(\alpha), \alpha}} (\eta_{\typehint{\alpha, \FF_\emptyset(\alpha)}} (N_{\typehint\alpha})) \to$} \\
  \multicolumn{2}{l}{$N_{\typehint\alpha}$} \\
  \\
  $\CC ([x]\eta (M(x))) \to$ & rules $\CC^\eta_{\alpha, \beta, E}$ \\
  $\eta ([x] M(x))$ & \\
  \multicolumn{2}{l}{$\CC_{\typehint{\alpha \to \FF_E(\beta), \FF_E(\alpha \to \beta)}} ([x_{\typehint\alpha}]\eta_{\typehint{\beta, \FF_E(\beta)}} (M_{\typehint{\alpha, \beta}}(x_{\typehint\alpha}))) \to$} \\
  \multicolumn{2}{l}{$\eta_{\typehint{(\alpha \to \beta), \FF_E(\alpha \to \beta)}} ([x_{\typehint\alpha}] M_{\typehint{\alpha, \beta}}(x_{\typehint\alpha}))$} \\
  \\
  $\CC ([x] \op{op} (M^p, [y]M^c(x, y))) \to$ & rules $\CC^{\op{op}}_{\alpha, \beta, E}$ \\
  $\op{op} (M^p, [y] \CC ([x] M^c(x, y)))$ & \\
  \multicolumn{2}{l}{$\CC_{\typehint{\alpha \to \FF_E(\beta), \FF_E(\alpha \to \beta)}} ([x_{\typehint\alpha}] \op{op}_{\typehint{\gamma, \delta \to \FF_E(\beta), \FF_E(\beta)}} (M^p_{\typehint\gamma}, [y_{\typehint\delta}]M^c_{\typehint{\alpha, \delta, \FF_E(\beta)}}(x_{\typehint\alpha}, y_{\typehint\delta}))) \to$} \\
  \multicolumn{2}{l}{$\op{op}_{\typehint{\gamma, \delta \to \FF_E(\alpha \to \beta), \FF_E(\alpha \to \beta)}} (M^p_{\typehint\gamma}, [y_{\typehint\delta}] \CC_{\typehint{\alpha \to \FF_E(\beta), \FF_E(\alpha \to \beta)}} ([x_{\typehint\alpha}] M^c_{\typehint{\alpha, \delta, \FF_E(\beta)}}(x_{\typehint\alpha}, y_{\typehint\delta})))$}
  \end{tabular}
  
  \caption{\label{fig:tau-types} IDTS rewrite rules for
    $\banana{\lambda}_\tau$, shown in parallel with the CRS rules for
    $\banana{\lambda}$.}
  
\end{sidewaysfigure}

To complete our IDTS, we have to give the rewrite rules. The rules for
$\banana{\lambda}_\tau$ are given in Figure~\ref{fig:tau-types}. An
important property of an IDTS rewrite rule is that both its left-hand and
right-hand side are well-typed and that they have the same type. In order
to facilitate the reader's verification that this is indeed the case, we
have used a different labelling scheme for function symbols. When we write
$f_{\alpha_1,\ldots,\alpha_n,\beta}$, we are referring to the instance of
symbol $f$ which has the type $\alpha_1 \to \ldots \to \alpha_n \to \beta$
(i.e.\ belongs to $F_{\alpha_1,\ldots,\alpha_n,\beta}$). This way, instead
of using a symbol name like $\eta_{\alpha,E}$, forcing you to look up its
type $\alpha \to \FF_E(\alpha)$, we will refer to this symbol directly as
$\eta_{\alpha,\FF_E(\alpha)}$.

In Figure~\ref{fig:tau-types}, you will also find the rewrite rules with
all the subscripts removed. This allows you to get a high-level look at the
term without any of the type annotation noise. You might notice that the
reduction rules without type annotations are very similar to the CRS rules
we have used in~\ref{sec:confluence}. There is only a small divergence in
the way the two systems encode $\lambda$ abstractions. In
Section~\ref{sec:confluence}, we followed Klop's work on
CRS~\cite{klop1993combinatory} wherein $\lam{x}{M}$ is encoded as
$\lambda([x] M)$. In this section, we follow Blanqui's work on
IDTS~\cite{blanqui2000termination}, where $\lam{x}{M}$ is encoded as
$[x] M$.

When describing the rewrite rules for handlers, the $\banana{}$ symbol
applied to all of its clauses and annotated with all of the intervening
types ends up taking lots of space. Since this expression stays the same
from redex to contractum, from rule to rule, we introduce a shortcut
$\banana{}^{(\op{op}_i)_{i \in
    I}}_{\typehint{\FF_E(\gamma),\FF_{E'}(\delta)}}(N_{\typehint{\FF_E(\gamma)}})$
that we use throughout all of the handler rules.

We have given a complete formal definition of $\banana{\lambda}_\tau$. This
will let us find a proof of termination for $\banana{\lambda}_\tau$ using
the theory of IDTSs. However, in order to carry over this result to our
calculus $\banana{\lambda}$, we will need to formalize relationship between
the two.

\begin{definition}
  \demph{Term} is a (partial) function from $\banana{\lambda}_\tau$ terms
  to $\banana{\lambda}$ terms which removes any type annotations (the
  subscripts on function symbols, variables and metavariables) and
  translates $\banana{\lambda}_\tau$ syntax to $\banana{\lambda}$ syntax
  using the following equations:
  
  \begin{align*}
    & \Term(x) &&= x \\
    & \Term([x] M) &&= \lam{x}{\Term(M)} \\
    & \Term(@(M, N)) &&= \ap{(\Term(M))}{(\Term(N))} \\
    & \Term(c) &&= c \\
    & \Term(\eta(M)) &&= \etaE{(\Term(M))} \\
    & \Term(\op{op}(M^{\mathrm{p}}, [x] M^{\mathrm{c}})) &&= \app{\op{op}}{(\Term(M^{\mathrm{p}}))}{(\lam{x}{\Term(M^{\mathrm{c}})})} \\
    & \Term(\cherry(M)) &&= \ap{\cherry}{(\Term(M))} \\
    & \Term(\banana{}_{\op{op}_1, \ldots, \op{op}_n}(M_1, \ldots, M_n, M_\eta, N)) &&= \ap{\banana{\onto{\op{op}_1}{\Term(M_1)},\ \onto{\op{op}_n}{\Term(M_n)},\ \onto{\eta}{\Term(M_\eta)}}}{(\Term(N))} \\
    & \Term(\CC(M)) &&= \ap{\CC}{(\Term(M))}
  \end{align*}
\end{definition}

\begin{definition}
  \demph{Types} is a function from $\banana{\lambda}$ terms to sets of
  $\banana{\lambda}_\tau$ terms, defined by the equation below.
  
  $$
  \Types(M) = \{ m \mid \Term(m) = M \}
  $$
\end{definition}

\begin{lemma}
  \label{lem:infinite-chains}
  Let $M$ and $N$ be $\banana{\lambda}$ terms. Then,

  $$
  M \to N \quad \Rightarrow \quad
  \forall m \in \Types(M).\ \exists n \in \Types(N).\ m \to n
  $$
  
  In the above, upper-case letters stand for $\banana{\lambda}$ terms,
  while lower-case letters stand for $\banana{\lambda}_\tau$ terms.
\end{lemma}

\begin{proof}
  This property is essentially a stronger kind of subject reduction for
  $\banana{\lambda}$. In proofs of subject reduction, we examine every
  reduction rule and we show how a typing derivation of the redex can be
  transformed into a typing derivation of the contractum. We can think of
  $\banana{\lambda}_\tau$ terms as $\banana{\lambda}$ typing
  derivations. The reduction rules in Figure~\ref{fig:tau-types} are the
  rules which tell us how to take a typing of the redex and transform it
  into a typing of the contractum.
  
  In order to prove this property, we will need to check the following:
  \begin{itemize}
  \item The redexes and contracta in Figure~\ref{fig:tau-types} are
    well-formed (i.e.\ well-typed). For that reason, we have included the
    type of every variable, metavariable and function symbol as a
    subscript.
  \item Applying $\Term$ to the type-annotated $\banana{\lambda}_\tau$
    redexes and contracta yields the redexes and contracta of
    $\banana{\lambda}$ (and therefore the $\banana{\lambda}_\tau$ redexes
    and contracta belong to the $\Types$ image of the $\banana{\lambda}$
    redexes and contracta). Since in Figure~\ref{fig:tau-types}, we have
    included the terms with their type annotations removed, we can see at a
    glance that the stripped rules align with the CRS formulation of
    $\banana{\lambda}$.
  \item Finally, we have to check whether the rewriting rules in
    Figure~\ref{fig:tau-types} actually apply to \emph{all} the
    $m \in \Types(M)$. In other words, we need to check whether the type
    annotation scheme used for the redexes is the most general and covers
    all possible typings of the redex. In our case, we have followed the
    typing rule constraints and given the most general type annotations.
  \end{itemize}
  
  Given a reduction in $\banana{\lambda}$ from $M$ to $N$, we can find the
  untyped reduction rule used in Figure~\ref{fig:tau-types}. We know that
  if $m \in \Types(M)$, then $m$ then matches the redex of the
  corresponding typed rule. We also know that the contractum of the typed
  rule belongs to $\Types(N)$ and therefore, the property
  holds. Furthermore, if we were to formalize the correspondence between
  $\banana{\lambda}$ typing derivations and $\banana{\lambda}_\tau$ terms,
  we would get another proof of subject reduction for $\banana{\lambda}$.
\end{proof}

\begin{corollary}
  If the reduction relation of $\banana{\lambda}_\tau$ is terminating, then
  so is the $\banana{\lambda}$ reduction relation on well-typed terms.
\end{corollary}

\begin{proof}
  Consider the contrapositive: if there exists an infinite chain of
  well-typed $\banana{\lambda}$ terms, then there must also be an infinite
  chain of $\banana{\lambda}_\tau$ terms. Using
  Lemma~\ref{lem:infinite-chains}, we can take the $\banana{\lambda}$ chain
  and translate it, link by link, to a $\banana{\lambda}_\tau$ chain.
\end{proof}


\subsection{Termination for IDTS}

So far, we have introduced an IDTS and have shown that if this IDTS is
terminating, then so is our calculus. We will now look at a general result
for IDTSs that we will make use of.

\begin{theorem}
  \label{thm:idts-normalization}
  \demph{(Strong normalization)}~\cite{blanqui2000termination} Let
  $\II = (\AAA, \RR)$ be a $\beta$-IDTS satisfying the assumptions (A). If
  all the rules of $\RR$ satisfy the General Schema, then $\to_\II$ is
  strongly normalizing.
\end{theorem}

Strong normalization is confluence and termination and so by showing
$\banana{\lambda}_\tau$ strongly normalizing, we also prove it
terminating. The theorem was lifted verbatim
from~\cite{blanqui2000termination} and parts of it deserve explaining:

\begin{itemize}
\item What is a $\beta$-IDTS?
\item What are the assumptions (A)?
\item What is the General Schema?
\end{itemize}

We will deal with these in order.

A $\beta$-IDTS is just an IDTS which for every two types $\alpha$ and
$\beta$ has a function symbol
$@_{\alpha,\beta} \in F_{\alpha \to \beta,\alpha,\beta}$ and a rule
$@_{\alpha,\beta}([x_\alpha] M_{\alpha, \beta}(x_\alpha), N_\alpha) \to
M_{\alpha,\beta}(N_\alpha)$. Furthermore, there must be no other rules
whose left-hand side is headed by $@$. The IDTS we have defined
in~\ref{ssec:banana-idts} is a $\beta$-IDTS.

\subsubsection{Checking Off the Assumptions}

Next, we will deal with the assumptions (A).

\begin{definition}
  The \demph{Assumptions (A)} are defined as the following four conditions:
  \begin{enumerate}
  \item every constructor is positive
  \item no left-hand side of rule is headed by a constructor
  \item both $>_\BB$ and $>_\FF$ are well-founded
  \item $stat_f = stat_g$ whenever $f =_\FF g$
  \end{enumerate}
\end{definition}

For these to make sense to us, we will need to build some more structure on
top of our IDTS: the notion of a constructor and the $>_\BB$ and $>_\FF$
relations.

We will need to designate for every base type $\gamma$ a set
$C_\gamma \subseteq \cup_{p \ge 0, \alpha_1, \ldots, \alpha_p \in T(\BB)}
F_{\alpha_1, \ldots, \alpha_p, \gamma}$ (i.e.\ a set of function symbols
with result type $\gamma$). We will then call the elements of these sets
\emph{constructors} of $\gamma$.

The base types of our IDTS consist of atomic types and computation
types. We will have no constructors for atomic types. On the other hand,
every computation type $\FF_E(\gamma)$ will have constructors
$\eta_{\gamma,E}$ ($\in F_{\gamma,\FF_E(\gamma)}$) and $\op{op}_{\gamma,E}$
($\in F_{\alpha,\beta \to \FF_E(\gamma),\FF_E(\gamma)}$) for every
$\typedop{op}{\alpha}{\beta} \in E$.

We can now check assumption (A.2). Since the only constructors in our IDTS
are $\eta$ and $\op{op}$, we validate this assumption.

Our choice of constructors induces a binary relation on the base types.

\begin{definition}
  $\beta$ \emph{depends on} $\alpha$ if there is a constructor
  $c \in C_\beta$ such that $\alpha$ occurs in the type of one of the
  arguments of $c$.
  
  We will give the reflexive-transitive closure of this relation between
  $\alpha$ and $\beta$ the name $\ge_\BB$. Furthermore, we will use $=_\BB$
  and $>_\BB$ to mean the associated equivalence and strict ordering,
  respectively.
\end{definition}

\begin{observation}
  If $\tau_1 \le_\BB \tau_2$, then $\tau_1$ is a subterm of $\tau_2$.
\end{observation}
\begin{proof}
  We will prove this by induction on the structure of the base type
  $\tau_2$.

  If $\tau_2$ is an atomic type, then $\tau_2$ has no constructors, so it
  does not depend on any other type. If we look at the reflexive-transitive
  closure of that, $\ge_\BB$, then the only type $\alpha$ such that
  $\alpha \le_\BB \tau_2$ is $\tau_2$ itself, which is a subterm of
  $\tau_2$.
  
  If $\tau_2$ is the computation type $\FF_E(\gamma)$, then we will have
  several constructors. We have $\eta_{\gamma,E}$ with a single argument of
  type $\gamma$. We thus know that $\FF_E(\gamma)$ depends
  $\gamma$.\footnote{This is a slight abuse of notation. The dependency
    relation is a relation on base types. However, $\gamma$ might be a
    complex (function) type. By saying that $\FF_E(\gamma)$ depends on
    $\gamma$, we mean to say that for every base type $\gamma'$ occurring
    in $\gamma$, we have that $\FF_E(\gamma)$ depends on $\gamma'$.} For
  every $\typedop{op}{\alpha}{\beta} \in E$, we have a constructor
  $\op{op}_{\gamma,E}$ with arguments of types $\alpha$ and
  $\beta \to \FF_E(\gamma)$. This tells us that $\FF_E(\gamma)$ also
  depends on $\alpha$, $\beta$ and $\FF_E(\gamma)$. $\FF_E(\gamma)$ does
  not have any more constructors, so those are all the types it depends on.

  The $\ge_\BB$ relation that is the subject of this observation is the
  reflexive-transitive closure of the dependency relation between base
  types. This means that $\tau_1 \le_\BB \tau_2$ if either
  $\tau_1 = \tau_2$ or $\tau_2$ depends on some $\tau_2' \neq \tau_2$ such
  that $\tau_1 \le_\BB \tau_2'$.
  \begin{itemize}
  \item If $\tau_1 = \tau_2$, the trivially $\tau_1$ is a subterm of
    $\tau_2$ and we are done.
  \item If $\tau_2$ depends on some $\tau_2' \neq \tau_2$, then $\tau_2'$
    must be either $\gamma$ or one of the $\alpha$ or $\beta$ from $E$
    since $\tau_2 = \FF_E(\gamma)$. In all these cases, we can apply the
    induction hypothesis for $\tau_2'$. We know that
    $\tau_1 \le_\BB \tau_2'$ and by the induction hypothesis, we now know
    that $\tau_1$ is a subterm of $\tau_2'$. Since $\tau_2'$ is a subterm
    of $\tau_2$, we have that $\tau_1$ is a subterm of $\tau_2$.
  \end{itemize}
\end{proof}

\begin{corollary}
  If $\tau_1 =_\BB \tau_2$, then $\tau_1 = \tau_2$.
\end{corollary}

\begin{corollary}
  If $\tau_1 <_\BB \tau_2$, then $\tau_1$ is a proper subterm of $\tau_2$.
\end{corollary}

We can now check the first half of assumption (A.3). Since the proper
superterm/subterm relation is well-founded (i.e.\ has no infinite
descending chains) and $>_\BB$ is a subset of the proper superterm/subterm
relation, then $>_\BB$ must be well-founded as well.

We can also check assumption (A.1) once we explain what is a positive
constructor.

\begin{definition}
  A constructor $c \in C_\beta$ is \demph{positive} if every base type
  $\alpha =_\BB \beta$ occurs only at positive positions in the types of
  the arguments of $c$.
\end{definition}

\begin{definition}
  The base types occurring in \demph{positive positions} $(\Pos)$ and the
  base types occurring in \demph{negative positions} $(\Neg)$ within a type
  are defined by the following mutually recursive equations:

  \begin{align*}
    \Pos(\alpha \to \beta) &= \Neg(\alpha) \cup \Pos(\beta) \\
    \Neg(\alpha \to \beta) &= \Pos(\alpha) \cup \Neg(\beta) \\
    \Pos(\nu) &= \{ \nu \} \text{\quad with $\nu$ an atomic type} \\
    \Neg(\nu) &= \emptyset \text{\quad with $\nu$ an atomic type}
  \end{align*}
\end{definition}

In our IDTS, $\alpha =_\BB \beta$ is true only when $\alpha = \beta$. The
only time a type occurs in the type of one of his constructor's arguments
is in the case of the $\op{op}$ constructors. Given
$\typedop{op}{\alpha}{\beta} \in E$, $\op{op}_{\gamma,E}$ is a constructor
of $\FF_E(\gamma)$; the type of its second argument is
$\beta \to \FF_E(\gamma)$. This occurrence is positive and so we validate
assumption (A.1).

To validate the rest of (A.3), we will need to introduce the $>_\FF$
relation. As $>_\BB$ was induced by the structure of constructors, $>_\FF$
will be induced by the structure of the rewriting rules $\RR$ of our
IDTS.

\begin{definition}
  A function symbol $g$ \demph{depends on} a function symbol $f$ if there
  is a rule defining $g$ (i.e.\ whose left-hand side is headed by $g$) and
  in the right-hand side of which $f$ occurs.

  We will use $\le_\FF$ as the name for the reflexive-transitive closure of
  this relation between $f$ and $g$. We will also write $=_\FF$ and $>_\FF$
  for the associated equivalence and strict ordering, respectively.
\end{definition}

If we scan the rules of our calculus, we will see that the $\banana{}$
symbols depend on $\op{op}$ (for when there is no handler and the $\op{op}$
is copied), $@$ (for applying the handler clauses to their arguments) and
on $\banana{}$ symbols (for recursion). The $\CC$ symbols depend on
$\op{op}$ (when passing the $\lambda$ through an $\op{op}$), $\eta$ (when
switching the $\lambda$ with the $\eta$) and $\CC$ symbols (for
recursion). There is no other dependency in our IDTS.\@ This means we can
check off the second part of assumption (A.3) since $>_\FF$ is well-founded
(it contains only $\banana{} >_\FF \op{op}$, $\banana{} >_\FF @$,
$\CC >_\FF \op{op}$ and $\CC >_\FF \eta$).

Assumption (A.4) is trivial in our case, since within our IDTS $f =_\FF g$
only when $f = g$. This assumption only comes into play in the general
theory of IDTSs when one exploits mutual recursion with functions of
multiple arguments. The $stat_f$ values mentioned in the assumption (A.4)
describe the way in which a function's arguments should be ordered to
guarantee that recursive calls are always made to smaller arguments. In the
case of mutual recursion, both functions must agree on the order according
to which they will decrease their arguments. Since we do not deal with
mutual recursion in our calculus, we will not go into any more detail into
this.


\subsubsection{General Schema}

There is one last obstacle in our way towards proving termination of
$\banana{\lambda}_\tau$. We will need to verify that the rewrite rules that
we given in Figure~\ref{fig:tau-types} satisfy the General Schema.

\begin{definition}
  A rewrite rule $f(l_1, \ldots, l_n) \to r$ follows the \demph{General
    Schema} if $r \in \CC\CC_f(l_1, \ldots, l_n)$.
\end{definition}

$\CC\CC_f(l_1, \ldots, l_n)$ refers to the so-called \emph{computable
  closure} of the left-hand side $f(l_1, \ldots, l_n)$. The idea behind
computable closure is that the left-hand side of a rewrite rule can tell us
what are all the possible right-hand sides that still lead to a correct
proof of termination\footnote{Theorem~\ref{thm:idts-normalization} is
  proven using Tait's method of computability predicates
  \cite{tait1967intensional}. The term computable closure comes from the
  fact that the admissible right-hand sides are the metavariables of the
  left-hand side closed on operations that preserve computability.}. A
formal definition of computable closure is given
in~\cite[p. 8]{blanqui2000termination}.

Informally, $r \in \CC\CC_f(l_1, \ldots, l_n)$ if:
\begin{itemize}
\item Every metavariable used in $r$ must be accessible in one of $l_1$,
  \ldots, $l_n$.
\item Recursive function calls (i.e.\ uses of function symbols $g =_\FF f$)
  must be made to arguments smaller than the arguments $l_1$, \ldots,
  $l_n$.
\end{itemize}

A metavariable is \demph{accessible} in a term if it appears at the top of
the term or under abstractions or constructors. If a metavariable occurs
inside an argument of a function symbol which is not a constructor, then
there are some technical constraints on whether it is accessible. However,
in every rewrite rule of our IDTS, the only function symbol which is not a
constructor and which occurs within is the one at the top level: none of
the arguments contain a non-constructor function symbol.


