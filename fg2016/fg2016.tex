\documentclass{llncs}

\usepackage{url}
\usepackage{hyperref}
\usepackage{stmaryrd}
\usepackage{mathtools}

\include{definitions}


%
\begin{document}
%
\title{TBD}
%
\author{Anonymous Copy}
%
\institute{Anonymous Copy}

\maketitle              % typeset the title of the contribution

\begin{abstract}
\dots
\keywords{\dots}
\end{abstract}
%

\section{Introduction}
\label{sec:introduction}

The prevailing methodology of formal semantics is compositionality in the
sense of Frege: denotations of complex phrases are functions of the
denotations of their immediate constituents. However, several phenomena
have been identified that challenge this notion of
compositionality. Examples include anaphora, presupposition,
quantification, deixis and conventional implicature. In all of these
examples, simple models of denotation (i.e.\ noun phrases are individuals,
sentences are truth-values) run into complications as the denotations can
depend on external values (anaphora, deixis) or on something which is not
an immediate constituent (presupposition, quantification, conventional
implicature).

Among the solutions to these challenges, we find (at least) two types of
solutions. First, we have those that relax the condition of
compositionality. Notably, the denotation of a complex phrase is no longer
a \emph{function} per se of the denotations of its immediate
subconstituents. Rather, it is some other formally defined
process\footnote{This kind of distinction is the same distinction between a
  mathematical function and a function in a programming language, which
  might have all kinds of side effects and therefore not be an actual
  function.}. Examples of this approach include:

\begin{itemize}
\item the incremental algorithm used to build discourse representation
  structures in DRT, as presented in~\cite{kamp1993discourse}
\item the $\lambda\mu$ calculus used in~\cite{de2001type} to analyse
  quantification since, due to the lack of confluence, function terms no
  longer denote functions over simple denotations
\item the use of exceptions and exception handlers
  in~\cite{lebedeva2012expression} to model presuppositions in an otherwise
  compositional framework
\item the parsetree interpretation step in the logic of conventional
  implicatures of~\cite{potts2005logic} that builds the denotation of a
  sentence by extracting implicatures from the denotations of all of its
  subparts (including the non-immediate ones)
\end{itemize}

The other approach is to enrich the denotations so that they are
parameterized by the external information they need to obtain and contain
whatever internal information they need to provide to their
superconstituents. Here are some examples of this style:

\begin{itemize}
\item any kind of semantic indices (e.g.\ the speaker and addressee for
  deixis, the current world for modality), since they amount to saying that
  a phrase denotes an indexed set of simpler meanings
\item the continuized semantics of~\cite{barker2002continuations} for
  quantification in which denotations are functions of their own
  continuations
  \begin{itemize}
  \item and more generally, any semantics using type raising or generalized
    quantifiers for noun phrase denotations
  \end{itemize}
\item the dynamic denotations of~\cite{de2006towards} that are functions of
  the common ground and their continuation
\item compositional event semantics, such as the one
  in~\cite{qian2011event}, that shift the denotations of sentences from
  truth-values to predicates on events
\end{itemize}

We want to find a common language in which we could express the above
techniques. Our inspiration comes from computer science. There, a concept
known as \emph{monad} has been used:
\begin{itemize}
\item in denotational semantics to give the domain of interpretation for
  programming languages that involve side effects~\cite{moggi1991notions}.
\item in functional programming to emulate programming with side effects
  via term-level encodings of effectful programs~\cite{wadler1992essence}.
\end{itemize}
These two principal applications of monads align with the two approaches we
have seen above. One where we change our calculus so it no longer defines
pure functions (e.g.\ is non-deterministic, stateful or throws exceptions)
and the one where we use use a pure calculus to manipulate terms
(denotations) that encode some interaction (e.g.\ dynamicity, continuations
or event predication).

Monad is a term from category-theory. Its meaning is relative to some
category. For us, this will always be the category whose objects are types
and whose arrows are functions between different types. A monad is formed
by a functor and a pair of natural transformations that satisfy certain
laws. In our case, this means that a monad is some type wrapper (the
functor part) and some combinators (the natural transformations) that
follow some basic laws. To give an example of this, we can think of the
functor $T(\alpha) = (\alpha \to o) \to o$ together with combinators such
as the type raising $\eta(x) = \lam{P}{\ap{P}{x}}$ as a monad of
quantification.

The usefulness of monads in natural language semantics has been discovered
by Shan in 2002~\cite{shan2002monads}\footnote{Side effects are to
  programming languages what pragmatics are to natural languages: they both
  study how expressions interact with the worlds of their users. It might
  then come as no surprise that phenomena such as anaphora, presupposition,
  deixis and conventional implicature yield a monadic description.}. Since
then, the problem that remained was how to compose several different monads
in a single solution. Marlow used the popular method of monad
morphisms\footnote{Also known as monad transformers in functional
  programming.} to combine several monads in his
dissertation~\cite{charlow2014semantics}. Giorgolo and Asudeh have used
distributive laws between monads to combine
monads~\cite{giorgolo2015natural}, while Kiselyov has eschewed monads
altogether in favor of applicative functors which enjoy easy composability
\cite{kiselyov2015applicative}.

Our approach follows the recent trend in adopting effects and handlers to
combine side effects~\cite{bauer2012programming,kammar2013handlers} and to
encode effectful programs in pure functional programming
languages~\cite{kiselyov2013extensible,brady2013programming}.

The idea is that we can represent each of the relevant monads using an
algebra. We can then combine the algebras by summing up their
signatures. The resulting algebra will serve as a universal representation
format for terms built from any of the source algebras and closed on
substitution. Then, we will build modular interpreters that will give
meanings to the operators of the algebras in terms of individuals,
truth-values and functions.

In Sect.~\ref{sec:definition}, we will introduce a formal calculus for
working with the algebraic terms that will use in our linguistic
denotations. In Sect.~\ref{sec:phenomena} and~\ref{sec:combination}, we
will see some simple uses of the calculus on the phenomena outlied in this
introduction and then we will explore what it would take to have them
coexist in the same fragment. Before we conclude in
Sect.~\ref{sec:conclusion}, we will also discuss some of the formal
properties of the calculus in Sect.~\ref{sec:properties}.


\section{Definition of the Calculus}
\label{sec:definition}

Having sketched the general idea behind our calculus in the introduction,
we will now turn our attention to the specifics. We start by defining the
syntactic constructions used to build the terms of our language.

\subsection{Terms}
\label{ssec:terms}

First off, let $\XX$ be a set of variables, $\Sigma$ a typed signature and
$\EE$ a set of operation symbols. In the definition below, we will let $M$,
$N$\ldots range over terms, $x$, $y$, $z$\ldots range over variables from
$\XX$, $c$, $d$\ldots range over the names constants from $\Sigma$ and
$\op{op}$, $\op{op}_i$\ldots range over the operation symbols in $\EE$.

The terms of our language are comprised of the following:

\begin{align*}
  M, N ::= &\ \lam{x}{M} & \mbox{[abstraction]} \\
   | \, &\ \ap{M}{N}  & \mbox{[application]} \\
   | \, &\ x  & \mbox{[variable]} \\
   | \, &\ c  & \mbox{[constant]} \\
   | \, &\ \app{\op{op}}{M_{\mathrm{p}}}{(\lam{x}{M_{\mathrm{c}}})}  & \mbox{[operation]} \\
   | \, &\ \ap{\eta}{M}  & \mbox{[injection]} \\
   | \, &\ \ap{\cdbanana}{N}  & \mbox{[handler]} \\
   | \, &\ \ap{\cherry}{M}  & \mbox{[extraction]} \\
   | \, &\ \ap{\CC}{M} & \mbox{[exchange]} 
\end{align*}

The first four constructions --- abstraction, application, variables and
constants --- come directly from the simply-typed lambda calculus (STLC)
with constants.

The next four deal with the algebraic expressions used to encode
computations. Let us sketch the behaviors of these four kinds of
expressions.

The operation $\op{op}$ and injection $\eta$ expressions will serve as the
constructors for our algebraic expressions. Algebraic expressions are
usually formed by operation symbols and then variables at the
leaves. Instead of variables, our algebraic expressions use terms from our
calculus for ther leaves. The $\eta$ constructor can thus take an ordinary
term from our calculus and make it a leaf node in an algebraic
expression. The operation symbols $\op{op}$ are then the operations of the
algebra.

The other three expression types correspond to functions over algebraic
expressions.
\begin{itemize}
\item The most useful is the handler $\banana{}$\footnote{Pronounced
  ``banana''. See~\cite{meijer1991functional} for the introduction of
  banana brackets.}. It acts as a recursor for the type of algebraic
  expressions. The terms $M_1$,\ldots,$M_n$ and $M_\eta$ in $\cdbanana$ are
  the clauses for the constructors $\op{op}_1$,\ldots,$\op{op}_n$ and
  $\eta$, respectively. We will use handlers to define interpretations of
  operation symbols in algebraic expressions.
\item The cherry $\cherry$ operator allows us to extract terms out of
  algebraic expressions. If an algebraic expression is of the form
  $\ap{\eta}{M}$, applying $\cherry$ to it will yield $M$.
\item The exchange operator $\CC$ permits a kind of commutation between the
  $\lambda$ binder and the operation symbols. We will see its use later.
\end{itemize}

\subsection{Types}
\label{ssec:types}

\section{Linguistic Phenomena as Effects}
\label{sec:phenomena}


\section{Effects in Combination}
\label{sec:combination}


\section{Properties of the Calculus}
\label{sec:properties}


\section{Conclusion}
\label{sec:conclusion}

%
% ---- Bibliography ----
%
\bibliographystyle{splncs03}
\bibliography{references}

\end{document}
