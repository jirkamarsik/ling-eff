\documentclass{llncs}

\usepackage{url}
\usepackage{hyperref}
\usepackage{stmaryrd}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage{bussproofs}

\include{definitions}


%
\begin{document}
%
\title{TBD}
%
\author{Anonymous Copy}
%
\institute{Anonymous Copy}

\maketitle              % typeset the title of the contribution

\begin{abstract}
\dots
\keywords{\dots}
\end{abstract}
%

\section{Introduction}
\label{sec:introduction}

The prevailing methodology of formal semantics is compositionality in the
sense of Frege: denotations of complex phrases are functions of the
denotations of their immediate constituents. However, several phenomena
have been identified that challenge this notion of
compositionality. Examples include anaphora, presupposition,
quantification, deixis and conventional implicature. In all of these
examples, simple models of denotation (i.e.\ noun phrases are individuals,
sentences are truth-values) run into complications as the denotations can
depend on external values (anaphora, deixis) or on something which is not
an immediate constituent (presupposition, quantification, conventional
implicature).

Among the solutions to these challenges, we find (at least) two types of
solutions. First, we have those that relax the condition of
compositionality. Notably, the denotation of a complex phrase is no longer
a \emph{function} per se of the denotations of its immediate
subconstituents. Rather, it is some other formally defined
process\footnote{This kind of distinction is the same distinction between a
  mathematical function and a function in a programming language, which
  might have all kinds of side effects and therefore not be an actual
  function.}. Examples of this approach include:

\begin{itemize}
\item the incremental algorithm used to build discourse representation
  structures in DRT, as presented in~\cite{kamp1993discourse}
\item the $\lambda\mu$ calculus used in~\cite{de2001type} to analyse
  quantification since, due to the lack of confluence, function terms no
  longer denote functions over simple denotations
\item the use of exceptions and exception handlers
  in~\cite{lebedeva2012expression} to model presuppositions in an otherwise
  compositional framework
\item the parsetree interpretation step in the logic of conventional
  implicatures of~\cite{potts2005logic} that builds the denotation of a
  sentence by extracting implicatures from the denotations of all of its
  subparts (including the non-immediate ones)
\end{itemize}

The other approach is to enrich the denotations so that they are
parameterized by the external information they need to obtain and contain
whatever internal information they need to provide to their
superconstituents. Here are some examples of this style:

\begin{itemize}
\item any kind of semantic indices (e.g.\ the speaker and addressee for
  deixis, the current world for modality), since they amount to saying that
  a phrase denotes an indexed set of simpler meanings
\item the continuized semantics of~\cite{barker2002continuations} for
  quantification in which denotations are functions of their own
  continuations
  \begin{itemize}
  \item and more generally, any semantics using type raising or generalized
    quantifiers for noun phrase denotations
  \end{itemize}
\item the dynamic denotations of~\cite{de2006towards} that are functions of
  the common ground and their continuation
\item compositional event semantics, such as the one
  in~\cite{qian2011event}, that shift the denotations of sentences from
  truth-values to predicates on events
\end{itemize}

We want to find a common language in which we could express the above
techniques. Our inspiration comes from computer science. There, a concept
known as \emph{monad} has been used:
\begin{itemize}
\item in denotational semantics to give the domain of interpretation for
  programming languages that involve side effects~\cite{moggi1991notions}.
\item in functional programming to emulate programming with side effects
  via term-level encodings of effectful programs~\cite{wadler1992essence}.
\end{itemize}
These two principal applications of monads align with the two approaches we
have seen above. One where we change our calculus so it no longer defines
pure functions (e.g.\ is non-deterministic, stateful or throws exceptions)
and the one where we use use a pure calculus to manipulate terms
(denotations) that encode some interaction (e.g.\ dynamicity, continuations
or event predication).

Monad is a term from category-theory. Its meaning is relative to some
category. For us, this will always be the category whose objects are types
and whose arrows are functions between different types. A monad is formed
by a functor and a pair of natural transformations that satisfy certain
laws. In our case, this means that a monad is some type wrapper (the
functor part) and some combinators (the natural transformations) that
follow some basic laws. To give an example of this, we can think of the
functor $T(\alpha) = (\alpha \to o) \to o$ together with combinators such
as the type raising $\eta(x) = \lam{P}{\ap{P}{x}}$ as a monad of
quantification.

The usefulness of monads in natural language semantics has been discovered
by Shan in 2002~\cite{shan2002monads}\footnote{Side effects are to
  programming languages what pragmatics are to natural languages: they both
  study how expressions interact with the worlds of their users. It might
  then come as no surprise that phenomena such as anaphora, presupposition,
  deixis and conventional implicature yield a monadic description.}. Since
then, the problem that remained was how to compose several different monads
in a single solution. Marlow used the popular method of monad
morphisms\footnote{Also known as monad transformers in functional
  programming.} to combine several monads in his
dissertation~\cite{charlow2014semantics}. Giorgolo and Asudeh have used
distributive laws between monads to combine
monads~\cite{giorgolo2015natural}, while Kiselyov has eschewed monads
altogether in favor of applicative functors which enjoy easy composability
\cite{kiselyov2015applicative}.

Our approach follows the recent trend in adopting effects and handlers to
combine side effects~\cite{bauer2012programming,kammar2013handlers} and to
encode effectful programs in pure functional programming
languages~\cite{kiselyov2013extensible,brady2013programming}.

The idea is that we can represent each of the relevant monads using an
algebra. We can then combine the algebras by summing up their
signatures. The resulting algebra will serve as a universal representation
format for terms built from any of the source algebras and closed on
substitution. Then, we will build modular interpreters that will give
meanings to the operators of the algebras in terms of individuals,
truth-values and functions.

In Sect.~\ref{sec:definition}, we will introduce a formal calculus for
working with the algebraic terms that will use in our linguistic
denotations. In Sect.~\ref{sec:phenomena} and~\ref{sec:combination}, we
will see some simple uses of the calculus on the phenomena outlied in this
introduction and then we will explore what it would take to have them
coexist in the same fragment. Before we conclude in
Sect.~\ref{sec:conclusion}, we will also discuss some of the formal
properties of the calculus in Sect.~\ref{sec:properties}.


\section{Definition of the Calculus}
\label{sec:definition}

Having sketched the general idea behind our calculus in the introduction,
we will now turn our attention to the specifics. We start by defining the
syntactic constructions used to build the terms of our language.

\subsection{Terms}
\label{ssec:terms}

First off, let $\XX$ be a set of variables, $\Sigma$ a typed signature and
$\EE$ a set of operation symbols. In the definition below, we will let $M$,
$N$\ldots range over terms, $x$, $y$, $z$\ldots range over variables from
$\XX$, $c$, $d$\ldots range over the names constants from $\Sigma$ and
$\op{op}$, $\op{op}_i$\ldots range over the operation symbols in $\EE$.

The terms of our language are comprised of the following:

\begin{align*}
  M, N ::= &\ \lam{x}{M} & \mbox{[abstraction]} \\
   | \, &\ \ap{M}{N} & \mbox{[application]} \\
   | \, &\ x & \mbox{[variable]} \\
   | \, &\ c & \mbox{[constant]} \\
   | \, &\ \app{\op{op}}{M_{\mathrm{p}}}{(\lam{x}{M_{\mathrm{c}}})} & \mbox{[operation]} \\
   | \, &\ \ap{\eta}{M} & \mbox{[injection]} \\
   | \, &\ \ap{\cdbanana}{N} & \mbox{[handler]} \\
   | \, &\ \ap{\cherry}{M} & \mbox{[extraction]} \\
   | \, &\ \ap{\CC}{M} & \mbox{[exchange]} 
\end{align*}

The first four constructions --- abstraction, application, variables and
constants --- come directly from the simply-typed lambda calculus (STLC)
with constants.

The next four deal with the algebraic expressions used to encode
computations. Let us sketch the behaviors of these four kinds of
expressions.

The operation $\op{op}$ and injection $\eta$ expressions will serve as the
constructors for our algebraic expressions. Algebraic expressions are
usually formed by operation symbols and then variables at the
leaves. Instead of variables, our algebraic expressions use terms from our
calculus for ther leaves. The $\eta$ constructor can thus take an ordinary
term from our calculus and make it a leaf node in an algebraic
expression. The operation symbols $\op{op}$ are then the operations of the
algebra.

The other three expression types correspond to functions over algebraic
expressions.
\begin{itemize}
\item The most useful is the handler $\banana{}$\footnote{Pronounced
  ``banana''. See~\cite{meijer1991functional} for the introduction of
  banana brackets.}. It acts as an iterator for the type of algebraic
  expressions. The terms $M_1$,\ldots,$M_n$ and $M_\eta$ in $\cdbanana$ are
  the clauses for the constructors $\op{op}_1$,\ldots,$\op{op}_n$ and
  $\eta$, respectively. We will use handlers to define interpretations of
  operation symbols in algebraic expressions.
\item The cherry $\cherry$ operator allows us to extract terms out of
  algebraic expressions. If an algebraic expression is of the form
  $\ap{\eta}{M}$, applying $\cherry$ to it will yield $M$.
\item The exchange operator $\CC$ permits a kind of commutation between the
  $\lambda$ binder and the operation symbols. We will see its use later.
\end{itemize}


\subsection{Types}
\label{ssec:types}

We now give a syntax for the types of our calculus alongside with a typing
relation. In the grammar below, $\alpha$, $\beta$, $\gamma$\ldots range
over types, $\nu$ ranges over atomic types from some set $\TT$ and $E$,
$E'$\ldots ranges over effect signatures (introduced below).

The types of our language consist of:

\begin{align*}
  \alpha, \beta, \gamma ::= &\ \alpha \to \beta & \mbox{[function]} \\
   | \, &\ \nu & \mbox{[atom]} \\
   | \, &\ \FF_E(\alpha) & \mbox{[computation]}
\end{align*}

The only novelty here is the $\FF_E(\alpha)$ computation type. This is the
type of algebraic expressions whose leaves are terms of type $\alpha$ and
whose operation symbols come from the effect signature $E$. We call them
\emph{computation types} and we call terms of these types
\emph{computations} because our algebraic expressions will always represent
some kind of effectful program.

\emph{Effect signatures} are similar to typing contexts. They are partial
mappings from the set of operation symbols $\EE$ to pairs of types. We will
write the elements of effect signatures the following way ---
$\typedop{op}{\alpha}{\beta} \in E$ means that $E$ maps $\op{op}$ to the
pair of types $\alpha$ and $\beta$\footnote{The two types $\alpha$ and
  $\beta$ are to be seen as the operation's \emph{input} and \emph{output}
  types, respectively.}. When dealing with effect signatures, we will often
make use of the disjoint union operator $\uplus$. The term $E_1 \uplus E_2$
serves as a constraint demanding that the domains of $E_1$ and $E_2$ be
disjoint and at the same time it denotes the effect signature that is the
union of $E_1$ and $E_2$.

The typing rules are presented in Figure~\ref{fig:types}.

\newcommand{\handlerrule}{
 \begin{prooftree}
  \AxiomC{$E = \{\typedopg{\op{op}_i}{\alpha_i}{\beta_i}\}_{i \in I} \uplus E_{\mathrm{f}}$}
  \noLine
  \def\extraVskip{0pt}
  \UnaryInfC{$E' = E'' \uplus E_{\mathrm{f}}$}
  \noLine
  \UnaryInfC{$[\Gamma \vdash M_i : \alpha_i \to (\beta_i \to
    \FF_{E'}(\delta)) \to \FF_{E'}(\delta)]_{i \in I}$}
  \noLine
  \UnaryInfC{$\Gamma \vdash M_\eta : \gamma \to \FF_{E'}(\delta)$}
  \noLine
  \UnaryInfC{$\Gamma \vdash N : \FF_{E}(\gamma)$}
  \def\extraVskip{2pt}
  \RightLabel{[$\banana{}$]}
  \UnaryInfC{$\Gamma \vdash \ap{\cibanana}{N} : \FF_{E'}(\delta)$}
 \end{prooftree}}

\begin{figure}
  \def\labelSpacing{4pt}

  \begin{subfigure}{.5\textwidth}
   \begin{prooftree}
    \AxiomC{$\Gamma, x : \alpha \vdash M : \beta$}
    \RightLabel{[abs]}
    \UnaryInfC{$\Gamma \vdash \lam{x}{M} : \alpha \to \beta$}
   \end{prooftree}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
   \begin{prooftree}
    \AxiomC{$\Gamma \vdash M : \alpha \to \beta$}
    \AxiomC{$\Gamma \vdash N : \alpha$}
    \RightLabel{[app]}
    \BinaryInfC{$\Gamma \vdash M N : \beta$}
   \end{prooftree}
  \end{subfigure}

  \vspace{2mm}
 
  \begin{subfigure}{.5\textwidth}
   \begin{prooftree}
    \AxiomC{$x : \alpha \in \Gamma$}
    \RightLabel{[var]}
    \UnaryInfC{$\Gamma \vdash x : \alpha$}
   \end{prooftree}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
   \begin{prooftree}
    \AxiomC{$c : \alpha \in \Sigma$}
    \RightLabel{[const]}
    \UnaryInfC{$\Gamma \vdash c : \alpha$}
   \end{prooftree}
  \end{subfigure}

  \vspace{6mm}

  \begin{subfigure}{.5\textwidth}
   \begin{prooftree}
    \AxiomC{$\Gamma \vdash M : \alpha$}
    \RightLabel{[$\eta$]}
    \UnaryInfC{$\Gamma \vdash \ap{\eta}{M} : \FF_E(\alpha)$}
   \end{prooftree}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
   \begin{prooftree}
    \AxiomC{$\Gamma \vdash M_{\mathrm{p}} : \alpha$}
    \AxiomC{$\Gamma, x : \beta \vdash M_{\mathrm{c}} : \FF_E(\gamma)$}
    \def\extraVskip{0pt}
    \noLine
    \BinaryInfC{$\typedop{op}{\alpha}{\beta} \in E$}
    \def\extraVskip{2pt}
    \RightLabel{[op]}
    \UnaryInfC{$\Gamma \vdash \app{\op{op}}{M_{\mathrm{p}}}{(\lam{x}{M_{\mathrm{c}}})} : \FF_E(\gamma)$}
   \end{prooftree}
  \end{subfigure}

  \vspace{3mm}

  \hspace{-1.5cm}
  \begin{subfigure}{.5\textwidth}
   \begin{prooftree}
    \AxiomC{$\Gamma \vdash M : \FF_\emptyset(\alpha)$}
    \RightLabel{[$\cherry$]}
    \UnaryInfC{$\Gamma \vdash \ap{\cherry}{M} : \alpha$}
   \end{prooftree}
  \end{subfigure}
  \hspace{1cm}
  \begin{subfigure}{.5\textwidth}
   \handlerrule
  \end{subfigure}

  \vspace{6mm}

  \begin{subfigure}{\textwidth}
   \begin{prooftree}
    \AxiomC{$\Gamma \vdash M : \alpha \to \FF_E(\beta)$}
    \RightLabel{[$\CC$]}
    \UnaryInfC{$\Gamma \vdash \ap{\CC}{M} : \FF_E(\alpha \to \beta)$}
   \end{prooftree}
  \end{subfigure}

  \caption{\label{fig:types}Typing rules for our calculus.}
\end{figure}

The typing rules mirror the syntax of terms. Again, the first four rules
come from STLC.\@ The [$\eta$] and [$\cherry$] rules are self-explanatory
and so we will focus on the [$\op{op}$], [$\banana{}$] and [$\CC$] rules.

\subsubsection*{[$\op{op}$]}

To use an operation $\typedop{op}{\alpha}{\beta}$, we provide the input
parameter $M_{\mathrm{p}} : \alpha$ and a continuation
$\lam{x}{M_{\mathrm{c}}} : \beta \to \FF_E(\gamma)$ which expects the
output of type $\beta$. The resulting term has the same type as the body of
the continuation, $\FF_E(\gamma)$.

Before, we have spoken of terms of type $\FF_E(\gamma)$ as of algebraic
expressions generated by the terms of type $\gamma$ and the operators in
the effect signature $E$. However, having seen the typing rule for
operation terms, it might not be obvious how such a term represents an
algebraic expression. Traditionally, algebraic signatures map operation
symbols to arities, which are natural numbers. Our effect signatures map
each operation symbol to a pair of types $\alpha \rightarrowtail \beta$.
\begin{itemize}
\item We can explain $\alpha$ by analogy to the single-sorted algebra of
  vector spaces. In a single-sorted vector space algebra, scalar
  multiplication is viewed as a unary operation parameterized by some
  scalar. So technically, there is a different unary operation for each
  scalar. All of our operations are similarly parameterized and $\alpha$ is
  the type of that parameter.
\item The type $\beta$ expresses the arity of the operator. When we say
  that an operator has arity $\beta$, where $\beta$ is a type, we mean that
  it takes one operand for every value of $\beta$. We can also think of the
  operator as taking one operand with $x : \beta$ as a free variable.
\end{itemize}

We can look at the algebraic expression
$\app{\op{op}}{M_{\mathrm{p}}}{(\lam{x}{M_{\mathrm{c}}})}$ as a description
of a program that:
\begin{itemize}
\item interacts with its context by some operator called $\op{op}$
\item to which it provides the input $M_{\mathrm{p}}$
\item and from which it expects to receive an output of type $\beta$
\item which it will then bind as the variable $x$ and continue as the
  program described by $M_{\mathrm{c}}$.
\end{itemize}

\subsubsection*{[$\banana{}$]}

The banana brackets describe iterators/catamorphisms\footnote{These are
  similar to recursors/paramorphisms. See~\cite{meijer1991functional} for
  the difference. Catamorphisms are also known as folds and the common
  higher-order function \emph{fold} found in functional programming
  languages is actually the iterator/catamorphism for lists.}. In the
typing rule, $E$ is the input's signature, $E'$ is the output's signature,
$\gamma$ is the input's leaf type and $\delta$ is the output's leaf
type. $E$ is decomposed into the operation that our iterator will actually
interpret, the other operations form a residual signature
$E_{\mathrm{f}}$. The output signature will then still contain the
uninterpreted operations $E_{\mathrm{f}}$ combined with any operations
$E''$ that our interpretation might introduce.

\subsubsection*{[$\CC$]}

We said before that the $\CC$ function will let us commute $\lambda$ and
operations. Here, we see that on the type level, this corresponds to
commuting the $\FF_E(\_)$ and the $\alpha \to \_$ type constructors.




\section{Linguistic Phenomena as Effects}
\label{sec:phenomena}


\section{Effects in Combination}
\label{sec:combination}


\section{Properties of the Calculus}
\label{sec:properties}


\section{Conclusion}
\label{sec:conclusion}

%
% ---- Bibliography ----
%
\bibliographystyle{splncs03}
\bibliography{references}

\end{document}
